{"pages":[{"title":"分 类","text":"","link":"/categories/index.html"},{"title":"标 签","text":"","link":"/tags/index.html"},{"title":"关 于","text":"Live in DaLian","link":"/about/index.html"}],"posts":[{"title":"Mac IDEA启动SpringBoot项目过慢","text":"最近本地新起的SpringBoot项目运行非常慢，能有十几秒，最后通过以下方法进行解决，解决后运行在三四秒左右。 通过hostname命令查看本机hostname1$ hostname 得到如下信息1MacBook-Pro.local 修改host文件1sudo vim /etc/hosts 修改条目如下，注意分隔符是TAB，不是空格12127.0.0.1 localhost MacBook-Pro.local::1 localhost MacBook-Pro.local 也可以通过软件进行修改","link":"/2019/05/06/IdeaSpringBoot/"},{"title":"Launchpad图标修改","text":"最近买了34寸曲面显示器，Launchpad的图标显示比较别扭，所以调整显示的行数与列数。 解决这个问题的方法是通过如下命令： 设置行数与列数123defaults write com.apple.dock springboard-rows -int 4defaults write com.apple.dock springboard-columns -int 7killall Dock 恢复默认行数与列数123defaults delete com.apple.dock springboard-rowsdefaults delete com.apple.dock springboard-columnskillall Dock 删除图标分组还有一个命令是删除图标分组（真心觉得这命令没啥用，没事儿别乱试，重新分组老麻烦了！）12defaults write com.apple.dock ResetLaunchPad -bool TRUEkillall Dock","link":"/2019/06/05/LaunchpadIcon/"},{"title":"搭建个人博客 之 MWeb，服务器和全站Https","text":"MWeb界面简洁和高性能，支持发布协议，可以快速发布写好的文章，MWeb备份配合Docker及七牛，防止数据丢失，重新部署也不会太麻烦，下面介绍MWeb快速部署Hexo文章，Docker创建Nginx容器并配置SSL证书，七牛云图床申请及开启Https。 MWeb使用在那么多md编辑器里之所以喜欢用MWeb有这几个原因： 可以边编辑、预览同开（其实也不看预览，但是必须要开，哈哈～） 可以复制图片到正在编辑的md文件，会在对应目录添加图片副本 可以将图片上传到自己的图床 可以快捷发布到各种服务商：印象，少数派……支持自定义脚本 有外部引用模式 操作简洁 配置七牛云在偏好设置--&gt;发布服务可以看到，对应的填入七牛的空间名称，Access Key，Secret Key，和域名即可。填写好后可以进行验证，上传一张图片看是否成功。 上传图片到七牛云写文章时候直接复制图片粘到md中，文章全部写完后点击右上角分享按钮。 选择把本地图片传至图床。 选择复制 Markdown，图片会上传到所选图床并会复制已经替换成对应域名地址的md文本，将md复制到需要部署的md文件中即可。 注：git要手动上传复制外链 配置发布服务在偏好设置--&gt;发布服务可以看到支持和运行脚本,然后写下对应的hexo部署命令即可。 发布文章到Hexo在需要进行部署的md文件点击右上分享选择对应的发布服务。 MWeb会复制命令到剪切板，直接在弹出的终端里command + V回车就可以运行已经写好的部署命令。 Docker + NginxDocker是一个虚拟化软件，你可以认为是类似：VMware、Virtualbox。对开发来讲总结一个最简单的说法：在 Maven 未产生的年代，jar 包要随着开发项目走到哪里跟到哪里。有了 Maven 写好 pom.xml 即可。此时的 Docker 就好比如 Maven，帮你省去了开发过程中的部署环境差异，你再也不能随便说：你的系统可以运行，我的系统就不行。现在别人连系统都帮你做好了~ Docker安装Nginx容器安装启动Docker（以后会更新Docker详细教程）12sudo yum install docker-ce //安装sudo systemctl start docker //启动 推荐一个替代docker stats的插件 ctop12sudo wget https://github.com/bcicen/ctop/releases/download/v0.7.2/ctop-0.7.2-linux-amd64 -O /usr/local/bin/ctopsudo chmod +x /usr/local/bin/ctop 从Docker仓库拉取最新nginx镜像1docker pull nginx 创建Nginx容器12345678910docker run -v /var/dfile/nginx/nginx.conf:/etc/nginx/nginx.conf -v /var/dfile/nginx:/var/dfile/ -v /var/dfile/nginx/full_chain.pem:/etc/nginx/cert/full_chain.pem -v /var/dfile/nginx/private.key:/etc/nginx/cert/private.key -d -p 80:80 -p 443:443 --name=ng -i -t --restart=always bb7 /bin/bash 进入容器1docker exec -it ng bash Nginx配置nginx的配置文件是/etc/nginx/nginx.conf，配置文件如下（ssl）：123456789101112131415161718192021222324server { listen 443 ssl; server_name localhost; ssl_certificate /etc/nginx/cert/full_chain.pem;#ssl配置 ssl_certificate_key /etc/nginx/cert/private.key;#ssl配置 ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / { root /var/dfile/hexo;#静态资源文件夹 index index.html index.htm;#静态资源页面 } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } server { listen 80;#监听端口 server_name www.mikecorden.com mikecorden.com; rewrite ^(.*) https://$server_name$1 permanent;#301永久重定向 } 启动nginx1/usr/local/sbin/nginx 修改配置文件要重启nginx1/usr/local/sbin/nginx -s reload 用vim修改nginx.conf太费劲，一般直接本地修改完，SFTP工具拖到服务器nginx容器挂在目录，然后重启。 阿里云本站的域名和服务器都是在阿里云购买。阿里云的交互还是很简单的，比较方便，app做的也还行，现在手机也有内置的控制台了。 域名及解析我把博客部署到了github和自己的服务器上，在域名解析的时候，对于国内线路解析到自己的服务器，国外的线路解析到自己的GitHubPages上，来提高访问速度。 SSL证书申请，全站HTTPSSSL证书是在阿里云申请的，下载的时候 选择nginx版本，在创建nginx容器的时候要映射宿主机的443端口用于ssl。具体配置看👆。全站Https需要本站所有的外链必须为Https，包括加载的js，css等，所有的图片链接也必须为Https。因为Hexo其实就是静态页面，实现起来也简单。下面介绍下七牛云图床开启https。 七牛云七牛云提供 10 G/月的标准存储 CDN 回源流量免费额度， 超过按0.15 元/GB 价格进行收费。每个月免费10G对于这种没人看的小博客很够用了，哈哈～ 配置七牛云图床注册七牛云账号，申请对象存储空间（公开空间）。 进入所申请的空间，绑定域名（自动跳转域名管理）。 输入域名，先申请http，保存后进入域名管理，（保存成功后再改为https，这样可以免去手动配置ssl证书）。 状态变为成功后（一般10分钟左右），选择对应的域名，进入配置界面。 配置防盗链白名单，然后配置Https：选择免费证书（阿里云等其他网站申请，点击已有证书），七牛云会自动帮你申请一年有效的免费ssl证书并配置好，最后开启强制Https即可。 最后在域名管理找到域名对应的CNAME值，在阿里云上配置域名解析，类型为CNAME。 最后到此，整个流程结束，现在在MWeb的资源库写笔记，需要发到博客上的直接上传图床复制到外部引用模式对应md中，直接部署生效。也不需要担心备份等突发情况，MWeb支持3个地方的备份，我在Mac本机有备份，在iCloud网盘也有备份，永远不会担心资料丢失了～","link":"/2019/03/18/Hexo2/"},{"title":"Spring Cloud Bus","text":"主要介绍Spring Cloud Bus github上配置文件 Spring Cloud Bus 概述Spring Cloud Bus 使用轻量级的消息代理（RabbitMQ,Kafka……）连接分布式系统的节点（clients），这样可以广播传播状态的更改（更新配置文件操作）或其他管理指令。达到下图效果。例如上图，所有client都与消息总线想连，当configserver的/bus/refresh接收到请求，会像消息总线发送一个配置更新的事件，通过消息总线广播，所有的client会去configServer拉最新的配置。 Client如何更新配置–&gt;refresh客户端如何去主动获取新的配置信息呢，springcloud已经给我们提供了解决方案，每个客户端通过POST方法触发各自的/refresh Client添加依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; spring-boot-starter-actuator是一套监控的功能，可以监控程序在运行时状态，其中就包括/refresh的功能。 开启更新机制需要给加载变量的类上面加载@RefreshScope，在客户端执行/refresh的时候就会更新此类下面的变量值。 所有的客户端和服务端都需要的依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt; ConfigServer配置文件在configServer配置文件增加：1234567891011121314151617181920212223spring: application: name: Config-Server cloud: config: server: git: uri: https://github.com/****/first-config-repo search-paths: /first username: *** password: *** prefix: /config # 访问yml时候http://hostname:port/config/test/dev即可 rabbitmq: host: 0.0.0.0 # RabbitMQ服务地址 port: 5672 username: *** password: *** management: endpoints: web: exposure: include: bus-refresh # 暴露/bus/refresh端点 可以把所有端点都暴露，用*就可以，但yml中的*需要用双引号括起–&gt;&quot;*&quot;,SpringBoot 2.0.x暴露端点方式：1234# 启用端点 envmanagement.endpoint.env.enabled=true# 暴露端点 env 配置多个,隔开management.endpoints.web.exposure.include=env 已经弃用：management.security.enabled=false client配置文件在bootstrap.yml中增加：1234567891011121314151617spring: cloud: config: name: test # application profile: dev # profile label: master # git分支 discovery: service-id: EUR-SERVER2 # 指定server端的name,也就是server端spring.application.name的值 enabled: true # 开启Config服务发现支持 bus: trace: enabled: true # 开启消息跟踪 rabbitmq: host: 0.0.0.0 port: 5672 username: *** password: *** 其中spring.cloud.config.discovery.*下的配置是为了实现配置中心高可用，也可以指定configServer的地址(此方式不是高可用)：spring.cloud.config.uri: http://peer2:8882 WebHook可以在github上设置，码云也可以，push后可以发送一个Post请求。本地验证可以用HTTP工具自己发http://peer1:8881/actuator/bus-refresh（其中actuator别忘了，经常忘写） 验证当更新github上的文件后，手动发送一个post请求http://peer1:8881/actuator/bus-refresh，这时候再验证client中对应的属性值就会发现已经更改了。","link":"/2019/03/01/SpringCloudBus/"},{"title":"Spring Cloud Eureka","text":"主要介绍Spring Cloud Eureka 服务发现组件概述 各个服务启动时候，将自己注册到注册中心，服务发现组件（Eureka Server）会记录这些信息。 服务消费之可以到服务发现组件（Eureka Server）的注册表查询服务提供者的信息（地址等……），并使用该信息调用提供者的接口 各个微服务使用心跳机制与服务发现组件（Eureka Server）进行通信，服务发现组件长时间没有接收到心跳，会注销该服务实例。 微服务更改信息（IP地址等）会重新进行注册，服务消费者可直接获取最新信息。 Spring Cloud服务发现组件有：Eureka，Zookeeper，Consul…… Eureka概述 Netflix开发的服务发现组件，基于REST的服务。包含：Server、Client。 Spring Cloud将其集成于Spring Cloud Netflix中。 Eureka 2.0以上已经闭源。 Eureka原理概述 Eureka Server提供服务发现能力。 Eureka Client是一个Java客户端，会周期性（默认30s）向Eureka Server 发送心跳。 Eureka Server一定时间（默认90s）内没有接收到心跳会注销掉该实例。 默认情况下Eureka Server也是一个Eureka Client（用于高可用），多个Eureka Server互相注册，会通过复制的方式来同步注册表。 Eureka Client也会缓存注册表信息（避免Eureka Server挂掉，无法调用服务提供者） 创建Eureka Serverpom.xml12345&lt;!-- EurekaServer --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 启动类增加@EnableEurekaServer注解 配置文件application.yml123456789101112131415server: port: 8002spring: application: name: Eureka-Servereureka: client: registerWithEureka: true #是否将自己注册到注册中心 fetchRegistry: true #高可用设置，作用：从其他EurekaServer上复制注册表 service-url: defaultZone: http://admin:admin1@peer1:8001/eureka/ #可以配置多个地址，用逗号分隔 instance: hostname: peer2 高可用Eureka Server因为Eureka Server本身也是一个Eureka Client，互相注册，配置文件设置eureka.client.regsiterWithEureka=true,eureka.client.fetchRegistry=true即可。 添加用户认证引入依赖12345&lt;!-- 登陆验证 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件 Spring Cloud 2.x以后 12345spring: security: user: name: admin password: 123456 Srong CLoud 1.x 123456security: base: enable: true user: name: admin password: 123456 关闭crsf验证设置安全验证后，由于Spring Cloud 2.x是默认开启crsf验证的，所以一点要关闭crsf，否则client是无法注册到eureka server的。1234567891011121314151617@Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { //覆盖父类的 configure(HttpSecurity http) 方法，关闭掉 csrf //如果不关闭，服务将无法注册到此注册中心 //http.csrf().disable();默认是formLogin()，登陆时候不弹窗 http.csrf() .disable() .authorizeRequests() .anyRequest().authenticated() .and() .httpBasic();//httpBasic登陆模式（弹出框） super.configure(http); }} 用户认证下Eureka Client的配置更改defaultZone：erueka.client.service-url.defaultZone: http://{name}:{password}@{host}:{port}/eureka 其他 eureka.instance.prefer-ip-address=true表示将自己的IP注册到Eureka Server，false会将微服务所在的操作系统HOSTNAME注册到Eureka Server eureka.instance.metadate-map.my-metadata=***（key，value随便写）,可以自定义Eureka Server元数据，例如“my-metadata=***”。 自我保护模式，当Eureka Serve节点短时间丢失过多客户端时候，这个节点就会进入自我保护模式，，此时，Eureka Server会保护注册表中的信息，不再删除，故障恢复后节点会自动退出自我保护模式。 多网卡环境下IP选择： 12345678910111213spring: client: inetutils: #忽略docker0网卡和所有veth开头的网卡 ignored-interfaces: - docker0 - veth.* #允许的网络地址 preferredNetworks: - 192.168 - 10.0 #只允许使用站点本地的地址 useOnlySiteLocalInterfaces: true 健康检查状态有：UP，DOWN，OUT_OF_SERVICE，UNKNOWN显示错误，看看健康检查是否开启eureka.client.healthcheck.enabled=true 创建Eureka Clientpom.xml12345&lt;!-- Eureka client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 启动类增加@EnableDiscoveryClient注解 配置文件1234567891011server: port: 9001spring: application: name: Producer eureka: client: serviceUrl: defaultZone: http://admin:123456@peer1:8001/eureka/ 启动Eureka Client可以看到已经注册成功。","link":"/2019/02/05/SpringCloudEureka/"},{"title":"微服务概念类知识","text":"关于CAP理论CAP定理指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可同时获得。 一致性：C在分布式系统中的所有数据备份，在同一时刻是否同样的值。（所有节点在同一时间的数据完全一致，越多节点，数据同步越耗时） 可用性：A负载过大后，集群整体是否还能响应客户端的读写请求。（服务一直可用，而且是正常响应时间） 分区容错性：P分区容忍性，就是高可用性，一个节点崩了，并不影响其它的节点（100个节点，挂了几个，不影响服务，越多机器越好） CAP理论就是说在分布式存储系统中，最多只能实现上面的两点。而由于当前的网络硬件肯定会出现延迟丢包等问题，所以分区容忍性是我们必须需要实现的。所以我们只能在一致性和可用性之间进行权衡 其他问题 满足CA，不能满足P原因：数据同步(C)需要时间，也要正常的时间内响应(A)，那么机器数量就要少，所以P就不满足 满足CP，不能满足A原因：数据同步(C)需要时间, 机器数量也多(P)，但是同步数据需要时间，所以不能再正常时间内响应，所以A就不满足 满足AP，不能满足C原因：机器数量也多(P)，正常的时间内响应(A)，那么数据就不能及时同步到其他节点，所以C不满足 注册中心选择 Zookeeper：CP设计，保证了一致性，集群搭建的时候，某个节点失效，则会进行选举行的leader，或者半数以上节点不可用，则无法提供服务，因此可用性没法满足 Eureka：AP原则，无主从节点，一个节点挂了，自动切换其他节点可以使用，去中心化 结论：分布式系统中P,肯定要满足，所以只能在CA中二选一。没有最好的选择，最好的选择是根据业务场景来进行架构设计。 如果要求一致性，则选择zookeeper，如金融行业如果要去可用性，则Eureka，如电商系统 云计算模式:三种主流模式 名称 全称 翻译 PaaS Platform as a Service 平台即服务 IaaS Infrastructure sa a Service 基础设施即服务 SaaS Software as a Service 软件即服务 结合例子理解在《Spring Microservices in Action》有这样一个例子：当你想吃饭时，你有4种模式： 在家做饭。 去杂货店买一顿先做好的食物，然后你加热并享用。 叫外卖送到家里。 开车去餐厅吃饭。 这些选择之间主要的区别在于：谁负责烹饪，以及在哪烹饪。 上述第一条，想要在家里吃饭，就需要自己做所有的工作，家里的食材，器材。 上述第二条，去商店买，自己加热吃，是使用店内的厨师和器材先做好餐点，但你仍有责任要加热，食用，清洗餐具——&gt;IaaS。 上述第三条，外卖，自己提供盘子，家具，但餐厅提供烤箱、食材、厨师——&gt;PaaS 上述第四条，你去一个餐厅吃饭，什么都不需要做，你就是供应商所提供服务的被动消费者，无法对技术进行选择，同时没有责任维护应用程序的基础设施——&gt;SaaS IaaS也就是基础设施即服务（Infrastructure-as-a-Service），拥有了IaaS，就可以将引荐外包到别的地方去。IaaS公司会提供场外服务器，存储和网络硬件，也可以选择租用。节省了维护成本和办公场地，公司可以在任何时候利用这些硬件来运行其应用。目前比较知名的IaaS公司有亚马逊、Bluelock、CSC、GoGrid、IBM等。 PaaS即软件即服务（Platform-as-a-Service），某些时候也被叫作中间件。所有的开发都可以在这一层进行，节省时间与资源。PaaS公司可以提供各种开发和分发应用的解决方案，比如虚拟服务器和操作系统等，可以节省硬件上的费用。PaaS公司与IaaS公司有许多重叠，除了上面列出的那些之外，还有Google、Microsoft Azure、Force.com、,Heroku、Engine Yard等。 最后则是SaaS，软件即服务（Software-as-a-Service），也是我们目前普通用户接触最多的层面，在网络上任意一个远程服务器上的应用都是属于SaaS。比如现在阿里的钉钉、JIBUU以及苹果的iCloud都属于这一类。比较知名的SaaS公司有Salesforce、workday、Slack等。 新兴的云平台 FaaS 函数即服务 CaaS 容器即服务，例如Docker微服务概念的重点在于 构建 有限职责的 小型服务 ，并使用基于HTTP的接口进行通讯。FAAS、CaaS是部署微服务的替代基础设施机制","link":"/2019/02/01/MicroServices/"},{"title":"MacOS JDK，使用Jenv管理本地JDK版本","text":"MacOS上配置JDK环境（附带下载地址），并使用Jenv快速高效的管理本地环境变量JDK版本。 Mac JDK下载 mac版本 jdk 1.6 需要到苹果开发者网站下载 mac版本 jdk 1.7 需要到网上找资源，官方已经停止jdk 1.7的下载链接 mac版本 jdk 1.8 直接到官方网站下载即可 homebrew 使用brew install java 安装会直接安装jdk 10（最新版本） 1brew install java JDK安装目录命令查询1/usr/libexec/java_home -V 卸载JDK执行命令：123456789sudo rm -fr ~/Library/Application\\ Support/Javasudo rm -rf /Library/Java/JavaVirtualMachines/jdk&lt;version&gt;.jdksudo rm -rf /Library/PreferencePanes/JavaControlPanel.prefPanesudo rm -fr /Library/PreferencesPanes/JavaControlPanel.prefpanesudo rm -rf /Library/Internet\\ Plug-Ins/JavaAppletPlugin.pluginsudo rm -rf /Library/LaunchAgents/com.oracle.java.Java-Updater.plistsudo rm -rf /Library/PrivilegedHelperTools/com.oracle.java.JavaUpdateHelpersudo rm -rf /Library/LaunchDaemons/com.oracle.java.Helper-Tool.plistsudo rm -rf /Library/Preferences/com.oracle.java.Helper-Tool.plist 使用Jevn管理MacOS JDKJenv概述jEnv is a command line tool to help you forget how to set the JAVA_HOME environment variable 安装（zsh下）使用homebrew安装1brew install jenv 添加环境变量12echo &apos;export PATH=&quot;$HOME/.jenv/bin:$PATH&quot;&apos; &gt;&gt; ~/.zshrcecho &apos;eval &quot;$(jenv init -)&quot;&apos; &gt;&gt; ~/.zshrc 添加jdk版本使用jevn add jdk安装路径，例如：1jenv add /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home 常用操作查看所有本地jdk版本1$ jenv versions 设置全局jdk版本1$ jenv global 1.7 设置本地jdk版本 (可以为每个文件夹单独设置版本)1$ jenv local 1.8 设置shell中的jdk版本1$ jenv shell 1.8 配置JVM Options（全局，本地，shell）123jenv global-options &quot;-Xmx512m&quot;jenv local-options &quot;-Xmx512m&quot;jenv shell-options &quot;-Xmx512m&quot;","link":"/2018/07/16/MacJDK/"},{"title":"搭建个人博客 之 Hexo基础","text":"一直有在本地写md笔记的习惯，又想同步到自己的各个设备随时查看，Win平台试过马克飞象同步到印象笔记，印象笔记端不能编辑，放弃……之后一直使用typora在本地保存，自从18年换到MacOS平台后，尝试过MWeb，Quiver，Bear，Ulysses，最后选择MWeb。后来有了自己的服务器，使用了WordPress一段时间，感觉比较麻烦，速度也不理想。折腾向的我又选择了Hexo，所以有了这篇文章，哈哈。现在是采用MWeb编辑md文件，通过MWeb发布服务直接推到服务器上，图片通过MWeb上传到七牛云，服务器使用Docker和Nginx来实现。这样一来，写完md文件后，直接发布，相当方便哈哈！ 安装HexoMac已经使用HomeBrew安装了node和git，所以直接安装Hexo。1npm install -g hexo 新建并进入Hexo目录，并执行Hexo初始化。 1hexo init //hexo初始化 123hexo g //重新生成博客静态文件hexo g --watch//重新生成博客代码(只对变动的文件生成静态文件)hexo s //启动hexo服务 可以在http://localhost:4000看到本地的hexo博客。 使用Hexo写作1hexo new [layout] &lt;title&gt; layout有三种布局： post 文章 page 页面 draft 草稿 三种布局的模版在Hexo目录/scaffolds/下，可以根据需要进行修改，正文部分可以使用md格式也可以使用html格式。 配置Hexo站点在Hexo目录下的_config.yml是Hexo的站点配置文件，注意每个冒号后要有空格，这是我做更改的配置，其余都为默认。1234567891011121314151617181920212223242526# Sitetitle: Corden Web //网站标题subtitle: Web developer, lifelong learner //网站副标题description: //网站描述keywords: //网站关键词author: MikeCorden //作者language: zh-CN //语言timezone: //时区，默认你电脑的时区## Themes: https://hexo.io/themes/theme: next //使用next主题# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: //同时部署到阿里云服务器和git上- type: sftp //部署方式 host: //服务器ip user: //用户名 pass: //密码 remotePath: //上传路径 port: //端口 agent: $SSH_AUTH_SOCK- type: git //部署方式 repo: //git上仓库地址 branch: //分支名称 message: //提交信息 如果只部署到服务器上(更多方式请参考 : hexo.io) ：123deploy: type: sftp ... 使用Hexo主题主题可以在hexo.themes上选择并下载，默认主题是landscape，我下载了Modernist和NexT。 安装NexT主题进入Hexo目录。1git clone git@github.com:theme-next/hexo-theme-next.git themes/next 修改Hexo路径下站点配置文件_config.yml。1theme: next //next需要与themes下对应的主题文件夹同名 配置NexT主题在Hexo目录下cd themes/next可以看到_config.yml，这个是NexT主题的配置文件，注意不要跟Hexo的站点配置文件搞混。 👇简单介绍一些我使用的配置： 菜单配置12345678910# Usage: `Key: /link/ || icon`menu: home: / || home archives: /archives/ || archive categories: /categories/ || th tags: /tags/ || tags about: /about/ || user #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 设置后需要在Hexo主目录下创建页面： 1hexo new page tags 如果引入评论系统要在页面加上comments: false（分类和关于页面也要加） 更改主题布局四种布局可选，打开所需布局即可。12345# Schemes#scheme: Muse#scheme: Mistscheme: Pisces#scheme: Gemini 联系方式12345social: GitHub: https://github.com/yourname || github E-Mail: mailto:&lt;yourmail&gt; || envelope Instagram: https://instagram.com/&lt;你的Ins用户名&gt; || instagram ... 头像123456# Sidebar Avataravatar: url: #头像地址 rounded: false #true--&gt;圆的 opacity: 1 #透明度 rotated: false #true--&gt;鼠标放上旋转 url可以是OSS外链，也可以在主题下的source/images/下放置头像文件即可。 边栏123sidebar: # Sidebar Position, available values: left | right (only for Pisces | Gemini). position: left 自带动画效果123motion: enable: true #开启 async: true #开启异步 开启动画会影响打开网站速度，可以关闭 自带动画背景效果1234567canvas_nest: enable: true #开启 onmobile: false #手机端是否显示 color: \"0,0,0\" #线条颜色 opacity: 0.5 #透明度 zIndex: -1 #z轴坐标 count: 99 #线的数量 NexT主题自带动画canvas_nest或three_waves，根据需求设置值为true或者false即可。 fancybox图片放大12git clone https://github.com/theme-next/theme-next-fancybox3 /themes/next/source/lib/fancybox 在NexT主题配置文件中设置fancybox: true即可。 自定义行内代码样式进入themes/next/source/css/_custom修改custom.styl文件即可。12345678code { color: #c7254e; background: #f9f2f4; border: 1px solid #d6d6d6; padding:1px 4px; word-break: break-all; border-radius:4px;} 百度统计分析 注册百度统计，并新建网站列表。 建立成功后，获取新版统计代码。 将上图中黑色遮挡的ID复制到NexT配置文件,即可开启。 1baidu_analytics: Your Baidu Analytics ID 百度统计的自动代码检测可能检测不到代码装载，可以进行手动检查。 不蒜子阅读量统计在NexT配置文件开启即可。12345678busuanzi_count: enable: true total_visitors: true total_visitors_icon: user total_views: true total_views_icon: eye post_views: true post_views_icon: eye 评论系统ValineNexT已经集成了Valine，在主题的配置文件中就可以找到。Valine是基于LeanCloud的，所以需要先申请LeanCloud。 在LeanCloud创建应用。 获取AppId和AppKey 在NexT主题配置文件找到valine并配置 12345678910111213valine: enable: true #开启 appid: #leancloud appid appkey: #leancloud appkey notify: false #邮件通知,参考:https://github.com/xCss/Valine/wiki verify: false #验证码 placeholder: ヾﾉ≧∀≦)o 来呀！快活呀！~ #placeholder文本 avatar: mm #评论头像，参考:https://valine.js.org/avatar.html guest_info: nick,mail #评论标题，link(网址) pageSize: 10 #每页数量 language: #语言:en, zh-cn visitor: false #阅读量 comment_count: true #true首页显示每篇文章评论数 使用Valine阅读量统计需要注意：leancloud-counter-security is not supported for now. When visitor is set to be true, appid and appkey are recommended to be the same as leancloud_visitors’ for counter compatibility. Article reading statistic 评论效果👇： 最后到此，Hexo和NexT主题配置结束，下一篇文章将介绍markdown编辑器MWeb快速部署Hexo文章，Docker创建Nginx容器，以及七牛云图床申请，ssl证书等设置。","link":"/2019/03/17/Hexo/"},{"title":"FreeMarker指令常用标签及语法","text":"复习FreeMarker，结合网上资料整理了一下常用的指令与语法，以备日后查看。 FreeMarker Template Language(FTL),文件一般保存为xxx.ftl。严格依赖MVC模式，不依赖Servlet容器（不占用JVM内存），使用内建函数。 注意：使用freemaker，要求所有标签必须闭合，否则会导致freemaker无法解析。freemaker注释:&lt;#– 注释内容 –&gt;格式部分,不会输出 基础语法 字符输出 1234${emp.name?if_exists} // 变量存在，输出该变量，否则不输出${emp.name!} // 变量存在，输出该变量，否则不输出${emp.name?default(&quot;xxx&quot;)} // 变量不存在，取默认值xxx ${emp.name!&quot;xxx&quot;} // 变量不存在，取默认值xxx 常用内部函数： 12345${&quot;123&lt;br&gt;456&quot;?html} // 对字符串进行HTML编码，对html中特殊字符进行转义 ${&quot;str&quot;?cap_first} // 使字符串第一个字母大写 ${&quot;Str&quot;?lower_case} // 将字符串转换成小写 ${&quot;Str&quot;?upper_case} // 将字符串转换成大写 ${&quot;str&quot;?trim} // 去掉字符串前后的空白字符 字符串的两种拼接方式拼接： 12$ { “你好$ {emp.name！}”} //输出你好+变量名 $ {“hello”+ emp.name！} //使用+号来连接，输出你好+变量名 可以通过如下语法来截取子串： 12345678&lt;#assign str =“abcdefghijklmn”/&gt;//方法1$ {str?substring（0,4）} //输出abcd//方法2 $ {str[0]}${str[4]} //结果是ae$ {str [1..4]} //结果是bcde//返回指定字符的索引$ {str?index_of（&quot;n&quot;）} 日期输出 1$ {emp.date?string（&apos;yyyy -MM-dd&apos;）} //日期格式 数字输出（以数字20为例） 123456789101112131415161718192021222324252627$ {emp.name?string.number} //输出20 $ {emp.name?string.currency} //¥20.00 $ {emp.name?string.percent} // 20％ $ {1.222？int} //将小数转为int，输出1 &lt;#setting number_format =“percent”/&gt; //设置数字默认输出方式（&apos;percent&apos;，百分比） &lt;#assign answer = 42 /&gt; //声明变量回答42 #{answer} //输出4,200％$ {answer？string} //输出4,200％$ {answer？string.number} //输出42$ {answer？string.currency} //输出¥42.00 $ {answer？string.percent} //输出4,200％#{answer} //输出42 数字格式化插值可采用＃{expr; format}形式来格式化数字，其中格式可以是：mX：小数部分最小X位MX：小数部分最大X位如下面的例子：&lt;#assign x = 2.582 /&gt; &lt;#assign y = 4 /&gt; ＃ {x; M2} //输出2.58 ＃ {y; M2} //输出4 ＃ {x; m2} //输出2.58 ＃{Y; m2} //输出4.0＃ {x; m1M2} //输出2.58 ＃ {x; m1M2} //输出4.0 申明变量 12&lt;#assign foo = false /&gt; //声明变量，插入布尔值进行显示，注意不要用引号$ {foo？string（“yes”，“no”）} //当为真时输出“yes”，否则输出“no” 申明变量的几种方式 1234567891011&lt;#assign name = value&gt; &lt;#assign name1 = value1 name2 = value2 ... nameN = valueN&gt; &lt;#assign same as above... in namespacehash&gt; &lt;#assign name&gt; capture this &lt;/＃assign&gt; &lt;#assign name in namespacehash&gt; capture this &lt;/＃assign&gt; 比较运算算符 12345表达式中支持的比较运算符符如下几个：=或==：判断两个值是否相等。！=：判断两个值是否不等。&gt;或gt：判断左边值是否大于右边值&gt;&lt;=或lte：判断左边值是否小于等于右边值 算术运算符 123456FreeMarker表达式中完全支持算术运算，FreeMarker支持的算术运算符包括：+， - ，*，/，％注意：（1）运算符两边必须是数字（2）使用+运算符时，如果一边是数字，一边是字符串，就会自动将数字转换为字符串再连接， 如：$ {3 +“5”}，结果是：35 逻辑运算符 12345逻辑运算符有如下几个：逻辑与：&amp;&amp; 逻辑或：|| 逻辑非：！逻辑运算符只能作用于布尔值，否则将产生错误 FreeMarker中的运算符优先级如下（由高到低排列）： 123456789①，一元运算符：！②，内建函数：③，乘除法：*，/，％④，加减法： - ，+ ⑤，比较：&gt;，&lt;，&gt; =，&lt;=（lt，lte，gt，gte）⑥，相等：==，=， ！= ⑦，逻辑与：&amp;&amp; ⑧，逻辑或：|| ⑨，数字范围：.. 实际上，我们在开发过程中应该使用括号来严格区分，这样的可读性好，出错少 if逻辑判断（注意：elseif不加空格） 1234567891011121314151617181920&lt;#if condition&gt;...&lt;#elseif condition2&gt;...&lt;#elseif condition3&gt;...&lt;#else&gt;...&lt;/#if&gt;if 空值判断// 当 photoList 不为空时&lt;#if photoList??&gt;...&lt;/#if&gt; 值得注意的是,${..}只能用于文本部分,不能用于表达式,下面的代码是错误的:&lt;#if ${isBig}&gt;Wow!&lt;/#if&gt;&lt;#if &quot;${isBig}&quot;&gt;Wow!&lt;/#if&gt;// 正确写法&lt;#if isBig&gt;Wow!&lt;/#if&gt; switch (条件可为数字，可为字符串) 12345678910111213&lt;#switch value&gt; &lt;#case refValue1&gt; ....&lt;#break&gt; &lt;#case refValue2&gt; ....&lt;#break&gt; &lt;#case refValueN&gt; ....&lt;#break&gt; &lt;#default&gt; .... &lt;/#switch&gt; 集合 &amp; 循环 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// 遍历集合:&lt;#list empList! as emp&gt; ${emp.name!}&lt;/#list&gt;// 可以这样遍历集合:&lt;#list 0..(empList!?size-1) as i&gt; ${empList[i].name!}&lt;/#list&gt;// 与jstl循环类似,也可以访问循环的状态。empList?size // 取集合的长度emp_index: // int类型，当前对象的索引值 emp_has_next: // boolean类型，是否存在下一个对象// 使用&lt;#break&gt;跳出循环&lt;#if emp_index = 0&gt;&lt;#break&gt;&lt;/#if&gt;// 集合长度判断 &lt;#if empList?size != 0&gt;&lt;/#if&gt; // 判断=的时候,注意只要一个=符号,而不是==&lt;#assign l=0..100/&gt; // 定义一个int区间的0~100的集合，数字范围也支持反递增,如100..2&lt;#list 0..100 as i&gt; // 等效于java for(int i=0; i &lt;= 100; i++) ${i}&lt;/#list&gt;// 截取子集合：empList[3..5] //返回empList集合的子集合,子集合中的元素是empList集合中的第4-6个元素// 创建集合：&lt;#list [&quot;星期一&quot;, &quot;星期二&quot;, &quot;星期三&quot;, &quot;星期四&quot;, &quot;星期五&quot;, &quot;星期六&quot;, &quot;星期天&quot;] as x&gt;// 集合连接运算,将两个集合连接成一个新的集合&lt;#list [&quot;星期一&quot;,&quot;星期二&quot;,&quot;星期三&quot;] + [&quot;星期四&quot;,&quot;星期五&quot;,&quot;星期六&quot;,&quot;星期天&quot;] as x&gt;// 除此之外,集合元素也可以是表达式,例子如下:[2 + 2, [1, 2, 3, 4], &quot;whatnot&quot;]// seq_contains：判断序列中的元素是否存在&lt;#assign x = [&quot;red&quot;, 16, &quot;blue&quot;, &quot;cyan&quot;]&gt; ${x?seq_contains(&quot;blue&quot;)?string(&quot;yes&quot;, &quot;no&quot;)} // yes${x?seq_contains(&quot;yellow&quot;)?string(&quot;yes&quot;, &quot;no&quot;)} // no${x?seq_contains(16)?string(&quot;yes&quot;, &quot;no&quot;)} // yes${x?seq_contains(&quot;16&quot;)?string(&quot;yes&quot;, &quot;no&quot;)} // no// seq_index_of：第一次出现的索引&lt;#assign x = [&quot;red&quot;, 16, &quot;blue&quot;, &quot;cyan&quot;, &quot;blue&quot;]&gt; ${x?seq_index_of(&quot;blue&quot;)} // 2// sort_by：排序（升序）&lt;#list movies?sort_by(&quot;showtime&quot;) as movie&gt;&lt;/#list&gt;// sort_by：排序（降序）&lt;#list movies?sort_by(&quot;showtime&quot;)?reverse as movie&gt;&lt;/#list&gt;// 具体介绍：// 不排序的情况：&lt;#list movies as moive&gt; &lt;a href=&quot;${moive.url}&quot;&gt;${moive.name}&lt;/a&gt;&lt;/#list&gt;//要是排序，则用&lt;#list movies?sort as movie&gt; &lt;a href=&quot;${movie.url}&quot;&gt;${movie.name}&lt;/a&gt;&lt;/#list&gt;// 这是按元素的首字母排序。若要按list中对象元素的某一属性排序的话，则用&lt;#list moives?sort_by([&quot;name&quot;]) as movie&gt; &lt;a href=&quot;${movie.url}&quot;&gt;${movie.name}&lt;/a&gt;&lt;/#list&gt;//这个是按list中对象元素的[name]属性排序的，是升序，如果需要降序的话，如下所示：&lt;#list movies?sort_by([&quot;name&quot;])?reverse as movie&gt; &lt;a href=&quot;${movie.url}&quot;&gt;${movie.name}&lt;/a&gt;&lt;/#list&gt; Map对象 12345678910// 创建map&lt;#assign scores = {&quot;语文&quot;:86,&quot;数学&quot;:78}&gt;// Map连接运算符&lt;#assign scores = {&quot;语文&quot;:86,&quot;数学&quot;:78} + {&quot;数学&quot;:87,&quot;Java&quot;:93}&gt;// Map元素输出${emp.name} // 全部使用点语法${emp[&quot;name&quot;]} // 使用方括号循环//遍历集合：&lt;＃list empList！as emp&gt; $ {emp.name！} FreeMarker支持如下转义字符: 1234567891011121314151617\\&quot; ：双引号(u0022)\\&apos; ：单引号(u0027)\\\\ ：反斜杠(u005C)\\n ：换行(u000A)\\r ：回车(u000D)\\t ：Tab(u0009)\\b ：退格键(u0008)\\f ：Form feed(u000C)\\l ：&lt;\\g ：&gt;\\a ：&amp;\\{ ：{\\xCode ：直接通过4位的16进制数来指定Unicode码,输出该unicode码对应的字符.如果某段文本中包含大量的特殊符号,FreeMarker提供了另一种特殊格式:可以在指定字符串内容的引号前增加r标记,在r标记后的文件将会直接输出.看如下代码:${r&quot;${foo}&quot;} // 输出 ${foo}${r&quot;C:/foo/bar&quot;} // 输出 C:/foo/bar include指令 1234567// include指令的作用类似于JSP的包含指令:&lt;#include &quot;/test.ftl&quot; encoding=&quot;UTF-8&quot; parse=true&gt;// 在上面的语法格式中,两个参数的解释如下:encoding=&quot;GBK&quot; // 编码格式parse=true // 是否作为ftl语法解析,默认是true，false就是以文本方式引入注意:在ftl文件里布尔值都是直接赋值的如parse=true,而不是parse=&quot;true&quot; import指令 123// 类似于jsp里的import,它导入文件，然后就可以在当前文件里使用被导入文件里的宏组件&lt;#import &quot;/libs/mylib.ftl&quot; as my&gt;// 上面的代码将导入/lib/common.ftl模板文件中的所有变量,交将这些变量放置在一个名为com的Map对象中，&quot;my&quot;在freemarker里被称作namespace compress 压缩 1234567891011// 用来压缩空白空间和空白的行 &lt;#compress&gt; ... &lt;/#compress&gt;&lt;#t&gt; // 去掉左右空白和回车换行 &lt;#lt&gt;// 去掉左边空白和回车换行 &lt;#rt&gt;// 去掉右边空白和回车换行 &lt;#nt&gt;// 取消上面的效果 escape,noescape 对字符串进行HTML编码 123456789101112// escape指令导致body区的插值都会被自动加上escape表达式,但不会影响字符串内的插值, 只会影响到body内出现的插值,使用escape指令的语法格式如下:&lt;#escape x as x?html&gt; First name: ${firstName} &lt;#noescape&gt;Last name: ${lastName}&lt;/#noescape&gt; Maiden name: ${maidenName} &lt;/#escape&gt;// 相同表达式First name: ${firstName?html} Last name: ${lastName} Maiden name: ${maidenName?html} 配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950spring.freemarker.allow-request-override指定HttpServletRequest的属性是否可以覆盖controller的model的同名项spring.freemarker.allow-session-override指定HttpSession的属性是否可以覆盖controller的model的同名项spring.freemarker.cache是否开启template caching.spring.freemarker.charset设定Template的编码.spring.freemarker.check-template-location是否检查templates路径是否存在.spring.freemarker.content-type设定Content-Type.spring.freemarker.enabled是否允许mvc使用freemarker.spring.freemarker.expose-request-attributes设定所有request的属性在merge到模板的时候，是否要都添加到model中.spring.freemarker.expose-session-attributes设定所有HttpSession的属性在merge到模板的时候，是否要都添加到model中.spring.freemarker.expose-spring-macro-helpers设定是否以springMacroRequestContext的形式暴露RequestContext给Spring’s macro library使用spring.freemarker.prefer-file-system-access是否优先从文件系统加载template，以支持热加载，默认为truespring.freemarker.prefix设定freemarker模板的前缀.spring.freemarker.request-context-attribute指定RequestContext属性的名.spring.freemarker.settings设定FreeMarker keys.spring.freemarker.suffix设定模板的后缀.spring.freemarker.template-loader-path设定模板的加载路径，多个以逗号分隔，默认: [&quot;classpath:/templates/&quot;]spring.freemarker.view-names指定使用模板的视图列表.","link":"/2019/03/03/FreeMarker/"},{"title":"MyBatis-Plus","text":"在整理MyBatis时候，Mybatis的逆向工程的xml实在懒得写，找代码生成器的时候听说了MyBatis-Plus，看了看官方文档，代码生成器深得我心，对照文档学习了下，感觉效率比MyBatis提升不少。 简介MyBatis-Plus（以下简称MP）是一个MyBatis的增强工具，在MyBatis的基础上只做增强不做改变，为简化开发、提高效率而生。 特性 无侵入：只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑 损耗小：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作 强大的 CRUD 操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求 支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错 支持主键自动生成：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题 支持 ActiveRecord 模式：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作 支持自定义全局通用操作：支持全局通用方法注入（ Write once, use anywhere ） 内置代码生成器：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用 内置分页插件：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询 分页插件支持多种数据库：支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer2005、SQLServer 等多种数据库 内置性能分析插件：可输出 Sql 语句以及其执行时间，建议开发测试时启用该功能，能快速揪出慢查询 内置全局拦截插件：提供全表 delete 、 update 操作智能分析阻断，也可自定义拦截规则，预防误操作 代码生成器详细配置参数详见代码生成器配置，以下为我的 常用的配置。 六种ConfigDataSourceConfig 数据源配置12345678DataSourceConfig dataSource = new DataSourceConfig();dataSource.setUrl(\"jdbc:mysql://**:**/***?useUnicode=true&amp;characterEncoding=utf-8\") .setDriverName(\"com.mysql.jdbc.Driver\") .setUsername(\"**\") .setPassword(\"**\") //.setSchemaName(\"public\")//可以在Url中设置 //.setTypeConvert()//自定义类型转换（决定对应数据库内置实现） .setDbType(DbType.MYSQL);//数据库类型 MP内置的类型转换在：com.baomidou.mybatisplus.generator.config.converts，默认提供5种数据库：以MySql为例可以看到数据库对应类型与Java类型的对应：因为jdk1.8引入java.time.*新api，在日期的转换上有个通过GlobalConfig(全局配置)的参数，可以指定数据库日期类型对应的java类型转换。 StrategyConfig 策略配置123456789StrategyConfig strategy = new StrategyConfig();strategy.setNaming(NamingStrategy.underline_to_camel)//表名映射规则 .setColumnNaming(NamingStrategy.underline_to_camel)//字段名映射规则 .setEntityLombokModel(false)//【实体】是否为lombok模型（默认 false) .setEntityTableFieldAnnotationEnable(true)//实体生成字段注解 .setTablePrefix(\"test_\")//表名前缀 .setRestControllerStyle(true)//生成 @RestController 控制器 //.setExclude() .setInclude(tableNames);//需要包含的表名，允许正则表达式（与exclude二选一配置)，参数String...tablename NamingStrategy.underline_to_camel下划线转驼峰，NamingStrategy.no_change不做任何改变，原样输出。详细配置见这里 PackageConfig 包配置123456789PackageConfig pac = new PackageConfig();pac.setModuleName(modelName)//modelName .setParent(\"com.mkcorden.bootmybatisplus\")//父包名。如果为空，将下面子包名必须写全部， 否则就只需写子包名 .setController(\"controller\") .setService(\"service\") .setServiceImpl(\"service.impl\") .setMapper(\"mapper\") .setEntity(\"domain\") .setXml(\"mapper\"); 包配置时候如果要按照模块进行生成区分，一定设置modelName。ServiceImpl设置二级的目录需要注意。 TemplateConfig 模版配置1234567TemplateConfig templateConfig = new TemplateConfig();// 配置自定义输出模板// 指定自定义模板路径，注意不要带上.ftl/.vm, 会根据使用的模板引擎自动识别// templateConfig.setEntity(\"templates/entity2.java\");// templateConfig.setService();// templateConfig.setController();templateConfig.setXml(null); 因为静态的xml文件一般生成在resources目录下，但是按上面的包配置，.xml的mapper会直接生成在modelName/mapper/*下，在TemplateConfig下设置xml为null，则可以不输出xml文件，然后用自定义配置进行对应输出。 设置Null不输出： com.baomidou.mybatisplus.generator.config.builder.ConfigBuilder中，template.getXml()为Null，不会设置pathInfo(HashMap)中Key:xml_path的value。 在com.baomidou.mybatisplus.generator.engine.AbstractTemplateEngine的batchOutput()方法,pathInfo.get(ConstVal.XML_PATH)为null，所以不进行xml文件的输出。 GlobalConfig 全局配置12345678910111213141516GlobalConfig gc = new GlobalConfig();gc.setFileOverride(false)//文件是否覆盖上一次 .setActiveRecord(false)// 开启 activeRecord 模式 .setEnableCache(true)// XML 二级缓存 .setBaseResultMap(true)// XML ResultMap .setBaseColumnList(true)// XML columList基本的Sql片段 .setOutputDir(System.getProperty(\"user.dir\")+\"/src/main/java\") .setAuthor(\"MkCorden\") .setServiceName(\"%sService\") .setServiceImplName(\"%sServiceImpl\") .setControllerName(\"%sController\") .setMapperName(\"%sDao\") .setXmlName(\"%sDao\") .setIdType(IdType.UUID) .setOpen(false) .setDateType(DateType.ONLY_DATE);//日期类型字段对应的转换模式 %s是占位符 DateType有三种 ONLY_DATE 只使用 java.util.date 代替 SQL_PACK 使用 java.sql 包下的 TIME_PACK 使用 java.time 包下的 InjectionConfig 自定义配置1234567891011121314151617181920212223InjectionConfig cfg = new InjectionConfig() { @Override public void initMap() { //TODO }}; // 自定义输出配置List&lt;FileOutConfig&gt; focList = new ArrayList&lt;&gt;();//String projectPath = System.getProperty(\"user.dir\");// 自定义配置会被优先输出focList.add(new FileOutConfig(\"/templates/mapper.xml.ftl\") { @Override public String outputFile(TableInfo tableInfo) { //首字母小写 char[] cs = tableInfo.getEntityName().toCharArray(); cs[0] += 32; // 自定义输出文件名 ， 如果你 Entity 设置了前后缀、此处注意 xml 的名称会跟着发生变化！！ return System.getProperty(\"user.dir\") + \"/src/main/resources/mapper/\" + String.valueOf(cs) + \"/\" + tableInfo.getEntityName() + \"Dao\" + StringPool.DOT_XML; }});cfg.setFileOutConfigList(focList); /templates/mapper.xml.ftl默认模版路径 与Druid集成问题 在Druid 1.1.19版本已经解决 使用Druid旧版本连接池，在使用MP代码生成器将时间类型字段映射到jdk1.8的java.time.*时，进行数据库操作对应字段会报java.sql.SQLFeatureNotSupportedException，原因具体issue见 druid:3393 / mybatis-plus:1245，解决办法又两个： 在MP的GlobalConfig中设置.setDateType(DateType.ONLY_DATE)，强制把所有时间类型转换为Date。 将MP版本将到3.1.0即可。 因为在MP ver.3.1.1加入了分布式事务特性，再一个使用新的时间格式会造成不可知的其他第三方插件不支持，综上我选第一种，哈哈。 注解使用MP自带代码生成器生成的Domain类会有@TableName @TableId @TableField注解。同时MP也提供了如@Version（乐观锁中代表版本）@TableLogic（逻辑删除中使用)，下面简单介绍几个注解，详细请参考官网文档 @TableName12@TableName(value = \"test_subject\",resultMap = \"BaseResultMap\")public class Subject implements Serializable { value：指定数据库中的表名 resultMap：指定xml中ResultMap的id keepGlobalPrefix： false（默认）：如果是 false , 全局的 tablePrefix 不生效 @TableId12@TableId(value = \"subject_id\", type = IdType.AUTO)private Long subjectId; 用于注解主键对应的属性值 value：指定主键字段名 type：指定主键的类型 AUTO：数据库自增 INPUT：自行输入 ID_WORKER：分布式全局唯一ID 长整型类型 UUID：32位UUID字符串 NONE：无状态 ID_WORKER_STR：分布式全局唯一ID 字符串类型 @TableField12@TableField(value = \"sup_subject_id\", fill = FieldFill.INSERT)private String supSubjectId; 用于注解除主键以外其他属性 value：指定对应数据库字段名 fill：自动填充策略 DEFAULT：默认不处理 INSERT：插入时填充字段 UPDATE：更新时填充字段 INSERT_UPDATE：插入和更新时填充字段 其他配置见官方文档 （公共字段）默认填充使用默认填充特性，首先要在@TableField注解内配置fill属性，然后需要实现MetaObjectHandler接口，进行自定义自动填充时候的赋值。 注意：当字段不为空时，默认填充的值会覆盖原有值。可以在填充时候进行判断，不为空时候进行填充（有点像数据库默认值），但是不建议这么做。因为每次insert和update操作都会执行我们实现的接口，所以该特性最好用于公共字段的默认填充。 12345678910111213141516171819202122232425@Componentpublic class MyMetaObjectHandler implements MetaObjectHandler { /** * 插入元对象字段填充（用于插入时对公共字段的填充） * * @param metaObject 元对象 */ @Override public void insertFill(MetaObject metaObject) { System.out.println(\"-----------------插入方法实体填充INSERT----------------\"); setFieldValByName(\"classOverDate\", LocalDate.now().plusDays(60), metaObject); setFieldValByName(\"supSubjectId\", \"-1\", metaObject); } /** * 更新元对象字段填充（用于更新时对公共字段的填充） * * @param metaObject 元对象 */ @Override public void updateFill(MetaObject metaObject) { System.out.println(\"-----------------插入方法实体填充UPDATE----------------\"); setFieldValByName(\"classOverDate\", LocalDate.now().plusDays(70), metaObject); }} 分页插件分页时候如果设置pageSize = -1则不进行分页，如果要进行排序分页，传参数时，将排序条件封装即可，MP在Page对象中已经封装好了1234 /** * 排序字段信息 */private List&lt;OrderItem&gt; orders = new ArrayList&lt;&gt;(); 12345678910public class OrderItem { /** * 需要进行排序的字段 */ private String column; /** * 是否正序排列，默认 true */ private boolean asc = true; 请求： 具体使用 配置 12345678910/** * 分页插件 */@Beanpublic PaginationInterceptor paginationInterceptor() { PaginationInterceptor paginationInterceptor = new PaginationInterceptor(); //你的最大单页限制数量，默认 500 条，小于 0 如 -1 不受限制 // paginationInterceptor.setLimit(500); return paginationInterceptor;} 使用 1234567891011121314 /** * 分页 * @return */@GetMapping(\"students/page\")public ResponseEntity searchByPage(Page&lt;Student&gt; student_page, boolean listMode){ if (listMode) { // size 小于 0 不在查询 total 及分页，自动调整为列表模式。 // 注意！！这个地方自己控制好！！ student_page.setSize(-1); } IPage&lt;Student&gt; pageStudent = studentService.page(student_page); return ResponseUtil.pageSuccess(pageStudent.getTotal(),pageStudent.getRecords());} 性能分析器12345678@Bean//@Profile({\"dev\",\"test\"})// 设置 dev test 环境开启public PerformanceInterceptor performanceInterceptor() { PerformanceInterceptor performanceInterceptor = new PerformanceInterceptor(); performanceInterceptor.setMaxTime(1000);// 最大执行时间 performanceInterceptor.setFormat(true);// sql是否格式化 return performanceInterceptor;} 控制台效果： 默认接口CURD通过MP的代码构造器生成的Service和Dao文件，已经默认继承了com.baomidou.mybatisplus.extension.service.impl.ServiceImpl和com.baomidou.mybatisplus.core.mapper.BaseMapper,在这两文件中MP已经默认帮我们实现了一些CRUD方法。 Mapper CURD接口在启动时会自动解析实体表关系映射转换为Mybatis内部对象注入容器。 Service CRUD接口进一步封装CRUD，采用get查询单行remove删除list查询集合page分页，前缀命名方式区分Mapper层避免混淆。 业务ServiceImpl继承了MP的ServiceImpl，并注入到Controller层，所以在Controller层，对于简单的业务，可以直接调用对应方法进行返回。 条件构造器Wrapper因为使用Jdk1.8，支持lambda表达式，主要是用各种LambdaWrapper。对于在RPC模式中，不建议传输Wrapper，因为Wrapper很重。正确的方式是封装DTO进行传输，在接收端根据接收到的DTO进行相应的操作。 使用中如果入参的Map或者List为空,则不会加入最后生成的sql中!!! LambdaQueryWrapper123456789@GetMapping(\"students/search\")public ResponseEntity searchByCondition(@ModelAttribute StudentModel student_model){ //最好使用LambdaQueryWrapper,这样可以通过Student::getTrueName方式获取数据库字段名 //使用正常的QueryWrapper，需要写死字段名如\"true_name\"才可以 return ResponseUtil.success(studentService.list(new QueryWrapper&lt;Student&gt;() .lambda() .like(Student::getTrueName,student_model.getTrueName()) .between(Student::getBirthday,student_model.getBeginDate(),student_model.getEndDate())));} 上面代码中Student::getBirthday，Student为实体类，getBirthday是birthday字段的getMethod 通过QueryWrapper的.lambda()方法转换为LambdaQueryWrapper，这样可以不用将字段名写死，因为MP在处理LambdaQueryWrapper时候会通过columnToString()来转换为数据库中的字段名。 如果不能使用Lambda特性，指定字段时候，一定要写数据库中的字段名。不要写实体类的属性名。 LambdaUpdateWrapper跟QueryWrapper相似，需要注意的点是，在设置SET时候，要进行非空判断（最好直接使用已经封装的UpdateByID），因为： 例: set(“name”, “”)—&gt;数据库字段值变为空字符串 例: set(“name”, null)—&gt;数据库字段值变为null SQL注入器 与 分表分库待完成… 总结Mybatis-Plus的诸多特性，在开发中大大减少了无意义Coding的时间，同时也带来了一些不确定性，和少量的学习成本。本文学习过程中的代码已将上传到GitHub上，链接在这——&gt;","link":"/2019/08/13/MabtisPlus/"},{"title":"要了命的版本Druid/Mybatis/MybatisPlus","text":"问题现象Druid是alibaba的一款开源数据库连接池。被称为是专门为监控而生的数据库连接池配置，他可以监控sql的执行情况，以及性能，然后根据结果来优化sql或者做性能调优。 之前自己写项目时候没有用到Druid的监控功能。昨天试了试监控功能就出现了如下错误：java.sql.SQLFeatureNotSupportedException,主要是使用了LocalDateTime类型对应了数据库的timestamp类型字段引发的问题，java8新的时间类都会引发如下问题。 当前使用版本的是Mybatis-Plus 3.1.2和druid 1.1.20。 在Mybatis-Plus的3.1.1及之后的版本中，引用的mybatis版本为3.5.1。 在没有启动Druid的监控模块时候druid 1.1.19及以上版本支持mybatis 3.5.1，java8新的时间类型对应数据库时间类型都正常。 原因因为mybatis 3.5.1版本对于java.time包下LocalDateTime,LocalDate,LocalTime类型的转换交由了JDBC，若JDBC组件不支持对于LocalDateTime类型的处理则会报错。Druid数据库连接池，在最新版本中尚不支持对于LocalDateTime的处理，会throw SQLFeatureNotSupportedException，提请注意。 解决方式降低mybatis版本Mybatis-Plus使用3.1.0及以下版本12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt;&lt;/dependency&gt; Mybatis使用mybatis 3.5.0及以下版本 mybatis-spring-boot-starter 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt; mybatis 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.0&lt;/version&gt;&lt;/dependency&gt; 更换连接池更换为 hicaricp 3.3.1，并将jdbc换为最新的 附录Druid配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879spring: datasource: druid: url: jdbc:mysql://localhost:3306/videomall?useUnicode=true&amp;characterEncoding=utf-8&amp;serverTimezone=Asia/Shanghai username: root password: root driver-class-name: com.mysql.cj.jdbc.Driver # 初始化时建立物理连接的个数。初始化发生在显示调用init方法，或者第一次getConnection时，默认0 initial-size: 3 # 最大连接池数量，默认8 max-active: 5 # 最小连接池数量 min-idle: 1 # 获取连接时最大等待时间，单位毫秒。配置了maxWait之后，缺省启用公平锁，并发效率会有所下降 # 如果需要可以通过配置useUnfairLock属性为true使用非公平锁 max-wait: 30000 # 是否缓存preparedStatement，也就是PSCache # PSCache对支持游标的数据库性能提升巨大，比如说oracle。在mysql下建议关闭。默认false pool-prepared-statements: false # 要启用PSCache，必须配置大于0，当大于0时，poolPreparedStatements自动触发修改为true # 在Druid中，不会存在Oracle下PSCache占用内存过多的问题，可以把这个数值配置大一些，比如说100，默认-1 max-pool-prepared-statement-per-connection-size: 100 # 用来检测连接是否有效的sql，要求是一个查询语句，常用select 'x' # 如果validationQuery为null，testOnBorrow、testOnReturn、testWhileIdle都不会起作用 validation-query: SELECT 1 # 单位：秒，检测连接是否有效的超时时间。底层调用jdbc Statement对象的void setQueryTimeout(int seconds)方法 validation-query-timeout: 30000 # 申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能，默认true test-on-borrow: true # 归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能，默认false test-on-return: true # 申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效 # 建议配置为true，不影响性能，并且保证安全性，默认false test-while-idle: true # 连接池中的minIdle数量以内的连接，空闲时间超过minEvictableIdleTimeMillis，则会执行keepAlive操作，默认false keep-alive: true # 有两个含义： # 1) Destroy线程会检测连接的间隔时间，如果连接空闲时间大于等于minEvictableIdleTimeMillis则关闭物理连接 # 2) testWhileIdle的判断依据，详细看testWhileIdle属性的说明 # 默认1分钟 time-between-eviction-runs-millis: 60000 # 连接保持空闲而不被驱逐的最小时间 min-evictable-idle-time-millis: 300000 filters: stat,wall filter: stat: log-slow-sql: true slow-sql-millis: 2000 # WebStatFilter配置，说明请参考Druid Wiki，配置_配置WebStatFilter web-stat-filter: # 1.1.10以后的版本需要指定为true 不然默认是关闭的就会出现404 enabled: true # 添加过滤规则 url-pattern: /* # 忽略过滤格式 exclusions: \"*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*\" # StatViewServlet配置 stat-view-servlet: #展示Druid的统计信息,StatViewServlet的用途包括：1.提供监控信息展示的html页面2.提供监控信息的JSON API #是否启用StatViewServlet默认值true enabled: true #根据配置中的url-pattern来访问内置监控页面，如果是上面的配置，内置监控页面的首页是/druid/index.html例如： #http://110.76.43.235:9000/druid/index.html #http://110.76.43.235:8080/mini-web/druid/index.html url-pattern: /druid/* #是否允许清空统计数据 reset-enable: false login-username: admin login-password: admin #StatViewSerlvet展示出来的监控信息比较敏感，是系统运行的内部情况，如果你需要做访问控制，可以配置allow和deny这两个参数 #deny优先于allow，如果在deny列表中，就算在allow列表中，也会被拒绝。如果allow没有配置或者为空，则允许所有访问 #配置的格式 #&lt;IP&gt; #或者&lt;IP&gt;/&lt;SUB_NET_MASK_size&gt;其中128.242.127.1/24 #24表示，前面24位是子网掩码，比对的时候，前面24位相同就匹配,不支持IPV6。 allow: deny: 128.242.127.1/24,128.242.128.1 # Spring监控AOP切入点，如x.y.z.service.*,配置多个英文逗号分隔 aop-patterns:","link":"/2019/09/11/DruidMybatisMybatisPlusVersion/"},{"title":"初遇Redis","text":"什么是Redis讲到redis不得不讲NoSql NoSQL是不同于传统的关系数据库的数据库管理系统的统称。其两者最重要的区别是NoSQL不使用SQL作为查询语言。 NoSQL数据存储可以不需要固定的表格模式。NoSQL是基于键值对的，可以想象成表中的主键和值的对应关系。 NoSQL：redis、memcached、mongodb、guava（loadingCache） Redis是什么Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多 种类型的数据结构，如 字符串（strings）、散列（hashes）、 列表（lists）、 集合（sets）、 有序集合（sorted sets）等。 对比Mysql关系型数据库的一个常见用法是存储长期的报告数据，并将这些报告数据用作固定时间范围内的聚合数据。收集聚合数据的常见做法是：先将各个行插入一个报告表里面， 之后再通过扫描这些行来收集聚合数据， 并更新聚合表中巳有的那些行。先来看看Mysql的执行流程图： 添加索引是在最后一步：执行引擎中发挥作用。 当执行查询时，命中缓存Cache时候，才是最快的。而Redis是一个内存缓存工具，可以通过内存返回数据结果，不用进行表查询，效率是最高的。因为磁盘计算是远远比不上内存计算的。磁盘是要进行一个全表扫描，数据是持久化的。 对比Memcached内存管理机制 Memcached默认使用Slab Allocation机制管理内存，其主要思想是按照预先规定的大小， 将分配的内存分割成特定长度的块 以存储相应长度的key-value数据记录，以完全解决内存碎 片问题。空闲列表进行判断存储状态,【类似于Java虚拟机对象的分配，空闲列表】 Redis使用现场申请内存的方式来存储数据，并且很少使用free-list等方式来优化内存分配，会在一定程度上存在内存碎片,【CPU内存是连续，类似于Java虚拟机对象的分配，直接内存分配（指针碰撞）】 Memcached个人感觉就是将内存碎片变成了内存的浪费。 redis作者可能为了更高的性能，所以在redis中实现了自己的内存分配器来管理内存，不会马上返还内存，不用每次都向OS申请了，从而实现高性能。但是redis的每个k-v对初始化的内存大小是最适合的，当这个value改变的并且原来内存大小不适用的时候，就需要重新分配内存了。（但是value存比原来小不知道会不会产生碎片）。重新分配之后，就会有一部分内存redis无法正常回收，一直占用着。解决方案： 重启redis服务，简单粗暴。 4.0以后清理：（自动）redis-cli -p 6379 config set activedefrag yes 4.0以后清理：（手动）redis-cli -p 6379 memory purge 数据持久化方案 memcached不支持内存数据的持久化操作，所有的数据都以in-memory的形式存储。 redis支持持久化操作。redis提供了两种不同的持久化方法来讲数据存储到硬盘里面， 第一种是rdb形式，一种是aof形式 rdb：属于全量数据备份，备份的是数据 aof：append only if,增量持久化备份，备份的是指令 缓存数据过期机制 概念：key，设计一个小时之后过期，超过一个小时查数据就会查不到 Memcached 在删除失效主键时也是采用的消极方法，即 Memcached 内部也不会监视主键是否失效，而是在通过 Get 访问主键时才会检查其是否已经失效 Redis 定时、定期等多种缓存失效机制，减少内存泄漏 支持的数据类型 Memcached支持单一数据类型,[k,v] redis支持五种数据类型 Redis数据类型操作Key/Value类型简介： String是最常用的一种数据类型，普通的key/value存储都可以归为此类。 set/get 设置key对应的值为String类型的value 获取key对应的值 mget 批量获取多个key的值，如果可以不存在则返回nil incr &amp;&amp; incrby incr对key对应的值进行加加操作，并返回新的值;incrby加指定值 incr &amp;&amp; incrby incr对key对应的值进行加加操作，并返回新的值;incrby加指定值 setnx 设置key对应的值为String类型的value，如果key已经存在则返回0 setex 设置key对应的值为String类型的value，并设定有效期 其他命令 getrange 获取key对应value的子字符串 mset 批量设置多个key的值，如果成功表示所有值都被设置，否则返回0表示没有任何值被设置 msetnx，同mset，不存在就设置，不会覆盖已有的key getset 设置key的值，并返回key旧的值 append：给指定key的value追加字符串，并返回新字符串的长度 Hash类型 Hash是一个String类型的field和value之间的映射表 redis的Hash数据类型的key（hash表名称）对应的value实际的内部存储结构为一个HashMap Hash特别适合存储对象 相对于把一个对象的每个属性存储为String类型，将整个对象存储在Hash类型中会占用更少内存。 所存储的成员较少时数据存储为zipmap，当成员数量增大时会自动转成真正的HashMap,此时encoding为ht。 运用场景： 如用一个对象来存储用户信息，商品信息，订单信息等等。 Hash命令讲解 hset——设置key对应的HashMap中的field的value hget——获取key对应的HashMap中的field的value hgetall——获取key对应的HashMap中的所有field的value hlen–返回key对应的HashMap中的field的数量 List类型 lpush——在key对应的list的头部添加一个元素 lrange——获取key对应的list的指定下标范围的元素，-1表示获取所有元素 lpop——从key对应的list的尾部删除一个元素，并返回该元素 rpush——在key对应的list的尾部添加一个元素 rpop——从key对应的list的尾部删除一个元素，并返回该元素 Set类型 sadd——在key对应的set中添加一个元素 smembers——获取key对应的set的所有元素 spop——随机返回并删除key对应的set中的一个元素 suion——求给定key对应的set并集 sinter——求给定key对应的set交集 SortSet类型简介：set的基础增加顺序score，再根据score进行排序 实战：通过sortset实现排行榜 zadd ——在key对应的zset中添加一个元素 zrange——获取key对应的zset中指定范围的元素，-1表示获取所有元素 zrem——删除key对应的zset中的一个元素 zrangebyscore——返回有序集key中，指定分数范围的元素列表,排行榜中运用 zrank——返回key对应的zset中指定member的排名。其中member按score值递增(从小到大）； 排名以0为底，也就是说，score值最小的成员排名为0,排行榜中运用 Set与SortSet set是通过hashmap存储，key对应set的元素，value是空对象 sortset是怎么存储并实现排序的呢，hashmap存储，还加了一层跳跃表 跳跃表：相当于双向链表，在其基础上添加前往比当前元素大的跳转链接","link":"/2019/06/15/RedisFirstEncounter/"},{"title":"Redis(单机)安装部署，与SpringBoot整合(有redis配置详解)","text":"了解了Redis相关基础知识后，本文介绍了如何在Linux中用Docker快速搭建Redis服务（单机），并与SpringBoot进行整合。使用RedisTemplate进行redis的相关操作。 通过Docker安装RedisRedis版本5.0.5SpringBoot版本2.0.4 准备配置文件如果要自定义启动docker的Redis容器，需要去官网下载对应版本的配置文件redis.conf进行更改,以下是docker下更改的单机版配置文件内容。123456789101112daemonize no #docker设置为yes无法启动#安全情况的几个特殊配置：requirepass 123456protected-mode yesbind 0.0.0.0#免密情况：#bind 0.0.0.0#protected-mode noport 6379appendonly yesappendfsync everysec Docker部署拉取对应版本镜像1docker pull redis:5.0.5 创建容器123456789docker run -d -it --privileged=true -v /media/psf/Linux/df/redis/config/redis6.conf:/etc/redis/redis.conf --privileged=true -v /var/df/cluster-redis/data:/data --restart always --name redis5.0.5 --net=host --sysctl net.core.somaxconn=1024 redis-cluster:5.0.5 redis-server /etc/redis/redis.conf 查看镜像运行情况1docker ps 通过rdm连接命令测试 Spring Data Redis与JedisJedisJedis是redis的java客户端，通过它可以对redis进行操作。 与之功能相似的还包括：Lettuce等。 Spring Data Redis它依赖jedis或Lettuce，实际上是对jedis这些客户端的封装，提供一套与客户端无关的api供应用使用，从而你在从一个redis客户端切换为另一个客户端，不需要修改业务代码。spring-boot-data-redis 内部实现了对Lettuce和jedis两个客户端的封装，默认使用的是Lettuce。 连接包作为多个Redis驱动程序（Lettuce和Jedis）的低级抽象。 异常翻译到Spring的便携式数据访问异常层次结构Redis的驱动程序例外。 RedisTemplate，提供高级抽象，用于执行各种Redis操作，异常转换和序列化支持。 Pubsub支持（例如消息驱动的POJO的MessageListenerContainer）。 Redis Sentinel和Redis Cluster支持。 使用Lettuce驱动程序的Reactive API。 JDK，String，JSON和Spring Object / XML映射序列化程序。 在Redis之上的JDK Collection实现。 原子计数器支持课程。 排序和流水线功能。 专门支持SORT，SORT / GET模式和返回的批量值。 Redis 实现了Spring 3.1缓存抽象。 自动实现Repository接口，包括支持自定义查询方法@EnableRedisRepositories。 CDI对存储库的支持。 SpringBoot整合单机版redis使用redisTemplate进行交互 pom.xml依赖新版本：在新版本中spring-boot-starter-redis移除了jedis依赖，因为我们要使用到jedis提供的jedispool，所以要追加引入jedis包12345678910&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt; &lt;version&gt;2.1.8.RELEASE&lt;/version&gt;&lt;/dependency&gt; 旧版本：12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt; &lt;version&gt;2.1.8.RELEASE&lt;/version&gt;&lt;/dependency&gt; 添加配置文件1234567891011121314spring: redis: host: 10.211.55.15 port: 6379 password: 123456 database: 0 timeout: 10000 ssl: false jedis: pool: max-active: 10 max-wait: 10000 max-idle: 10 min-idle: 0 创建RedisConfig1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586@Configurationpublic class RedisConfig { @Value(\"${spring.redis.database}\") private int database; @Value(\"${spring.redis.host}\") private String host; @Value(\"${spring.redis.port}\") private int port; @Value(\"${spring.redis.password}\") private String password; @Value(\"${spring.redis.timeout}\") private int timeout; @Value(\"${spring.redis.jedis.pool.max-active}\") private int maxActive; @Value(\"${spring.redis.jedis.pool.max-idle}\") private int maxIdle; @Value(\"${spring.redis.jedis.pool.min-idle}\") private int minIdle; @Value(\"${spring.redis.jedis.pool.max-wait}\") private long maxWaitMillis; @Value(\"${spring.redis.ssl}\") private boolean ssl; @Bean public RedisConnectionFactory redisConnectionFactory(){ RedisStandaloneConfiguration redisConfig = new RedisStandaloneConfiguration(); redisConfig.setHostName(host); redisConfig.setPort(port); redisConfig.setPassword(RedisPassword.of(password)); redisConfig.setDatabase(database); //设置连接池 JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxIdle(maxIdle); jedisPoolConfig.setMinIdle(minIdle); jedisPoolConfig.setMaxWaitMillis(maxWaitMillis); // 连接耗尽时是否阻塞, false报异常,ture阻塞直到超时, 默认true jedisPoolConfig.setBlockWhenExhausted(true); // 是否启用pool的jmx管理功能, 默认true jedisPoolConfig.setJmxEnabled(true); JedisClientConfiguration jedisClientConfiguration; if(ssl){ jedisClientConfiguration = JedisClientConfiguration.builder() .usePooling().poolConfig(jedisPoolConfig) .and().readTimeout(Duration.ofMillis(timeout)) .useSsl().build(); }else{ jedisClientConfiguration = JedisClientConfiguration.builder() .usePooling().poolConfig(jedisPoolConfig).build(); } return new JedisConnectionFactory(redisConfig,jedisClientConfiguration); } @Bean public RedisTemplate&lt;String,String&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory){ RedisTemplate&lt;String,String&gt; redisTemplate = new RedisTemplate&lt;String,String&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory); RedisSerializer&lt;Object&gt; serializer = getRedisSerializer(); //设置序列化器 redisTemplate.setDefaultSerializer(serializer); redisTemplate.setKeySerializer(serializer); redisTemplate.setValueSerializer(serializer); redisTemplate.setHashKeySerializer(serializer); redisTemplate.setHashValueSerializer(serializer); //开启事务 redisTemplate.setEnableTransactionSupport(true); redisTemplate.afterPropertiesSet(); return redisTemplate; } /** * Redis序列化方式 * @return */ private RedisSerializer getRedisSerializer(){ Jackson2JsonRedisSerializer&lt;Object&gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer&lt;&gt;(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); //解决LocalDateTime的序列化错误 om.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS); om.registerModule(new JavaTimeModule()); jackson2JsonRedisSerializer.setObjectMapper(om); return jackson2JsonRedisSerializer; }} 创建RedisService在RedisService中封装一些常用的redis操作，如果没有可以参考RedisTemplate的api自行封装，下面简单举两个例子：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869@Servicepublic class RedisService { @Autowired private RedisTemplate redisTemplate; /** * 写入缓存 * * @param key * @param value * @return */ public boolean set(final String key, Object value) { boolean result = false; try { ValueOperations&lt;Serializable, Object&gt; operations = redisTemplate.opsForValue(); operations.set(key, value); result = true; } catch (Exception e) { e.printStackTrace(); } return result; } /** * 写入缓存设置时效时间 * * @param key * @param value * @return */ public boolean set(final String key, Object value, Long expireTime) { boolean result = false; try { ValueOperations&lt;Serializable, Object&gt; operations = redisTemplate.opsForValue(); operations.set(key, value); redisTemplate.expire(key, expireTime, TimeUnit.SECONDS); result = true; } catch (Exception e) { e.printStackTrace(); } return result; } /** * 读取缓存 * * @param key * @return */ public Object genValue(final String key) { Object result = null; ValueOperations&lt;String, String&gt; operations = redisTemplate.opsForValue(); result = operations.get(key); return result; } /** * 哈希 添加 * * @param key * @param hashKey * @param value */ public void hmSet(String key, Object hashKey, Object value) { HashOperations&lt;String, Object, Object&gt; hash = redisTemplate.opsForHash(); hash.put(key, hashKey, value); }} RedisTemplateRedisTemplate中定义了对5种数据结构来对redis进行操作:12345redisTemplate.opsForValue();//操作字符串redisTemplate.opsForHash();//操作hashredisTemplate.opsForList();//操作listredisTemplate.opsForSet();//操setredisTemplate.opsForZSet();//操作sortset 以ValueOperations为例,提供如下接口 Redis5.0配置详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281#是否在后台执行，yes：后台运行；no：不是后台运行daemonize yes #是否开启保护模式，默认开启。要是配置里没有指定bind和密码。开启该参数后，redis只会本地进行访问，拒绝外部访问。protected-mode yes #redis的进程文件pidfile /var/run/redis/redis-server.pid #redis监听的端口号。port 6379 #此参数确定了TCP连接中已完成队列(完成三次握手之后)的长度， 当然此值必须不大于Linux系统定义的/proc/sys/net/core/somaxconn值，默认是511，而Linux的默认参数值是128。当系统并发量大并且客户端速度缓慢的时候，可以将这二个参数一起参考设定。该内核参数默认值一般是128，对于负载很大的服务程序来说大大的不够。一般会将它修改为2048或者更大。在/etc/sysctl.conf中添加:net.core.somaxconn = 2048，然后在终端中执行sysctl -p。tcp-backlog 511 #指定 redis 只接收来自于该 IP 地址的请求，如果不进行设置，那么将处理所有请求bind 127.0.0.1 #配置unix socket来让redis支持监听本地连接。# unixsocket /var/run/redis/redis.sock #配置unix socket使用文件的权限# unixsocketperm 700 # 此参数为设置客户端空闲超过timeout，服务端会断开连接，为0则服务端不会主动断开连接，不能小于0。timeout 0 #tcp keepalive参数。如果设置不为0，就使用配置tcp的SO_KEEPALIVE值，使用keepalive有两个好处:检测挂掉的对端。降低中间设备出问题而导致网络看似连接却已经与对端端口的问题。在Linux内核中，设置了keepalive，redis会定时给对端发送ack。检测到对端关闭需要两倍的设置值。tcp-keepalive 0 #指定了服务端日志的级别。级别包括：debug（很多信息，方便开发、测试），verbose（许多有用的信息，但是没有debug级别信息多），notice（适当的日志级别，适合生产环境），warn（只有非常重要的信息）loglevel notice #指定了记录日志的文件。空字符串的话，日志会打印到标准输出设备。后台运行的redis标准输出是/dev/null。logfile /var/log/redis/redis-server.log #是否打开记录syslog功能# syslog-enabled no #syslog的标识符。# syslog-ident redis #日志的来源、设备# syslog-facility local0 #数据库的数量，默认使用的数据库是DB 0。可以通过SELECT命令选择一个dbdatabases 16 # redis是基于内存的数据库，可以通过设置该值定期写入磁盘。# 注释掉“save”这一行配置项就可以让保存数据库功能失效# 900秒（15分钟）内至少1个key值改变（则进行数据库保存--持久化）# 300秒（5分钟）内至少10个key值改变（则进行数据库保存--持久化）# 60秒（1分钟）内至少10000个key值改变（则进行数据库保存--持久化）save 900 1save 300 10save 60 10000 #当RDB持久化出现错误后，是否依然进行继续进行工作，yes：不能进行工作，no：可以继续进行工作，可以通过info中的rdb_last_bgsave_status了解RDB持久化是否有错误stop-writes-on-bgsave-error yes #使用压缩rdb文件，rdb文件压缩使用LZF压缩算法，yes：压缩，但是需要一些cpu的消耗。no：不压缩，需要更多的磁盘空间rdbcompression yes #是否校验rdb文件。从rdb格式的第五个版本开始，在rdb文件的末尾会带上CRC64的校验和。这跟有利于文件的容错性，但是在保存rdb文件的时候，会有大概10%的性能损耗，所以如果你追求高性能，可以关闭该配置。rdbchecksum yes #rdb文件的名称dbfilename dump.rdb #数据目录，数据库的写入会在这个目录。rdb、aof文件也会写在这个目录dir /var/lib/redis ############### 主从复制 ############### #复制选项，slave复制对应的master。# slaveof &lt;masterip&gt; &lt;masterport&gt; #如果master设置了requirepass，那么slave要连上master，需要有master的密码才行。masterauth就是用来配置master的密码，这样可以在连上master后进行认证。# masterauth &lt;master-password&gt; #当从库同主机失去连接或者复制正在进行，从机库有两种运行方式：1) 如果slave-serve-stale-data设置为yes(默认设置)，从库会继续响应客户端的请求。2) 如果slave-serve-stale-data设置为no，除去INFO和SLAVOF命令之外的任何请求都会返回一个错误”SYNC with master in progress”。slave-serve-stale-data yes #作为从服务器，默认情况下是只读的（yes），可以修改成NO，用于写（不建议）。slave-read-only yes #是否使用socket方式复制数据。目前redis复制提供两种方式，disk和socket。如果新的slave连上来或者重连的slave无法部分同步，就会执行全量同步，master会生成rdb文件。有2种方式：disk方式是master创建一个新的进程把rdb文件保存到磁盘，再把磁盘上的rdb文件传递给slave。socket是master创建一个新的进程，直接把rdb文件以socket的方式发给slave。disk方式的时候，当一个rdb保存的过程中，多个slave都能共享这个rdb文件。socket的方式就的一个个slave顺序复制。在磁盘速度缓慢，网速快的情况下推荐用socket方式。repl-diskless-sync no #diskless复制的延迟时间，防止设置为0。一旦复制开始，节点不会再接收新slave的复制请求直到下一个rdb传输。所以最好等待一段时间，等更多的slave连上来。repl-diskless-sync-delay 5 #slave根据指定的时间间隔向服务器发送ping请求。时间间隔可以通过 repl_ping_slave_period 来设置，默认10秒。# repl-ping-slave-period 10 #复制连接超时时间。master和slave都有超时时间的设置。master检测到slave上次发送的时间超过repl-timeout，即认为slave离线，清除该slave信息。slave检测到上次和master交互的时间超过repl-timeout，则认为master离线。需要注意的是repl-timeout需要设置一个比repl-ping-slave-period更大的值，不然会经常检测到超时。# repl-timeout 60 #是否禁止复制tcp链接的tcp nodelay参数，可传递yes或者no。默认是no，即使用tcp nodelay。如果master设置了yes来禁止tcp nodelay设置，在把数据复制给slave的时候，会减少包的数量和更小的网络带宽。但是这也可能带来数据的延迟。默认我们推荐更小的延迟，但是在数据量传输很大的场景下，建议选择yes。repl-disable-tcp-nodelay no #复制缓冲区大小，这是一个环形复制缓冲区，用来保存最新复制的命令。这样在slave离线的时候，不需要完全复制master的数据，如果可以执行部分同步，只需要把缓冲区的部分数据复制给slave，就能恢复正常复制状态。缓冲区的大小越大，slave离线的时间可以更长，复制缓冲区只有在有slave连接的时候才分配内存。没有slave的一段时间，内存会被释放出来，默认1m。# repl-backlog-size 5mb #master没有slave一段时间会释放复制缓冲区的内存，repl-backlog-ttl用来设置该时间长度。单位为秒。# repl-backlog-ttl 3600 #当master不可用，Sentinel会根据slave的优先级选举一个master。最低的优先级的slave，当选master。而配置成0，永远不会被选举。slave-priority 100 #redis提供了可以让master停止写入的方式，如果配置了min-slaves-to-write，健康的slave的个数小于N，mater就禁止写入。master最少得有多少个健康的slave存活才能执行写命令。这个配置虽然不能保证N个slave都一定能接收到master的写操作，但是能避免没有足够健康的slave的时候，master不能写入来避免数据丢失。设置为0是关闭该功能。# min-slaves-to-write 3 #延迟小于min-slaves-max-lag秒的slave才认为是健康的slave。# min-slaves-max-lag 10 # 设置1或另一个设置为0禁用这个特性。# Setting one or the other to 0 disables the feature.# By default min-slaves-to-write is set to 0 (feature disabled) and# min-slaves-max-lag is set to 10. ############### 安全相关 ############### #requirepass配置可以让用户使用AUTH命令来认证密码，才能使用其他命令。这让redis可以使用在不受信任的网络中。为了保持向后的兼容性，可以注释该命令，因为大部分用户也不需要认证。使用requirepass的时候需要注意，因为redis太快了，每秒可以认证15w次密码，简单的密码很容易被攻破，所以最好使用一个更复杂的密码。注意只有密码没有用户名。# requirepass foobared #把危险的命令给修改成其他名称。比如CONFIG命令可以重命名为一个很难被猜到的命令，这样用户不能使用，而内部工具还能接着使用。# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 #设置成一个空的值，可以禁止一个命令# rename-command CONFIG &quot;&quot; ############### 进程限制相关 ############### # 设置能连上redis的最大客户端连接数量。默认是10000个客户端连接。由于redis不区分连接是客户端连接还是内部打开文件或者和slave连接等，所以maxclients最小建议设置到32。如果超过了maxclients，redis会给新的连接发送’max number of clients reached’，并关闭连接。# maxclients 10000 #redis配置的最大内存容量。当内存满了，需要配合maxmemory-policy策略进行处理。注意slave的输出缓冲区是不计算在maxmemory内的。所以为了防止主机内存使用完，建议设置的maxmemory需要更小一些。# maxmemory &lt;bytes&gt; #内存容量超过maxmemory后的处理策略。#volatile-lru：利用LRU算法移除设置过过期时间的key。#volatile-random：随机移除设置过过期时间的key。#volatile-ttl：移除即将过期的key，根据最近过期时间来删除（辅以TTL）#allkeys-lru：利用LRU算法移除任何key。#allkeys-random：随机移除任何key。#noeviction：不移除任何key，只是返回一个写错误。#上面的这些驱逐策略，如果redis没有合适的key驱逐，对于写命令，还是会返回错误。redis将不再接收写请求，只接收get请求。写命令包括：set setnx setex append incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby getset mset msetnx exec sort。# maxmemory-policy noeviction #lru检测的样本数。使用lru或者ttl淘汰算法，从需要淘汰的列表中随机选择sample个key，选出闲置时间最长的key移除。# maxmemory-samples 5 ############### APPEND ONLY 持久化方式 ############### #默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。但是redis如果中途宕机，会导致可能有几分钟的数据丢失，根据save来策略进行持久化，Append Only File是另一种持久化方式，可以提供更好的持久化特性。Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。appendonly no #aof文件名appendfilename &quot;appendonly.aof&quot; #aof持久化策略的配置#no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快。#always表示每次写入都执行fsync，以保证数据同步到磁盘。#everysec表示每秒执行一次fsync，可能会导致丢失这1s数据。appendfsync everysec # 在aof重写或者写入rdb文件的时候，会执行大量IO，此时对于everysec和always的aof模式来说，执行fsync会造成阻塞过长时间，no-appendfsync-on-rewrite字段设置为默认设置为no。如果对延迟要求很高的应用，这个字段可以设置为yes，否则还是设置为no，这样对持久化特性来说这是更安全的选择。设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议yes。Linux的默认fsync策略是30秒。可能丢失30秒数据。no-appendfsync-on-rewrite no #aof自动重写配置。当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，即当aof文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写。当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程。auto-aof-rewrite-percentage 100#设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写auto-aof-rewrite-min-size 64mb #aof文件可能在尾部是不完整的，当redis启动的时候，aof文件的数据被载入内存。重启可能发生在redis所在的主机操作系统宕机后，尤其在ext4文件系统没有加上data=ordered选项（redis宕机或者异常终止不会造成尾部不完整现象。）出现这种现象，可以选择让redis退出，或者导入尽可能多的数据。如果选择的是yes，当截断的aof文件被导入的时候，会自动发布一个log给客户端然后load。如果是no，用户必须手动redis-check-aof修复AOF文件才可以。aof-load-truncated yes ############### LUA SCRIPTING ############### # 如果达到最大时间限制（毫秒），redis会记个log，然后返回error。当一个脚本超过了最大时限。只有SCRIPT KILL和SHUTDOWN NOSAVE可以用。第一个可以杀没有调write命令的东西。要是已经调用了write，只能用第二个命令杀。lua-time-limit 5000 ############### 集群相关 ############### #集群开关，默认是不开启集群模式。# cluster-enabled yes #集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。这个文件并不需要手动配置，这个配置文件有Redis生成并更新，每个Redis集群节点需要一个单独的配置文件，请确保与实例运行的系统中配置文件名称不冲突# cluster-config-file nodes-6379.conf #节点互连超时的阀值。集群节点超时毫秒数# cluster-node-timeout 15000 #在进行故障转移的时候，全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了，导致数据过于陈旧，这样的slave不应该被提升为master。该参数就是用来判断slave节点与master断线的时间是否过长。判断方法是：#比较slave断开连接的时间和(node-timeout * slave-validity-factor) + repl-ping-slave-period#如果节点超时时间为三十秒, 并且slave-validity-factor为10,假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移# cluster-slave-validity-factor 10 #master的slave数量大于该值，slave才能迁移到其他孤立master上，如这个参数若被设为2，那么只有当一个主节点拥有2 个可工作的从节点时，它的一个从节点会尝试迁移。# cluster-migration-barrier 1 #默认情况下，集群全部的slot有节点负责，集群状态才为ok，才能提供服务。设置为no，可以在slot没有全部分配的时候提供服务。不建议打开该配置，这样会造成分区的时候，小分区的master一直在接受写请求，而造成很长时间数据不一致。# cluster-require-full-coverage yes ############### SLOW LOG 慢查询日志 ############### ###slog log是用来记录redis运行中执行比较慢的命令耗时。当命令的执行超过了指定时间，就记录在slow log中，slog log保存在内存中，所以没有IO操作。#执行时间比slowlog-log-slower-than大的请求记录到slowlog里面，单位是微秒，所以1000000就是1秒。注意，负数时间会禁用慢查询日志，而0则会强制记录所有命令。slowlog-log-slower-than 10000 #慢查询日志长度。当一个新的命令被写进日志的时候，最老的那个记录会被删掉。这个长度没有限制。只要有足够的内存就行。你可以通过 SLOWLOG RESET 来释放内存。slowlog-max-len 128 ############### 延迟监控 ################延迟监控功能是用来监控redis中执行比较缓慢的一些操作，用LATENCY打印redis实例在跑命令时的耗时图表。只记录大于等于下边设置的值的操作。0的话，就是关闭监视。默认延迟监控功能是关闭的，如果你需要打开，也可以通过CONFIG SET命令动态设置。latency-monitor-threshold 0 ############### EVENT NOTIFICATION 订阅通知 ################键空间通知使得客户端可以通过订阅频道或模式，来接收那些以某种方式改动了 Redis 数据集的事件。因为开启键空间通知功能需要消耗一些 CPU ，所以在默认配置下，该功能处于关闭状态。#notify-keyspace-events 的参数可以是以下字符的任意组合，它指定了服务器该发送哪些类型的通知：##K 键空间通知，所有通知以 __keyspace@__ 为前缀##E 键事件通知，所有通知以 __keyevent@__ 为前缀##g DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知##$ 字符串命令的通知##l 列表命令的通知##s 集合命令的通知##h 哈希命令的通知##z 有序集合命令的通知##x 过期事件：每当有过期键被删除时发送##e 驱逐(evict)事件：每当有键因为 maxmemory 政策而被删除时发送##A 参数 g$lshzxe 的别名#输入的参数中至少要有一个 K 或者 E，否则的话，不管其余的参数是什么，都不会有任何 通知被分发。详细使用可以参考http://redis.io/topics/notifications notify-keyspace-events &quot;&quot; ############### ADVANCED CONFIG 高级配置 ################数据量小于等于hash-max-ziplist-entries的用ziplist，大于hash-max-ziplist-entries用hashhash-max-ziplist-entries 512#value大小小于等于hash-max-ziplist-value的用ziplist，大于hash-max-ziplist-value用hash。hash-max-ziplist-value 64 #数据量小于等于list-max-ziplist-entries用ziplist，大于list-max-ziplist-entries用list。list-max-ziplist-entries 512#value大小小于等于list-max-ziplist-value的用ziplist，大于list-max-ziplist-value用list。list-max-ziplist-value 64 #数据量小于等于set-max-intset-entries用iniset，大于set-max-intset-entries用set。set-max-intset-entries 512 #数据量小于等于zset-max-ziplist-entries用ziplist，大于zset-max-ziplist-entries用zset。zset-max-ziplist-entries 128#value大小小于等于zset-max-ziplist-value用ziplist，大于zset-max-ziplist-value用zset。zset-max-ziplist-value 64 #value大小小于等于hll-sparse-max-bytes使用稀疏数据结构（sparse），大于hll-sparse-max-bytes使用稠密的数据结构（dense）。一个比16000大的value是几乎没用的，建议的value大概为3000。如果对CPU要求不高，对空间要求较高的，建议设置到10000左右。hll-sparse-max-bytes 3000 #Redis将在每100毫秒时使用1毫秒的CPU时间来对redis的hash表进行重新hash，可以降低内存的使用。当你的使用场景中，有非常严格的实时性需要，不能够接受Redis时不时的对请求有2毫秒的延迟的话，把这项配置为no。如果没有这么严格的实时性要求，可以设置为yes，以便能够尽可能快的释放内存。activerehashing yes ##对客户端输出缓冲进行限制可以强迫那些不从服务器读取数据的客户端断开连接，用来强制关闭传输缓慢的客户端。#对于normal client，第一个0表示取消hard limit，第二个0和第三个0表示取消soft limit，normal client默认取消限制，因为如果没有寻问，他们是不会接收数据的。client-output-buffer-limit normal 0 0 0#对于slave client和MONITER client，如果client-output-buffer一旦超过256mb，又或者超过64mb持续60秒，那么服务器就会立即断开客户端连接。client-output-buffer-limit slave 256mb 64mb 60#对于pubsub client，如果client-output-buffer一旦超过32mb，又或者超过8mb持续60秒，那么服务器就会立即断开客户端连接。client-output-buffer-limit pubsub 32mb 8mb 60 #redis执行任务的频率为1s除以hz。hz 10 #在aof重写的时候，如果打开了aof-rewrite-incremental-fsync开关，系统会每32MB执行一次fsync。这对于把文件写入磁盘是有帮助的，可以避免过大的延迟峰值。aof-rewrite-incremental-fsync yes","link":"/2019/06/16/RedisSpringJunior/"},{"title":"初遇Redis","text":"什么是Redis讲到redis不得不讲NoSql NoSQL是不同于传统的关系数据库的数据库管理系统的统称。其两者最重要的区别是NoSQL不使用SQL作为查询语言。 NoSQL数据存储可以不需要固定的表格模式。NoSQL是基于键值对的，可以想象成表中的主键和值的对应关系。 NoSQL：redis、memcached、mongodb、guava（loadingCache） Redis是什么Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多 种类型的数据结构，如 字符串（strings）、散列（hashes）、 列表（lists）、 集合（sets）、 有序集合（sorted sets）等。 对比Mysql关系型数据库的一个常见用法是存储长期的报告数据，并将这些报告数据用作固定时间范围内的聚合数据。收集聚合数据的常见做法是：先将各个行插入一个报告表里面， 之后再通过扫描这些行来收集聚合数据， 并更新聚合表中巳有的那些行。先来看看Mysql的执行流程图： 添加索引是在最后一步：执行引擎中发挥作用。 当执行查询时，命中缓存Cache时候，才是最快的。而Redis是一个内存缓存工具，可以通过内存返回数据结果，不用进行表查询，效率是最高的。因为磁盘计算是远远比不上内存计算的。磁盘是要进行一个全表扫描，数据是持久化的。 对比Memcached内存管理机制 Memcached默认使用Slab Allocation机制管理内存，其主要思想是按照预先规定的大小， 将分配的内存分割成特定长度的块 以存储相应长度的key-value数据记录，以完全解决内存碎 片问题。空闲列表进行判断存储状态,【类似于Java虚拟机对象的分配，空闲列表】 Redis使用现场申请内存的方式来存储数据，并且很少使用free-list等方式来优化内存分配，会在一定程度上存在内存碎片,【CPU内存是连续，类似于Java虚拟机对象的分配，直接内存分配（指针碰撞）】 Memcached个人感觉就是将内存碎片变成了内存的浪费。 redis作者可能为了更高的性能，所以在redis中实现了自己的内存分配器来管理内存，不会马上返还内存，不用每次都向OS申请了，从而实现高性能。但是redis的每个k-v对初始化的内存大小是最适合的，当这个value改变的并且原来内存大小不适用的时候，就需要重新分配内存了。（但是value存比原来小不知道会不会产生碎片）。重新分配之后，就会有一部分内存redis无法正常回收，一直占用着。解决方案： 重启redis服务，简单粗暴。 4.0以后清理：（自动）redis-cli -p 6379 config set activedefrag yes 4.0以后清理：（手动）redis-cli -p 6379 memory purge 数据持久化方案 memcached不支持内存数据的持久化操作，所有的数据都以in-memory的形式存储。 redis支持持久化操作。redis提供了两种不同的持久化方法来讲数据存储到硬盘里面， 第一种是rdb形式，一种是aof形式 rdb：属于全量数据备份，备份的是数据 aof：append only if,增量持久化备份，备份的是指令 缓存数据过期机制 概念：key，设计一个小时之后过期，超过一个小时查数据就会查不到 Memcached 在删除失效主键时也是采用的消极方法，即 Memcached 内部也不会监视主键是否失效，而是在通过 Get 访问主键时才会检查其是否已经失效 Redis 定时、定期等多种缓存失效机制，减少内存泄漏 支持的数据类型 Memcached支持单一数据类型,[k,v] redis支持五种数据类型 Redis数据类型操作Key/Value类型简介： String是最常用的一种数据类型，普通的key/value存储都可以归为此类。 set/get 设置key对应的值为String类型的value 获取key对应的值 mget 批量获取多个key的值，如果可以不存在则返回nil incr &amp;&amp; incrby incr对key对应的值进行加加操作，并返回新的值;incrby加指定值 incr &amp;&amp; incrby incr对key对应的值进行加加操作，并返回新的值;incrby加指定值 setnx 设置key对应的值为String类型的value，如果key已经存在则返回0 setex 设置key对应的值为String类型的value，并设定有效期 其他命令 getrange 获取key对应value的子字符串 mset 批量设置多个key的值，如果成功表示所有值都被设置，否则返回0表示没有任何值被设置 msetnx，同mset，不存在就设置，不会覆盖已有的key getset 设置key的值，并返回key旧的值 append：给指定key的value追加字符串，并返回新字符串的长度 Hash类型 Hash是一个String类型的field和value之间的映射表 redis的Hash数据类型的key（hash表名称）对应的value实际的内部存储结构为一个HashMap Hash特别适合存储对象 相对于把一个对象的每个属性存储为String类型，将整个对象存储在Hash类型中会占用更少内存。 所存储的成员较少时数据存储为zipmap，当成员数量增大时会自动转成真正的HashMap,此时encoding为ht。 运用场景： 如用一个对象来存储用户信息，商品信息，订单信息等等。 Hash命令讲解 hset——设置key对应的HashMap中的field的value hget——获取key对应的HashMap中的field的value hgetall——获取key对应的HashMap中的所有field的value hlen–返回key对应的HashMap中的field的数量 List类型 lpush——在key对应的list的头部添加一个元素 lrange——获取key对应的list的指定下标范围的元素，-1表示获取所有元素 lpop——从key对应的list的尾部删除一个元素，并返回该元素 rpush——在key对应的list的尾部添加一个元素 rpop——从key对应的list的尾部删除一个元素，并返回该元素 Set类型 sadd——在key对应的set中添加一个元素 smembers——获取key对应的set的所有元素 spop——随机返回并删除key对应的set中的一个元素 suion——求给定key对应的set并集 sinter——求给定key对应的set交集 SortSet类型简介：set的基础增加顺序score，再根据score进行排序 实战：通过sortset实现排行榜 zadd ——在key对应的zset中添加一个元素 zrange——获取key对应的zset中指定范围的元素，-1表示获取所有元素 zrem——删除key对应的zset中的一个元素 zrangebyscore——返回有序集key中，指定分数范围的元素列表,排行榜中运用 zrank——返回key对应的zset中指定member的排名。其中member按score值递增(从小到大）； 排名以0为底，也就是说，score值最小的成员排名为0,排行榜中运用 Set与SortSet set是通过hashmap存储，key对应set的元素，value是空对象 sortset是怎么存储并实现排序的呢，hashmap存储，还加了一层跳跃表 跳跃表：相当于双向链表，在其基础上添加前往比当前元素大的跳转链接","link":"/2019/06/15/media/RedisFirstEncounter/"}],"tags":[{"name":"Mac","slug":"Mac","link":"/tags/Mac/"},{"name":"IDEA","slug":"IDEA","link":"/tags/IDEA/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Spring Cloud","slug":"Spring-Cloud","link":"/tags/Spring-Cloud/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/tags/Spring-Boot/"},{"name":"备忘","slug":"备忘","link":"/tags/备忘/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"}],"categories":[{"name":"MacOS相关","slug":"MacOS相关","link":"/categories/MacOS相关/"},{"name":"Hexo","slug":"Hexo","link":"/categories/Hexo/"},{"name":"Spring Cloud","slug":"Spring-Cloud","link":"/categories/Spring-Cloud/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/categories/Spring-Boot/"},{"name":"Redis","slug":"Redis","link":"/categories/Redis/"}]}