{"pages":[{"title":"关 于","text":"Live in DaLian","link":"/about/index.html"},{"title":"分 类","text":"","link":"/categories/index.html"},{"title":"标 签","text":"","link":"/tags/index.html"}],"posts":[{"title":"Docker 基础","text":"工作忙了小半年，终于有时间开始更新了！！！！ 为什么使用Docker：开箱即用，快速部署，可移植性强，环境隔离本文主要介绍Docker的基础操作 Dockerfile基础 FROM 基于哪个镜像 MAINTAINER 注明作者 COPY 简单复制，不会解压复制的压缩文件 ADD 复制，会解压要复制的压缩文件 ADD 可以复制并执行语句，例如：ADD init.sql . WORKDIR 工作路径（进入容器默认文件夹），不存在会直接新建 ENV 设置环境变量 EXPOSE 暴露容器端口 RUN 在构建镜像的时候执行，作用于镜像层面 ENTRYPOINT 在容器启动的时候执行，作用于容器层，dockerfile里有多条时只允许执行最后一条 CMD 在容器启动的时候执行，作用于容器层，dockerfile里有多条时只允许执行最后一条 容器启动后执行默认的命令或者参数，允许被修改 命令格式: shell命令格式:RUN yum install -y net-tools exec命令格式:RUN [ “yum”,”install” ,”-y” ,”net-tools”] RUN作用于镜像层，在构建image时候执行。 CMD，ENTRYPOINT作用于容器层，创建容器才会执行。 例子：解释cmd / entrypoint dockerfile 无传入参数 有传入参数 当CMD有参数，当启动容器时会将CMD全部内容当成ENTRYPOINT的参数执行，如果想覆盖entrypoint，在docker run后带--entrypoint即可，当entrypoint在shell模式下，cmd任何参数内容都不会传入到entrypoint中。 一般该怎么使用：一般还是会用entrypoint的中括号形式作为docker容器启动以后的默认执行命令，里面放的是不变的部分，可变部分比如命令参数可以使用cmd的形式提供默认版本，也就是run里面没有任何参数时使用的默认参数。如果我们想用默认参数，就直接run，否则想用其他参数，就run 里面加参数。 Docker 网络模式Docker的网络模式源自CNM（容器网络模型）方案，CNM是开源且支持插接式连接。 CNM与DockerCNM定义了3个基本要素： 沙盒 一个独立的网络栈。包括以太网接口，端口，路由表以及DNS配置。 终端 虚拟网接口。就像普通网络接口一样，终端主要职责是负责创建连接，在CNM中，终端负责将沙盒连接到网络。 网络 是801.1d网桥（类似交换机）的软件实现。因此网络就是需要交换的终端的集合，并且终端之间相互独立。 如果一个容器要与另一个容器连接需要，则要讲两个容器连接到相同的网桥。当两个容器连接到相同的网桥时候，可以用对方容器的名字直接ping通，因为容器都注册到了指定的Docker DNS服务，所以相同网络的容器可以解析其他容器的名称。但是Linux默认的Bridge网络是不支持通过Docker DNS服务进行域名解析的，自定义桥接网络可以！ 默认网络模式 bridge:桥接模式 host:主机模式 none:无网络模式 查看网络模式命令docker network ls 桥接模式Bridge（Win叫Nat）Bridge模式是Docker默认的网络设置，当Docker服务启动时，会在主机上创建一个名为docker0的虚拟网桥，并选择一个和宿主机不同的IP地址和子网分配给docker 0网桥。 查看桥接情况： 12yum install -y net-tools &amp;&amp; yum install -y bridge-utilsbtctl show 主机模式Host该模式下，容器不会有自己的Ip地址，而是使用宿主机的IP地址和端口。查看宿主机端口占用情况： 12yum install -y net-tools &amp;&amp; yum install -y bridge-utilsnetstat -tunlp|grep &lt;port&gt; 无网络模式None无法连接外网 容器之间的单向双向连接 单向连接 在容器启东命令添加--link &lt;container name&gt; 双向连接 需要双向连接的容器添加到自定义的网桥上即可。 创建网桥方式docker network create -d bridge &lt;bridge name&gt; Docker-ComposeDocker-Compose的前身是Fig，知道Docker收购了Orchard公司后，将Fig更名为Docker-Compose。命令行工具也从fig更为docker-compose，并自此成为了绑定在Docker引擎之上的外部工具。内部实现上，Fig会解析YAML文件，并通过Docker API进行应用的部署和管理。 安装123yum install -y epel-release &amp;&amp; yum install -y python-pippip install -i https://pypi.tuna.tsinghua.edu.cn/simple docker-compose==1.24.1docker-compose version 简单的docker-compose.yml文件12345678910111213141516171819202122version: \"3\"services: web-fe: build: . command: python app.py ports: - target: 5000 published: 8080 networks: - counter-net volumes: - type: volume source: counter-vol target: /code redis: image: \"redis:5.0.5\" networks: counter-net:networks: counter-net:volumes: counter-vol: docker-compose.yml 解析包含四个一级key：version，services，networks，volumes versionversion是必须指定的，总是位于文件的第一行，定义了Compose文件格式（主要是API）的版本，而非定义了Docker Compose或Docker引擎的版本号，==建议使用最新版本==。 services在service里/定义了两个服务：web-fe，redis。 build:指定Docker基于当前目录下的Dockerfile创建一个新的镜像。 command:指定在Docker容器中执行app.py脚本，所以容器内必须有app.py文件，这一点在Dockerfile进行设置。此command指令可以覆盖Dockerfile中指定的CMD指令。 ports:讲容器内5000端口映射到宿主机8080端口。 networks:链接到已存在的Docker网络中，或者在networks中定义的key值名字的网络。 volumes:将counter-vol卷挂载到容器内/code上，同样counter-vol可以使存在的或者是CIA面volumes中定义的。 images:使用该值得镜像构建，本地没有会从DockerHub进行下载。 networks、volumes定义新的网络或者卷，网络默认是Bridge模式，当网络模式为Overlay模式时，允许独立的容器连接（attachable）到该网络 1234networks: over-net: driver: over-lay attachable: true 部署应用进入到docker-compose.yml和Dockerfile的文件夹。 启动创建 正常启动docker-compose up 指定文件启动docker-compose -f docker.yml up 后台启动docker-compose -d up 创建的镜像使用项目名+资源名称作为新的镜像名称，创建的网络和卷同样会使用项目名作为前缀。 停止/终止 终止docker-compose down，不会删除启动时创建或拉取的镜像，创建的卷（因为数据的长期持久化） 停止dokcer-compose stop 其他命令 列出各个容器内运行的进程docker-compose top 重启docker-compose restart 列出Compose应用中的各个容器docker-compose ps 其他例子1234567891011121314151617181920212223242526272829303132version: \"3\"services: db: # docker run -itd mysql:5.7 image: mysql:5.7 volumes: # 采用的是卷标的形式挂载(注意:- db_data是参数，可以变，自定义，必须与下面对应) - db_data:/var/lib/mysql # 自动重启，保证服务在线 restart: always # 指定环境变量 docker -itd -e environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: # - db 是参数，合起来的意思是只有当上面的mysql数据库安装成功后，这个wordpress才可以被安装， # 还有一个功能，就是docker --link 将上面的mysql数据库，与这个wordpress应用连起来 - db image: wordpress:latest ports: - \"8000:80\" restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress WORDPRESS_DB_NAME: wordpress volumes: db_data: {} 载入/导出镜像/容器镜像 导出 12docker save cd3ed0dfff7e -o /home/mysql.tardocker save mysql:5.7 &gt; /home/mysql.tar 载入 1docker load -i mysql.tar 容器 导出 1docker export 974b919e1fdd -o /home/mysql-export.tar 载入 1docker import mysql-export.tar docker容器导入会生成一个新的镜像，这个镜像的镜像ID跟生成打包容器的镜像ID不同 其他常用命令/操作镜像 查看本地镜像:docker images 搜索镜像:docker search centos 搜索镜像并过滤是官方的: docker search --filter &quot;is-official=true&quot; centos 搜索镜像并过滤大于多少颗星星的:docker search --filter stars=10 centos 下载centos7镜像:docker pull centos:7 修改本地镜像名字(小写):docker tag centos:7 mycentos:1 本地镜像的删除:docker rmi centos:7 容器 构建容器:docker run -itd --name=mycentos centos:7 -i :表示以交互模式运行容器(让容器的标准输入保持打开) -d:表示后台运行容器，并返回容器ID -t:为容器重新分配一个伪输入终端 –name:为容器指定名称 查看本地所有的容器:docker ps -a 查看本地正在运行的容器:docker ps 停止容器:docker stop CONTAINER_ID / CONTAINER_NAME 一次性停止所有容器:docker stop $(docker ps -a -q) 启动容器:docker start CONTAINER_ID / CONTAINER_NAME 重启容器:docker restart CONTAINER_ID / CONTAINER_NAME 删除容器:docker rm CONTAINER_ID / CONTAINER_NAME 强制删除容器:docker rmi -f CONTAINER_ID / CONTAINER_NAME 查看容器详细信息:docker inspect CONTAINER_ID / CONTAINER_NAME 进入容器:docker exec -it 0ad5d7b2c3a4 /bin/bash 文件复制 从宿主机复制到容器:docker cp 宿主机本地路径 容器名字/ID:容器路径 docker cp /root/123.txt mycentos:/home/ 从容器复制到宿主机:docker cp 容器名字/ID:容器路径 宿主机本地路径 docker cp mycentos:/home/456.txt /root 宿主机文件夹挂载到容器里:docker run -itd -v 宿主机路径:容器路径 镜像ID docker run -itd -v /root/xdclass/:/home centos:7 定义自己的阿里云镜像加速到自己阿里云找到对应的地址（每人不一样）修改/etc/docker/daemon.json,重启Docker服务。 123{ \"registry-mirrors\": [\"&lt;地址&gt;\"] } 私有镜像仓库Https改Http修改/etc/docker/daemon.json,重启Docker服务。 123{ \"insecure-registries\":[\"http://&lt;host:port&gt;\"] }","link":"/2020/04/04/Docker/"},{"title":"要了命的版本Druid/Mybatis/MybatisPlus","text":"问题现象Druid是alibaba的一款开源数据库连接池。被称为是专门为监控而生的数据库连接池配置，他可以监控sql的执行情况，以及性能，然后根据结果来优化sql或者做性能调优。 之前自己写项目时候没有用到Druid的监控功能。昨天试了试监控功能就出现了如下错误：java.sql.SQLFeatureNotSupportedException,主要是使用了LocalDateTime类型对应了数据库的timestamp类型字段引发的问题，java8新的时间类都会引发如下问题。 当前使用版本的是Mybatis-Plus 3.1.2和druid 1.1.20。 在Mybatis-Plus的3.1.1及之后的版本中，引用的mybatis版本为3.5.1。 在没有启动Druid的监控模块时候druid 1.1.19及以上版本支持mybatis 3.5.1，java8新的时间类型对应数据库时间类型都正常。 原因因为mybatis 3.5.1版本对于java.time包下LocalDateTime,LocalDate,LocalTime类型的转换交由了JDBC，若JDBC组件不支持对于LocalDateTime类型的处理则会报错。Druid数据库连接池，在最新版本中尚不支持对于LocalDateTime的处理，会throw SQLFeatureNotSupportedException，提请注意。 解决方式降低mybatis版本Mybatis-Plus使用3.1.0及以下版本12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt;&lt;/dependency&gt; Mybatis使用mybatis 3.5.0及以下版本 mybatis-spring-boot-starter 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt; mybatis 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.0&lt;/version&gt;&lt;/dependency&gt; 更换连接池更换为 hicaricp 3.3.1，并将jdbc换为最新的 附录Druid配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879spring: datasource: druid: url: jdbc:mysql://localhost:3306/videomall?useUnicode=true&amp;characterEncoding=utf-8&amp;serverTimezone=Asia/Shanghai username: root password: root driver-class-name: com.mysql.cj.jdbc.Driver # 初始化时建立物理连接的个数。初始化发生在显示调用init方法，或者第一次getConnection时，默认0 initial-size: 3 # 最大连接池数量，默认8 max-active: 5 # 最小连接池数量 min-idle: 1 # 获取连接时最大等待时间，单位毫秒。配置了maxWait之后，缺省启用公平锁，并发效率会有所下降 # 如果需要可以通过配置useUnfairLock属性为true使用非公平锁 max-wait: 30000 # 是否缓存preparedStatement，也就是PSCache # PSCache对支持游标的数据库性能提升巨大，比如说oracle。在mysql下建议关闭。默认false pool-prepared-statements: false # 要启用PSCache，必须配置大于0，当大于0时，poolPreparedStatements自动触发修改为true # 在Druid中，不会存在Oracle下PSCache占用内存过多的问题，可以把这个数值配置大一些，比如说100，默认-1 max-pool-prepared-statement-per-connection-size: 100 # 用来检测连接是否有效的sql，要求是一个查询语句，常用select 'x' # 如果validationQuery为null，testOnBorrow、testOnReturn、testWhileIdle都不会起作用 validation-query: SELECT 1 # 单位：秒，检测连接是否有效的超时时间。底层调用jdbc Statement对象的void setQueryTimeout(int seconds)方法 validation-query-timeout: 30000 # 申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能，默认true test-on-borrow: true # 归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能，默认false test-on-return: true # 申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效 # 建议配置为true，不影响性能，并且保证安全性，默认false test-while-idle: true # 连接池中的minIdle数量以内的连接，空闲时间超过minEvictableIdleTimeMillis，则会执行keepAlive操作，默认false keep-alive: true # 有两个含义： # 1) Destroy线程会检测连接的间隔时间，如果连接空闲时间大于等于minEvictableIdleTimeMillis则关闭物理连接 # 2) testWhileIdle的判断依据，详细看testWhileIdle属性的说明 # 默认1分钟 time-between-eviction-runs-millis: 60000 # 连接保持空闲而不被驱逐的最小时间 min-evictable-idle-time-millis: 300000 filters: stat,wall filter: stat: log-slow-sql: true slow-sql-millis: 2000 # WebStatFilter配置，说明请参考Druid Wiki，配置_配置WebStatFilter web-stat-filter: # 1.1.10以后的版本需要指定为true 不然默认是关闭的就会出现404 enabled: true # 添加过滤规则 url-pattern: /* # 忽略过滤格式 exclusions: \"*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*\" # StatViewServlet配置 stat-view-servlet: #展示Druid的统计信息,StatViewServlet的用途包括：1.提供监控信息展示的html页面2.提供监控信息的JSON API #是否启用StatViewServlet默认值true enabled: true #根据配置中的url-pattern来访问内置监控页面，如果是上面的配置，内置监控页面的首页是/druid/index.html例如： #http://110.76.43.235:9000/druid/index.html #http://110.76.43.235:8080/mini-web/druid/index.html url-pattern: /druid/* #是否允许清空统计数据 reset-enable: false login-username: admin login-password: admin #StatViewSerlvet展示出来的监控信息比较敏感，是系统运行的内部情况，如果你需要做访问控制，可以配置allow和deny这两个参数 #deny优先于allow，如果在deny列表中，就算在allow列表中，也会被拒绝。如果allow没有配置或者为空，则允许所有访问 #配置的格式 #&lt;IP&gt; #或者&lt;IP&gt;/&lt;SUB_NET_MASK_size&gt;其中128.242.127.1/24 #24表示，前面24位是子网掩码，比对的时候，前面24位相同就匹配,不支持IPV6。 allow: deny: 128.242.127.1/24,128.242.128.1 # Spring监控AOP切入点，如x.y.z.service.*,配置多个英文逗号分隔 aop-patterns:","link":"/2019/09/11/DruidMybatisMybatisPlusVersion/"},{"title":"Mac IDEA启动SpringBoot项目过慢","text":"最近本地新起的SpringBoot项目运行非常慢，能有十几秒，最后通过以下方法进行解决，解决后运行在三四秒左右。 通过hostname命令查看本机hostname1$ hostname 得到如下信息1MacBook-Pro.local 修改host文件1sudo vim /etc/hosts 修改条目如下，注意分隔符是TAB，不是空格12127.0.0.1 localhost MacBook-Pro.local::1 localhost MacBook-Pro.local 也可以通过软件进行修改","link":"/2019/05/06/IdeaSpringBoot/"},{"title":"Launchpad图标修改","text":"最近买了34寸曲面显示器，Launchpad的图标显示比较别扭，所以调整显示的行数与列数。 解决这个问题的方法是通过如下命令： 设置行数与列数123defaults write com.apple.dock springboard-rows -int 4defaults write com.apple.dock springboard-columns -int 7killall Dock 恢复默认行数与列数123defaults delete com.apple.dock springboard-rowsdefaults delete com.apple.dock springboard-columnskillall Dock 删除图标分组还有一个命令是删除图标分组（真心觉得这命令没啥用，没事儿别乱试，重新分组老麻烦了！）12defaults write com.apple.dock ResetLaunchPad -bool TRUEkillall Dock","link":"/2019/06/05/LaunchpadIcon/"},{"title":"MyBatis-Plus","text":"在整理MyBatis时候，Mybatis的逆向工程的xml实在懒得写，找代码生成器的时候听说了MyBatis-Plus，看了看官方文档，代码生成器深得我心，对照文档学习了下，感觉效率比MyBatis提升不少。 简介MyBatis-Plus（以下简称MP）是一个MyBatis的增强工具，在MyBatis的基础上只做增强不做改变，为简化开发、提高效率而生。 特性 无侵入：只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑 损耗小：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作 强大的 CRUD 操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求 支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错 支持主键自动生成：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题 支持 ActiveRecord 模式：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作 支持自定义全局通用操作：支持全局通用方法注入（ Write once, use anywhere ） 内置代码生成器：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用 内置分页插件：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询 分页插件支持多种数据库：支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer2005、SQLServer 等多种数据库 内置性能分析插件：可输出 Sql 语句以及其执行时间，建议开发测试时启用该功能，能快速揪出慢查询 内置全局拦截插件：提供全表 delete 、 update 操作智能分析阻断，也可自定义拦截规则，预防误操作 代码生成器详细配置参数详见代码生成器配置，以下为我的 常用的配置。 六种ConfigDataSourceConfig 数据源配置12345678DataSourceConfig dataSource = new DataSourceConfig();dataSource.setUrl(\"jdbc:mysql://**:**/***?useUnicode=true&amp;characterEncoding=utf-8\") .setDriverName(\"com.mysql.jdbc.Driver\") .setUsername(\"**\") .setPassword(\"**\") //.setSchemaName(\"public\")//可以在Url中设置 //.setTypeConvert()//自定义类型转换（决定对应数据库内置实现） .setDbType(DbType.MYSQL);//数据库类型 MP内置的类型转换在：com.baomidou.mybatisplus.generator.config.converts，默认提供5种数据库：以MySql为例可以看到数据库对应类型与Java类型的对应：因为jdk1.8引入java.time.*新api，在日期的转换上有个通过GlobalConfig(全局配置)的参数，可以指定数据库日期类型对应的java类型转换。 StrategyConfig 策略配置123456789StrategyConfig strategy = new StrategyConfig();strategy.setNaming(NamingStrategy.underline_to_camel)//表名映射规则 .setColumnNaming(NamingStrategy.underline_to_camel)//字段名映射规则 .setEntityLombokModel(false)//【实体】是否为lombok模型（默认 false) .setEntityTableFieldAnnotationEnable(true)//实体生成字段注解 .setTablePrefix(\"test_\")//表名前缀 .setRestControllerStyle(true)//生成 @RestController 控制器 //.setExclude() .setInclude(tableNames);//需要包含的表名，允许正则表达式（与exclude二选一配置)，参数String...tablename NamingStrategy.underline_to_camel下划线转驼峰，NamingStrategy.no_change不做任何改变，原样输出。详细配置见这里 PackageConfig 包配置123456789PackageConfig pac = new PackageConfig();pac.setModuleName(modelName)//modelName .setParent(\"com.mkcorden.bootmybatisplus\")//父包名。如果为空，将下面子包名必须写全部， 否则就只需写子包名 .setController(\"controller\") .setService(\"service\") .setServiceImpl(\"service.impl\") .setMapper(\"mapper\") .setEntity(\"domain\") .setXml(\"mapper\"); 包配置时候如果要按照模块进行生成区分，一定设置modelName。ServiceImpl设置二级的目录需要注意。 TemplateConfig 模版配置1234567TemplateConfig templateConfig = new TemplateConfig();// 配置自定义输出模板// 指定自定义模板路径，注意不要带上.ftl/.vm, 会根据使用的模板引擎自动识别// templateConfig.setEntity(\"templates/entity2.java\");// templateConfig.setService();// templateConfig.setController();templateConfig.setXml(null); 因为静态的xml文件一般生成在resources目录下，但是按上面的包配置，.xml的mapper会直接生成在modelName/mapper/*下，在TemplateConfig下设置xml为null，则可以不输出xml文件，然后用自定义配置进行对应输出。 设置Null不输出： com.baomidou.mybatisplus.generator.config.builder.ConfigBuilder中，template.getXml()为Null，不会设置pathInfo(HashMap)中Key:xml_path的value。 在com.baomidou.mybatisplus.generator.engine.AbstractTemplateEngine的batchOutput()方法,pathInfo.get(ConstVal.XML_PATH)为null，所以不进行xml文件的输出。 GlobalConfig 全局配置12345678910111213141516GlobalConfig gc = new GlobalConfig();gc.setFileOverride(false)//文件是否覆盖上一次 .setActiveRecord(false)// 开启 activeRecord 模式 .setEnableCache(true)// XML 二级缓存 .setBaseResultMap(true)// XML ResultMap .setBaseColumnList(true)// XML columList基本的Sql片段 .setOutputDir(System.getProperty(\"user.dir\")+\"/src/main/java\") .setAuthor(\"MkCorden\") .setServiceName(\"%sService\") .setServiceImplName(\"%sServiceImpl\") .setControllerName(\"%sController\") .setMapperName(\"%sDao\") .setXmlName(\"%sDao\") .setIdType(IdType.UUID) .setOpen(false) .setDateType(DateType.ONLY_DATE);//日期类型字段对应的转换模式 %s是占位符 DateType有三种 ONLY_DATE 只使用 java.util.date 代替 SQL_PACK 使用 java.sql 包下的 TIME_PACK 使用 java.time 包下的 InjectionConfig 自定义配置1234567891011121314151617181920212223InjectionConfig cfg = new InjectionConfig() { @Override public void initMap() { //TODO }}; // 自定义输出配置List&lt;FileOutConfig&gt; focList = new ArrayList&lt;&gt;();//String projectPath = System.getProperty(\"user.dir\");// 自定义配置会被优先输出focList.add(new FileOutConfig(\"/templates/mapper.xml.ftl\") { @Override public String outputFile(TableInfo tableInfo) { //首字母小写 char[] cs = tableInfo.getEntityName().toCharArray(); cs[0] += 32; // 自定义输出文件名 ， 如果你 Entity 设置了前后缀、此处注意 xml 的名称会跟着发生变化！！ return System.getProperty(\"user.dir\") + \"/src/main/resources/mapper/\" + String.valueOf(cs) + \"/\" + tableInfo.getEntityName() + \"Dao\" + StringPool.DOT_XML; }});cfg.setFileOutConfigList(focList); /templates/mapper.xml.ftl默认模版路径 与Druid集成问题 在Druid 1.1.19版本已经解决 使用Druid旧版本连接池，在使用MP代码生成器将时间类型字段映射到jdk1.8的java.time.*时，进行数据库操作对应字段会报java.sql.SQLFeatureNotSupportedException，原因具体issue见 druid:3393 / mybatis-plus:1245，解决办法又两个： 在MP的GlobalConfig中设置.setDateType(DateType.ONLY_DATE)，强制把所有时间类型转换为Date。 将MP版本将到3.1.0即可。 因为在MP ver.3.1.1加入了分布式事务特性，再一个使用新的时间格式会造成不可知的其他第三方插件不支持，综上我选第一种，哈哈。 注解使用MP自带代码生成器生成的Domain类会有@TableName @TableId @TableField注解。同时MP也提供了如@Version（乐观锁中代表版本）@TableLogic（逻辑删除中使用)，下面简单介绍几个注解，详细请参考官网文档 @TableName12@TableName(value = \"test_subject\",resultMap = \"BaseResultMap\")public class Subject implements Serializable { value：指定数据库中的表名 resultMap：指定xml中ResultMap的id keepGlobalPrefix： false（默认）：如果是 false , 全局的 tablePrefix 不生效 @TableId12@TableId(value = \"subject_id\", type = IdType.AUTO)private Long subjectId; 用于注解主键对应的属性值 value：指定主键字段名 type：指定主键的类型 AUTO：数据库自增 INPUT：自行输入 ID_WORKER：分布式全局唯一ID 长整型类型 UUID：32位UUID字符串 NONE：无状态 ID_WORKER_STR：分布式全局唯一ID 字符串类型 @TableField12@TableField(value = \"sup_subject_id\", fill = FieldFill.INSERT)private String supSubjectId; 用于注解除主键以外其他属性 value：指定对应数据库字段名 fill：自动填充策略 DEFAULT：默认不处理 INSERT：插入时填充字段 UPDATE：更新时填充字段 INSERT_UPDATE：插入和更新时填充字段 其他配置见官方文档 （公共字段）默认填充使用默认填充特性，首先要在@TableField注解内配置fill属性，然后需要实现MetaObjectHandler接口，进行自定义自动填充时候的赋值。 注意：当字段不为空时，默认填充的值会覆盖原有值。可以在填充时候进行判断，不为空时候进行填充（有点像数据库默认值），但是不建议这么做。因为每次insert和update操作都会执行我们实现的接口，所以该特性最好用于公共字段的默认填充。 12345678910111213141516171819202122232425@Componentpublic class MyMetaObjectHandler implements MetaObjectHandler { /** * 插入元对象字段填充（用于插入时对公共字段的填充） * * @param metaObject 元对象 */ @Override public void insertFill(MetaObject metaObject) { System.out.println(\"-----------------插入方法实体填充INSERT----------------\"); setFieldValByName(\"classOverDate\", LocalDate.now().plusDays(60), metaObject); setFieldValByName(\"supSubjectId\", \"-1\", metaObject); } /** * 更新元对象字段填充（用于更新时对公共字段的填充） * * @param metaObject 元对象 */ @Override public void updateFill(MetaObject metaObject) { System.out.println(\"-----------------插入方法实体填充UPDATE----------------\"); setFieldValByName(\"classOverDate\", LocalDate.now().plusDays(70), metaObject); }} 分页插件分页时候如果设置pageSize = -1则不进行分页，如果要进行排序分页，传参数时，将排序条件封装即可，MP在Page对象中已经封装好了1234 /** * 排序字段信息 */private List&lt;OrderItem&gt; orders = new ArrayList&lt;&gt;(); 12345678910public class OrderItem { /** * 需要进行排序的字段 */ private String column; /** * 是否正序排列，默认 true */ private boolean asc = true; 请求： 具体使用 配置 12345678910/** * 分页插件 */@Beanpublic PaginationInterceptor paginationInterceptor() { PaginationInterceptor paginationInterceptor = new PaginationInterceptor(); //你的最大单页限制数量，默认 500 条，小于 0 如 -1 不受限制 // paginationInterceptor.setLimit(500); return paginationInterceptor;} 使用 1234567891011121314 /** * 分页 * @return */@GetMapping(\"students/page\")public ResponseEntity searchByPage(Page&lt;Student&gt; student_page, boolean listMode){ if (listMode) { // size 小于 0 不在查询 total 及分页，自动调整为列表模式。 // 注意！！这个地方自己控制好！！ student_page.setSize(-1); } IPage&lt;Student&gt; pageStudent = studentService.page(student_page); return ResponseUtil.pageSuccess(pageStudent.getTotal(),pageStudent.getRecords());} 性能分析器12345678@Bean//@Profile({\"dev\",\"test\"})// 设置 dev test 环境开启public PerformanceInterceptor performanceInterceptor() { PerformanceInterceptor performanceInterceptor = new PerformanceInterceptor(); performanceInterceptor.setMaxTime(1000);// 最大执行时间 performanceInterceptor.setFormat(true);// sql是否格式化 return performanceInterceptor;} 控制台效果： 默认接口CURD通过MP的代码构造器生成的Service和Dao文件，已经默认继承了com.baomidou.mybatisplus.extension.service.impl.ServiceImpl和com.baomidou.mybatisplus.core.mapper.BaseMapper,在这两文件中MP已经默认帮我们实现了一些CRUD方法。 Mapper CURD接口在启动时会自动解析实体表关系映射转换为Mybatis内部对象注入容器。 Service CRUD接口进一步封装CRUD，采用get查询单行remove删除list查询集合page分页，前缀命名方式区分Mapper层避免混淆。 业务ServiceImpl继承了MP的ServiceImpl，并注入到Controller层，所以在Controller层，对于简单的业务，可以直接调用对应方法进行返回。 条件构造器Wrapper因为使用Jdk1.8，支持lambda表达式，主要是用各种LambdaWrapper。对于在RPC模式中，不建议传输Wrapper，因为Wrapper很重。正确的方式是封装DTO进行传输，在接收端根据接收到的DTO进行相应的操作。 使用中如果入参的Map或者List为空,则不会加入最后生成的sql中!!! LambdaQueryWrapper123456789@GetMapping(\"students/search\")public ResponseEntity searchByCondition(@ModelAttribute StudentModel student_model){ //最好使用LambdaQueryWrapper,这样可以通过Student::getTrueName方式获取数据库字段名 //使用正常的QueryWrapper，需要写死字段名如\"true_name\"才可以 return ResponseUtil.success(studentService.list(new QueryWrapper&lt;Student&gt;() .lambda() .like(Student::getTrueName,student_model.getTrueName()) .between(Student::getBirthday,student_model.getBeginDate(),student_model.getEndDate())));} 上面代码中Student::getBirthday，Student为实体类，getBirthday是birthday字段的getMethod 通过QueryWrapper的.lambda()方法转换为LambdaQueryWrapper，这样可以不用将字段名写死，因为MP在处理LambdaQueryWrapper时候会通过columnToString()来转换为数据库中的字段名。 如果不能使用Lambda特性，指定字段时候，一定要写数据库中的字段名。不要写实体类的属性名。 LambdaUpdateWrapper跟QueryWrapper相似，需要注意的点是，在设置SET时候，要进行非空判断（最好直接使用已经封装的UpdateByID），因为： 例: set(“name”, “”)—&gt;数据库字段值变为空字符串 例: set(“name”, null)—&gt;数据库字段值变为null SQL注入器 与 分表分库待完成… 总结Mybatis-Plus的诸多特性，在开发中大大减少了无意义Coding的时间，同时也带来了一些不确定性，和少量的学习成本。本文学习过程中的代码已将上传到GitHub上，链接在这——&gt;","link":"/2019/08/13/MabtisPlus/"},{"title":"MacOS JDK，使用Jenv管理本地JDK版本","text":"MacOS上配置JDK环境（附带下载地址），并使用Jenv快速高效的管理本地环境变量JDK版本。 Mac JDK下载 mac版本 jdk 1.6 需要到苹果开发者网站下载 mac版本 jdk 1.7 需要到网上找资源，官方已经停止jdk 1.7的下载链接 mac版本 jdk 1.8 直接到官方网站下载即可 homebrew 使用brew install java 安装会直接安装jdk 10（最新版本） 1brew install java JDK安装目录命令查询1/usr/libexec/java_home -V 卸载JDK执行命令：123456789sudo rm -fr ~/Library/Application\\ Support/Javasudo rm -rf /Library/Java/JavaVirtualMachines/jdk&lt;version&gt;.jdksudo rm -rf /Library/PreferencePanes/JavaControlPanel.prefPanesudo rm -fr /Library/PreferencesPanes/JavaControlPanel.prefpanesudo rm -rf /Library/Internet\\ Plug-Ins/JavaAppletPlugin.pluginsudo rm -rf /Library/LaunchAgents/com.oracle.java.Java-Updater.plistsudo rm -rf /Library/PrivilegedHelperTools/com.oracle.java.JavaUpdateHelpersudo rm -rf /Library/LaunchDaemons/com.oracle.java.Helper-Tool.plistsudo rm -rf /Library/Preferences/com.oracle.java.Helper-Tool.plist 使用Jevn管理MacOS JDKJenv概述jEnv is a command line tool to help you forget how to set the JAVA_HOME environment variable 安装（zsh下）使用homebrew安装1brew install jenv 添加环境变量12echo &apos;export PATH=&quot;$HOME/.jenv/bin:$PATH&quot;&apos; &gt;&gt; ~/.zshrcecho &apos;eval &quot;$(jenv init -)&quot;&apos; &gt;&gt; ~/.zshrc 添加jdk版本使用jevn add jdk安装路径，例如：1jenv add /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home 常用操作查看所有本地jdk版本1$ jenv versions 设置全局jdk版本1$ jenv global 1.7 设置本地jdk版本 (可以为每个文件夹单独设置版本)1$ jenv local 1.8 设置shell中的jdk版本1$ jenv shell 1.8 配置JVM Options（全局，本地，shell）123jenv global-options &quot;-Xmx512m&quot;jenv local-options &quot;-Xmx512m&quot;jenv shell-options &quot;-Xmx512m&quot;","link":"/2018/07/16/MacJDK/"},{"title":"FreeMarker指令常用标签及语法","text":"复习FreeMarker，结合网上资料整理了一下常用的指令与语法，以备日后查看。 FreeMarker Template Language(FTL),文件一般保存为xxx.ftl。严格依赖MVC模式，不依赖Servlet容器（不占用JVM内存），使用内建函数。 注意：使用freemaker，要求所有标签必须闭合，否则会导致freemaker无法解析。freemaker注释:&lt;#– 注释内容 –&gt;格式部分,不会输出 基础语法 字符输出 1234${emp.name?if_exists} // 变量存在，输出该变量，否则不输出${emp.name!} // 变量存在，输出该变量，否则不输出${emp.name?default(&quot;xxx&quot;)} // 变量不存在，取默认值xxx ${emp.name!&quot;xxx&quot;} // 变量不存在，取默认值xxx 常用内部函数： 12345${&quot;123&lt;br&gt;456&quot;?html} // 对字符串进行HTML编码，对html中特殊字符进行转义 ${&quot;str&quot;?cap_first} // 使字符串第一个字母大写 ${&quot;Str&quot;?lower_case} // 将字符串转换成小写 ${&quot;Str&quot;?upper_case} // 将字符串转换成大写 ${&quot;str&quot;?trim} // 去掉字符串前后的空白字符 字符串的两种拼接方式拼接： 12$ { “你好$ {emp.name！}”} //输出你好+变量名 $ {“hello”+ emp.name！} //使用+号来连接，输出你好+变量名 可以通过如下语法来截取子串： 12345678&lt;#assign str =“abcdefghijklmn”/&gt;//方法1$ {str?substring（0,4）} //输出abcd//方法2 $ {str[0]}${str[4]} //结果是ae$ {str [1..4]} //结果是bcde//返回指定字符的索引$ {str?index_of（&quot;n&quot;）} 日期输出 1$ {emp.date?string（&apos;yyyy -MM-dd&apos;）} //日期格式 数字输出（以数字20为例） 123456789101112131415161718192021222324252627$ {emp.name?string.number} //输出20 $ {emp.name?string.currency} //¥20.00 $ {emp.name?string.percent} // 20％ $ {1.222？int} //将小数转为int，输出1 &lt;#setting number_format =“percent”/&gt; //设置数字默认输出方式（&apos;percent&apos;，百分比） &lt;#assign answer = 42 /&gt; //声明变量回答42 #{answer} //输出4,200％$ {answer？string} //输出4,200％$ {answer？string.number} //输出42$ {answer？string.currency} //输出¥42.00 $ {answer？string.percent} //输出4,200％#{answer} //输出42 数字格式化插值可采用＃{expr; format}形式来格式化数字，其中格式可以是：mX：小数部分最小X位MX：小数部分最大X位如下面的例子：&lt;#assign x = 2.582 /&gt; &lt;#assign y = 4 /&gt; ＃ {x; M2} //输出2.58 ＃ {y; M2} //输出4 ＃ {x; m2} //输出2.58 ＃{Y; m2} //输出4.0＃ {x; m1M2} //输出2.58 ＃ {x; m1M2} //输出4.0 申明变量 12&lt;#assign foo = false /&gt; //声明变量，插入布尔值进行显示，注意不要用引号$ {foo？string（“yes”，“no”）} //当为真时输出“yes”，否则输出“no” 申明变量的几种方式 1234567891011&lt;#assign name = value&gt; &lt;#assign name1 = value1 name2 = value2 ... nameN = valueN&gt; &lt;#assign same as above... in namespacehash&gt; &lt;#assign name&gt; capture this &lt;/＃assign&gt; &lt;#assign name in namespacehash&gt; capture this &lt;/＃assign&gt; 比较运算算符 12345表达式中支持的比较运算符符如下几个：=或==：判断两个值是否相等。！=：判断两个值是否不等。&gt;或gt：判断左边值是否大于右边值&gt;&lt;=或lte：判断左边值是否小于等于右边值 算术运算符 123456FreeMarker表达式中完全支持算术运算，FreeMarker支持的算术运算符包括：+， - ，*，/，％注意：（1）运算符两边必须是数字（2）使用+运算符时，如果一边是数字，一边是字符串，就会自动将数字转换为字符串再连接， 如：$ {3 +“5”}，结果是：35 逻辑运算符 12345逻辑运算符有如下几个：逻辑与：&amp;&amp; 逻辑或：|| 逻辑非：！逻辑运算符只能作用于布尔值，否则将产生错误 FreeMarker中的运算符优先级如下（由高到低排列）： 123456789①，一元运算符：！②，内建函数：③，乘除法：*，/，％④，加减法： - ，+ ⑤，比较：&gt;，&lt;，&gt; =，&lt;=（lt，lte，gt，gte）⑥，相等：==，=， ！= ⑦，逻辑与：&amp;&amp; ⑧，逻辑或：|| ⑨，数字范围：.. 实际上，我们在开发过程中应该使用括号来严格区分，这样的可读性好，出错少 if逻辑判断（注意：elseif不加空格） 1234567891011121314151617181920&lt;#if condition&gt;...&lt;#elseif condition2&gt;...&lt;#elseif condition3&gt;...&lt;#else&gt;...&lt;/#if&gt;if 空值判断// 当 photoList 不为空时&lt;#if photoList??&gt;...&lt;/#if&gt; 值得注意的是,${..}只能用于文本部分,不能用于表达式,下面的代码是错误的:&lt;#if ${isBig}&gt;Wow!&lt;/#if&gt;&lt;#if &quot;${isBig}&quot;&gt;Wow!&lt;/#if&gt;// 正确写法&lt;#if isBig&gt;Wow!&lt;/#if&gt; switch (条件可为数字，可为字符串) 12345678910111213&lt;#switch value&gt; &lt;#case refValue1&gt; ....&lt;#break&gt; &lt;#case refValue2&gt; ....&lt;#break&gt; &lt;#case refValueN&gt; ....&lt;#break&gt; &lt;#default&gt; .... &lt;/#switch&gt; 集合 &amp; 循环 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// 遍历集合:&lt;#list empList! as emp&gt; ${emp.name!}&lt;/#list&gt;// 可以这样遍历集合:&lt;#list 0..(empList!?size-1) as i&gt; ${empList[i].name!}&lt;/#list&gt;// 与jstl循环类似,也可以访问循环的状态。empList?size // 取集合的长度emp_index: // int类型，当前对象的索引值 emp_has_next: // boolean类型，是否存在下一个对象// 使用&lt;#break&gt;跳出循环&lt;#if emp_index = 0&gt;&lt;#break&gt;&lt;/#if&gt;// 集合长度判断 &lt;#if empList?size != 0&gt;&lt;/#if&gt; // 判断=的时候,注意只要一个=符号,而不是==&lt;#assign l=0..100/&gt; // 定义一个int区间的0~100的集合，数字范围也支持反递增,如100..2&lt;#list 0..100 as i&gt; // 等效于java for(int i=0; i &lt;= 100; i++) ${i}&lt;/#list&gt;// 截取子集合：empList[3..5] //返回empList集合的子集合,子集合中的元素是empList集合中的第4-6个元素// 创建集合：&lt;#list [&quot;星期一&quot;, &quot;星期二&quot;, &quot;星期三&quot;, &quot;星期四&quot;, &quot;星期五&quot;, &quot;星期六&quot;, &quot;星期天&quot;] as x&gt;// 集合连接运算,将两个集合连接成一个新的集合&lt;#list [&quot;星期一&quot;,&quot;星期二&quot;,&quot;星期三&quot;] + [&quot;星期四&quot;,&quot;星期五&quot;,&quot;星期六&quot;,&quot;星期天&quot;] as x&gt;// 除此之外,集合元素也可以是表达式,例子如下:[2 + 2, [1, 2, 3, 4], &quot;whatnot&quot;]// seq_contains：判断序列中的元素是否存在&lt;#assign x = [&quot;red&quot;, 16, &quot;blue&quot;, &quot;cyan&quot;]&gt; ${x?seq_contains(&quot;blue&quot;)?string(&quot;yes&quot;, &quot;no&quot;)} // yes${x?seq_contains(&quot;yellow&quot;)?string(&quot;yes&quot;, &quot;no&quot;)} // no${x?seq_contains(16)?string(&quot;yes&quot;, &quot;no&quot;)} // yes${x?seq_contains(&quot;16&quot;)?string(&quot;yes&quot;, &quot;no&quot;)} // no// seq_index_of：第一次出现的索引&lt;#assign x = [&quot;red&quot;, 16, &quot;blue&quot;, &quot;cyan&quot;, &quot;blue&quot;]&gt; ${x?seq_index_of(&quot;blue&quot;)} // 2// sort_by：排序（升序）&lt;#list movies?sort_by(&quot;showtime&quot;) as movie&gt;&lt;/#list&gt;// sort_by：排序（降序）&lt;#list movies?sort_by(&quot;showtime&quot;)?reverse as movie&gt;&lt;/#list&gt;// 具体介绍：// 不排序的情况：&lt;#list movies as moive&gt; &lt;a href=&quot;${moive.url}&quot;&gt;${moive.name}&lt;/a&gt;&lt;/#list&gt;//要是排序，则用&lt;#list movies?sort as movie&gt; &lt;a href=&quot;${movie.url}&quot;&gt;${movie.name}&lt;/a&gt;&lt;/#list&gt;// 这是按元素的首字母排序。若要按list中对象元素的某一属性排序的话，则用&lt;#list moives?sort_by([&quot;name&quot;]) as movie&gt; &lt;a href=&quot;${movie.url}&quot;&gt;${movie.name}&lt;/a&gt;&lt;/#list&gt;//这个是按list中对象元素的[name]属性排序的，是升序，如果需要降序的话，如下所示：&lt;#list movies?sort_by([&quot;name&quot;])?reverse as movie&gt; &lt;a href=&quot;${movie.url}&quot;&gt;${movie.name}&lt;/a&gt;&lt;/#list&gt; Map对象 12345678910// 创建map&lt;#assign scores = {&quot;语文&quot;:86,&quot;数学&quot;:78}&gt;// Map连接运算符&lt;#assign scores = {&quot;语文&quot;:86,&quot;数学&quot;:78} + {&quot;数学&quot;:87,&quot;Java&quot;:93}&gt;// Map元素输出${emp.name} // 全部使用点语法${emp[&quot;name&quot;]} // 使用方括号循环//遍历集合：&lt;＃list empList！as emp&gt; $ {emp.name！} FreeMarker支持如下转义字符: 1234567891011121314151617\\&quot; ：双引号(u0022)\\&apos; ：单引号(u0027)\\\\ ：反斜杠(u005C)\\n ：换行(u000A)\\r ：回车(u000D)\\t ：Tab(u0009)\\b ：退格键(u0008)\\f ：Form feed(u000C)\\l ：&lt;\\g ：&gt;\\a ：&amp;\\{ ：{\\xCode ：直接通过4位的16进制数来指定Unicode码,输出该unicode码对应的字符.如果某段文本中包含大量的特殊符号,FreeMarker提供了另一种特殊格式:可以在指定字符串内容的引号前增加r标记,在r标记后的文件将会直接输出.看如下代码:${r&quot;${foo}&quot;} // 输出 ${foo}${r&quot;C:/foo/bar&quot;} // 输出 C:/foo/bar include指令 1234567// include指令的作用类似于JSP的包含指令:&lt;#include &quot;/test.ftl&quot; encoding=&quot;UTF-8&quot; parse=true&gt;// 在上面的语法格式中,两个参数的解释如下:encoding=&quot;GBK&quot; // 编码格式parse=true // 是否作为ftl语法解析,默认是true，false就是以文本方式引入注意:在ftl文件里布尔值都是直接赋值的如parse=true,而不是parse=&quot;true&quot; import指令 123// 类似于jsp里的import,它导入文件，然后就可以在当前文件里使用被导入文件里的宏组件&lt;#import &quot;/libs/mylib.ftl&quot; as my&gt;// 上面的代码将导入/lib/common.ftl模板文件中的所有变量,交将这些变量放置在一个名为com的Map对象中，&quot;my&quot;在freemarker里被称作namespace compress 压缩 1234567891011// 用来压缩空白空间和空白的行 &lt;#compress&gt; ... &lt;/#compress&gt;&lt;#t&gt; // 去掉左右空白和回车换行 &lt;#lt&gt;// 去掉左边空白和回车换行 &lt;#rt&gt;// 去掉右边空白和回车换行 &lt;#nt&gt;// 取消上面的效果 escape,noescape 对字符串进行HTML编码 123456789101112// escape指令导致body区的插值都会被自动加上escape表达式,但不会影响字符串内的插值, 只会影响到body内出现的插值,使用escape指令的语法格式如下:&lt;#escape x as x?html&gt; First name: ${firstName} &lt;#noescape&gt;Last name: ${lastName}&lt;/#noescape&gt; Maiden name: ${maidenName} &lt;/#escape&gt;// 相同表达式First name: ${firstName?html} Last name: ${lastName} Maiden name: ${maidenName?html} 配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950spring.freemarker.allow-request-override指定HttpServletRequest的属性是否可以覆盖controller的model的同名项spring.freemarker.allow-session-override指定HttpSession的属性是否可以覆盖controller的model的同名项spring.freemarker.cache是否开启template caching.spring.freemarker.charset设定Template的编码.spring.freemarker.check-template-location是否检查templates路径是否存在.spring.freemarker.content-type设定Content-Type.spring.freemarker.enabled是否允许mvc使用freemarker.spring.freemarker.expose-request-attributes设定所有request的属性在merge到模板的时候，是否要都添加到model中.spring.freemarker.expose-session-attributes设定所有HttpSession的属性在merge到模板的时候，是否要都添加到model中.spring.freemarker.expose-spring-macro-helpers设定是否以springMacroRequestContext的形式暴露RequestContext给Spring’s macro library使用spring.freemarker.prefer-file-system-access是否优先从文件系统加载template，以支持热加载，默认为truespring.freemarker.prefix设定freemarker模板的前缀.spring.freemarker.request-context-attribute指定RequestContext属性的名.spring.freemarker.settings设定FreeMarker keys.spring.freemarker.suffix设定模板的后缀.spring.freemarker.template-loader-path设定模板的加载路径，多个以逗号分隔，默认: [&quot;classpath:/templates/&quot;]spring.freemarker.view-names指定使用模板的视图列表.","link":"/2019/03/03/FreeMarker/"},{"title":"Redis Cluster","text":"从Redis 3.0以后官方推出了Cluster的集群方案，大大增强了Redis水平扩展能力。在此之前已经有第三方Redis集群解决方案，如Twemproxy（Twitter开源），Codis等。Cluster与这些区别是并非使用Porxy模式来连接集群节点，而是使用无中心节点的模式来组建集群，在Cluster之前，只有Sentienl保证了Redis的高可用性。 Cluster实现了多个节点的数据共享，即使部分节点失效或者无法进行通讯，Cluster仍可以继续处理请求。每个主节点至少有一个从节点，当主机节点宕机等不可用情况，从节点会提升为主节点，并自动开始提供服务。 Cluster的节点分配是通过哈希槽实现的（Hash Slot），所有key值都属于16384个哈希槽其中一个，Cluster模式中，每一个主节点都会分配处理一定范围的slot。 Redis ClusterCAP CAP定理：指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可同时获得。一致性(C)：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（所有节点在同一时间的数据完全一致，越多节点，数据同步越耗时）可用性(A)：负载过大后，集群整体是否还能响应客户端的读写请求。（服务一直可用，而且是正常响应时间）分区容错性(P)：分区容忍性，就是高可用性，一个节点崩了，并不影响其它的节点（100个节点，挂了几个，不影响服务，越多机器越好） 对于单一节点的Redis，保证了CP牺牲了A，即Redis能够保证所有用户看到相同的数据（一致性，因为Redis不自动冗余数据）和网络通信出问题时，暂时隔离开的子系统能继续运行（分区容忍性，因为Master之间没有直接关系，不需要通信），但是不保证某些结点故障时，所有请求都能被响应（可用性，某个Master结点挂了的话，那么它上面分片的数据就无法访问了）。 对于Cluster，Redis从单一NOSQL内存数据库变为分布式NOSQL数据库，从CP变成了AP。即通过自动分片和冗余数据，Redis具有了真正的分布式能力，某个结点挂了的话，因为数据在其他结点上有备份，所以其他结点顶上来就可以继续提供服务，保证了Availability。然而，也正因为这一点，Redis无法保证曾经的强一致性了。 Redis Cluster特点 去中心、去中间件，各节点平等，保存各自数据和集群状态，节点间活跃互连。 传统用一致性哈希分配数据，集群用哈希槽（hash slot）分配。 算法为CRC16。 默认分配16384个slot， 用CRC16算法取模{ CRC16(key)%16384 }计算所属slot。 最少3个主节点 Redis Cluster优点 官方解决方案 可以在线水平扩展（Twemproxy的一大弊端就是不支持在线扩容节点） 客户端直连，系统瓶颈更少 无中心架构 支持数据分片 redis-cli代替redis-trib.rbredis 5.0版本后会抛弃redis-trib.rb。直接使用redis-cli客户端实现集群管理。命令如下：123456789101112131415161718192021222324252627282930313233343536redis-cli --cluster helpCluster Manager Commands: create host1:port1 ... hostN:portN #创建集群 --cluster-replicas &lt;arg&gt; #从节点个数 check host:port #检查集群 --cluster-search-multiple-owners #检查是否有槽同时被分配给了多个节点 info host:port #查看集群状态 fix host:port #修复集群 --cluster-search-multiple-owners #修复槽的重复分配问题 reshard host:port #指定集群的任意一节点进行迁移slot，重新分slots --cluster-from &lt;arg&gt; #需要从哪些源节点上迁移slot，可从多个源节点完成迁移，以逗号隔开，传递的是节点的node id，还可以直接传递--from all，这样源节点就是集群的所有节点，不传递该参数的话，则会在迁移过程中提示用户输入 --cluster-to &lt;arg&gt; #slot需要迁移的目的节点的node id，目的节点只能填写一个，不传递该参数的话，则会在迁移过程中提示用户输入 --cluster-slots &lt;arg&gt; #需要迁移的slot数量，不传递该参数的话，则会在迁移过程中提示用户输入。 --cluster-yes #指定迁移时的确认输入 --cluster-timeout &lt;arg&gt; #设置migrate命令的超时时间 --cluster-pipeline &lt;arg&gt; #定义cluster getkeysinslot命令一次取出的key数量，不传的话使用默认值为10 --cluster-replace #是否直接replace到目标节点 rebalance host:port #指定集群的任意一节点进行平衡集群节点slot数量 --cluster-weight &lt;node1=w1...nodeN=wN&gt; #指定集群节点的权重 --cluster-use-empty-masters #设置可以让没有分配slot的主节点参与，默认不允许 --cluster-timeout &lt;arg&gt; #设置migrate命令的超时时间 --cluster-simulate #模拟rebalance操作，不会真正执行迁移操作 --cluster-pipeline &lt;arg&gt; #定义cluster getkeysinslot命令一次取出的key数量，默认值为10 --cluster-threshold &lt;arg&gt; #迁移的slot阈值超过threshold，执行rebalance操作 --cluster-replace #是否直接replace到目标节点 add-node new_host:new_port existing_host:existing_port #添加节点，把新节点加入到指定的集群，默认添加主节点 --cluster-slave #新节点作为从节点，默认随机一个主节点 --cluster-master-id &lt;arg&gt; #给新节点指定主节点 del-node host:port node_id #删除给定的一个节点，成功后关闭该节点服务 call host:port command arg arg .. arg #在集群的所有节点执行相关命令 set-timeout host:port milliseconds #设置cluster-node-timeout import host:port #将外部redis数据导入集群 --cluster-from &lt;arg&gt; #将指定实例的数据导入到集群 --cluster-copy #migrate时指定copy --cluster-replace #migrate时指定replace help Docker部署配置文件redis.conf12345678910port 7001 # 3主3从分别为7000～7006requirepass 123456masterauth 123456daemonize no # docker部署为nocluster-enabled yescluster-config-file node-17-7001.conf # 集群配置文件，首次启动自动生成cluster-announce-ip 10.211.55.17cluster-announce-port 7001cluster-announce-bus-port 17001 启动容器123456docker run -d -it --privileged=true -v /media/psf/Linux/df/redis/cluster-config/redis11.conf:/etc/redis/redis.conf --privileged=true -v /var/df/cluster-redis/cluster1/data:/data --restart always --name cluster11 --net=host --sysctl net.core.somaxconn=1024 redis:5.0.5 redis-server /etc/redis/redis.conf --appendonly yesdocker run -d -it --privileged=true -v /media/psf/Linux/df/redis/cluster-config/redis12.conf:/etc/redis/redis.conf --privileged=true -v /var/df/cluster-redis/cluster2/data:/data --restart always --name cluster12 --net=host --sysctl net.core.somaxconn=1024 redis:5.0.5 redis-server /etc/redis/redis.conf --appendonly yesdocker run -d -it --privileged=true -v /media/psf/Linux/df/redis/cluster-config/redis13.conf:/etc/redis/redis.conf --privileged=true -v /var/df/cluster-redis/cluster3/data:/data --restart always --name cluster13 --net=host --sysctl net.core.somaxconn=1024 redis:5.0.5 redis-server /etc/redis/redis.conf --appendonly yesdocker run -d -it --privileged=true -v /media/psf/Linux/df/redis/cluster-config/redis14.conf:/etc/redis/redis.conf --privileged=true -v /var/df/cluster-redis/cluster4/data:/data --restart always --name cluster14 --net=host --sysctl net.core.somaxconn=1024 redis:5.0.5 redis-server /etc/redis/redis.conf --appendonly yesdocker run -d -it --privileged=true -v /media/psf/Linux/df/redis/cluster-config/redis15.conf:/etc/redis/redis.conf --privileged=true -v /var/df/cluster-redis/cluster5/data:/data --restart always --name cluster15 --net=host --sysctl net.core.somaxconn=1024 redis:5.0.5 redis-server /etc/redis/redis.conf --appendonly yesdocker run -d -it --privileged=true -v /media/psf/Linux/df/redis/cluster-config/redis16.conf:/etc/redis/redis.conf --privileged=true -v /var/df/cluster-redis/cluster6/data:/data --restart always --name cluster16 --net=host --sysctl net.core.somaxconn=1024 redis:5.0.5 redis-server /etc/redis/redis.conf --appendonly yes 自动生成的文件 防火墙设置12345678910111213firewall-cmd --permanent --add-port=7001/tcp firewall-cmd --permanent --add-port=7002/tcp firewall-cmd --permanent --add-port=7003/tcp firewall-cmd --permanent --add-port=7004/tcp firewall-cmd --permanent --add-port=7005/tcp firewall-cmd --permanent --add-port=7006/tcpfirewall-cmd --permanent --add-port=17001/tcp firewall-cmd --permanent --add-port=17002/tcp firewall-cmd --permanent --add-port=17003/tcp firewall-cmd --permanent --add-port=17004/tcp firewall-cmd --permanent --add-port=17005/tcp firewall-cmd --permanent --add-port=17006/tcp firewall-cmd --reload 通过redis-cli建立集群1/usr/local/bin/redis-cli -a 123456 --cluster create 10.211.55.17:7001 10.211.55.17:7002 10.211.55.17:7003 10.211.55.17:7004 10.211.55.17:7005 10.211.55.17:7006 --cluster-replicas 1 验证至此Cluster就搭建完毕了。 查看Cluster所有节点登陆Cluster任意节点，使用cluster nodes ,列出集群当前已知的所有节点（node），以及这些节点的相关信息。我们可以看到7001节点的slot为0-5460,7002为5461-10922，7003为10923-16383 Redis Cluster处理流程 检查Key所在Slot是否属于当前Node？ 计算crc16(key) % 16384得到Slot 查询clusterState.slots负责Slot的结点指针 与myself指针比较 若不属于，则响应MOVED错误重定向客户端 若属于且Key存在，则直接操作，返回结果给客户端 若Key不存在，检查该Slot是否迁出中？(clusterState.migrating_slots_to) 若Slot迁出中，返回ASK错误重定向客户端到迁移的目的服务器上 若Slot未迁出，检查Slot是否导入中？(clusterState.importing_slots_from) 若Slot导入中且有ASKING标记，则直接操作 否则响应MOVED错误重定向客户端 Redis Cluster的failover检测一般地，集群中的节点会向其他节点发送PING数据包，同时也总是应答（accept）来自集群连接端口的连接请求，并对接收到的PING数据包进行回复。当一个节点向另一个节点发PING命令，但是目标节点未能在给定的时限（node timeout）内回复时，那么发送命令的节点会将目标节点标记为PFAIL（possible failure）。 由于节点间的交互总是伴随着信息传播的功能，此时每次当节点对其他节点发送 PING 命令的时候，就会告知目标节点此时集群中已经被标记为PFAIL或者FAIL标记的节点。相应的，当节点接收到其他节点发来的信息时， 它会记下那些被其他节点标记为失效的节点。 这称为失效报告（failure report）。 如果节点已经将某个节点标记为PFAIL，并且根据节点所收到的失效报告显式，集群中的大部分其他主节点（n/2+1）也认为那个节点进入了失效状态，那么节点会将那个PFAIL节点的状态标记为FAIL。 一旦某个节点被标记为FAIL，关于这个节点已失效的信息就会被广播到整个集群，所有接收到这条信息的节点都会将失效节点标记为FAIL。 选举一旦某个主节点进入 FAIL 状态， 集群变为FAIL状态，同时会触发failover。failover的目的是从从节点中选举出新的主节点，使得集群恢复正常继续提供服务。整个主节点选举的过程可分为申请、授权、升级、同步四个阶段： 申请 新的主节点由原已失效的主节点属下的所有从节点中自行选举产生，从节点的选举遵循以下条件： 这个节点是已下线主节点的从节点； 已下线主节点负责处理的哈希槽数量非空； 主从节点之间的复制连接的断线时长有限，不超过 ( (node-timeout * slave-validity-factor) + repl-ping-slave-period ）。 如果一个从节点满足了以上的所有条件，那么这个从节点将向集群中的其他主节点发送授权请求，询问它们是否允许自己升级为新的主节点。从节点发送授权请求的时机会根据各从节点与主节点的数据偏差来进行排序，让偏差小的从节点优先发起授权请求。 授权其他主节点会遵信以下三点标准来进行判断： 发送授权请求的是从节点，而且它所属的主节点处于FAIL状态 ； 从节点的currentEpoch〉自身的currentEpoch，从节点的configEpoch&gt;=自身保存的该从节点的configEpoch； 这个从节点处于正常的运行状态，没有被标记为FAIL或PFAIL状态； 如果发送授权请求的从节点满足以上标准，那么主节点将同意从节点的升级要求，向从节点返回CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK授权。 升级 一旦某个从节点在给定的时限内得到大部分主节点（n/2+1）的授权，它就会接管所有由已下线主节点负责处理的哈希槽，并主动向其他节点发送一个PONG数据包，包含以下内容： 告知其他节点自己现在是主节点了 告知其他节点自己是一个ROMOTED SLAVE，即已升级的从节点； 告知其他节点都根据自己新的节点属性信息对配置进行相应的更新 同步 其他节点在接收到ROMOTED SLAVE的告知后，会根据新的主节点对配置进行相应的更新。特别地，其他从节点会将新的主节点设为自己的主节点，从而与新的主节点进行数据同步。至此，failover结束，集群恢复正常状态。 此时，如果原主节点恢复正常，但由于其的configEpoch小于其他节点保存的configEpoch（failover了产生较大的configEpoch），故其配置会被更新为最新配置，并将自己设新主节点的从节点。 另外，在failover过程中，如果原主节点恢复正常，failover中止，不会产生新的主节点。 在线迁移在10.211.55.19的7000～7006有一套cluster（3主3从），现在迁移到10.211.55.17上 迁移前： 主 从 10.211.55.19:7001 10.211.55.19:7004 10.211.55.19:7002 10.211.55.19:7005 10.211.55.19:7003 10.211.55.19:7006 迁移后： 主 从 10.211.55.17:7001 10.211.55.17:7004 10.211.55.17:7002 10.211.55.17:7005 10.211.55.17:7003 10.211.55.17:7006 迁移前状态 添加主节点123./redis-cli -a 123456 --cluster add-node 10.211.55.17:7001 10.211.55.19:7001./redis-cli -a 123456 --cluster add-node 10.211.55.17:7002 10.211.55.19:7001./redis-cli -a 123456 --cluster add-node 10.211.55.17:7003 10.211.55.19:7001 使用./redis-cli -a 123456 --cluster check 10.211.55.19:7001查看状态发现已经将3个节点加入cluster集群，但是没有分配任何slot。 添加新的主节点的从节点我们分别为10.211.55.17上7001～7003增加从节点7004～700612345./redis-cli -a javaee12 --cluster add-node 10.211.55.17:7004 10.211.55.19:7001 --cluster-slave --cluster-master-id b13675b85b05d4fd2c430fb78b3998ebbf777295./redis-cli -a javaee12 --cluster add-node 10.211.55.17:7005 10.211.55.19:7001 --cluster-slave --cluster-master-id 3cf5fd50477d4a35931c18073967f672308712d7./redis-cli -a javaee12 --cluster add-node 10.211.55.17:7006 10.211.55.19:7001 --cluster-slave --cluster-master-id 1c3a2b8460e0a2d8abb3d716bcafe48d9644dba3 查看现在集群状态三个slave节点已经加上 进行迁移12345# 后续填的迁移slot会从现有节点随机抽取./redis-cli -a javaee12 --cluster reshard 10.211.55.19:7001# 将一个节点的定量slot迁移到其他节点./redis-cli -a javaee12 --cluster reshard 10.211.55.19:7001 --cluster-from bd8be2765f1ea9be8abf86e55d72ce77eda59a70 --cluster-to 3cf5fd50477d4a35931c18073967f672308712d7 --cluster-slots 3641 --cluster-yes --cluster-timeout 5000 --cluster-pipeline 10 删除旧节点1./redis-cli -a 123456 --cluster del-node 10.211.55.19:7003 45e24c18dfd00d7f460faeb66ddbc6506612c8de 删除master主节点时需注意下面几点： 如果主节点有从节点，需要将从节点转移到其他主节点或提前删除从节点。 如果主节点有slot，去掉分配的slot，然后再删除主节点。 重新分配删除完节点后，发现slot并不平均，我们进行rebalance。1./redis-cli -a 123456 --cluster rebalance 10.211.55.17:7001 SpringBoot使用Cluster Redis配置文件1234567891011121314spring: redis: jedis: pool: max-active: 10 max-wait: 10000 max-idle: 10 min-idle: 0 cluster: max-redirects: 3 nodes: 10.211.55.19:7001 10.211.55.19:7002 10.211.55.19:7003 10.211.55.19:7004 10.211.55.19:7005 10.211.55.19:7006 password: 123456 ssl: false timeout: 10000 RedisConfig.java1234@Value(\"${spring.redis.cluster.max-redirects}\")private int maxRedirects;@Value(\"${spring.redis.cluster.nodes}\")private String nodes; 1234567891011RedisClusterConfiguration redisConfig = new RedisClusterConfiguration();redisConfig.setMaxRedirects(maxRedirects);String[] cNodes = nodes.split(\" \");List&lt;RedisNode&gt; nodes = new ArrayList&lt;&gt;();for(String node : cNodes){ String[] hp = node.split(\":\"); nodes.add(new RedisNode(hp[0],Integer.parseInt(hp[1])));}redisConfig.setClusterNodes(nodes);redisConfig.setPassword(RedisPassword.of(password));","link":"/2019/10/24/RedisCluster/"},{"title":"搭建个人博客 之 MWeb，服务器和全站Https","text":"MWeb界面简洁和高性能，支持发布协议，可以快速发布写好的文章，MWeb备份配合Docker及七牛，防止数据丢失，重新部署也不会太麻烦，下面介绍MWeb快速部署Hexo文章，Docker创建Nginx容器并配置SSL证书，七牛云图床申请及开启Https。 MWeb使用在那么多md编辑器里之所以喜欢用MWeb有这几个原因： 可以边编辑、预览同开（其实也不看预览，但是必须要开，哈哈～） 可以复制图片到正在编辑的md文件，会在对应目录添加图片副本 可以将图片上传到自己的图床 可以快捷发布到各种服务商：印象，少数派……支持自定义脚本 有外部引用模式 操作简洁 配置七牛云在偏好设置--&gt;发布服务可以看到，对应的填入七牛的空间名称，Access Key，Secret Key，和域名即可。填写好后可以进行验证，上传一张图片看是否成功。 上传图片到七牛云写文章时候直接复制图片粘到md中，文章全部写完后点击右上角分享按钮。 选择把本地图片传至图床。 选择复制 Markdown，图片会上传到所选图床并会复制已经替换成对应域名地址的md文本，将md复制到需要部署的md文件中即可。 注：git要手动上传复制外链 配置发布服务在偏好设置--&gt;发布服务可以看到支持和运行脚本,然后写下对应的hexo部署命令即可。 发布文章到Hexo在需要进行部署的md文件点击右上分享选择对应的发布服务。 MWeb会复制命令到剪切板，直接在弹出的终端里command + V回车就可以运行已经写好的部署命令。 Docker + NginxDocker是一个虚拟化软件，你可以认为是类似：VMware、Virtualbox。对开发来讲总结一个最简单的说法：在 Maven 未产生的年代，jar 包要随着开发项目走到哪里跟到哪里。有了 Maven 写好 pom.xml 即可。此时的 Docker 就好比如 Maven，帮你省去了开发过程中的部署环境差异，你再也不能随便说：你的系统可以运行，我的系统就不行。现在别人连系统都帮你做好了~ Docker安装Nginx容器安装启动Docker（以后会更新Docker详细教程）12sudo yum install docker-ce //安装sudo systemctl start docker //启动 推荐一个替代docker stats的插件 ctop12sudo wget https://github.com/bcicen/ctop/releases/download/v0.7.2/ctop-0.7.2-linux-amd64 -O /usr/local/bin/ctopsudo chmod +x /usr/local/bin/ctop 从Docker仓库拉取最新nginx镜像1docker pull nginx 创建Nginx容器12345678910docker run -v /var/dfile/nginx/nginx.conf:/etc/nginx/nginx.conf -v /var/dfile/nginx:/var/dfile/ -v /var/dfile/nginx/full_chain.pem:/etc/nginx/cert/full_chain.pem -v /var/dfile/nginx/private.key:/etc/nginx/cert/private.key -d -p 80:80 -p 443:443 --name=ng -i -t --restart=always bb7 /bin/bash 进入容器1docker exec -it ng bash Nginx配置nginx的配置文件是/etc/nginx/nginx.conf，配置文件如下（ssl）：123456789101112131415161718192021222324server { listen 443 ssl; server_name localhost; ssl_certificate /etc/nginx/cert/full_chain.pem;#ssl配置 ssl_certificate_key /etc/nginx/cert/private.key;#ssl配置 ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / { root /var/dfile/hexo;#静态资源文件夹 index index.html index.htm;#静态资源页面 } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } server { listen 80;#监听端口 server_name www.mikecorden.com mikecorden.com; rewrite ^(.*) https://$server_name$1 permanent;#301永久重定向 } 启动nginx1/usr/local/sbin/nginx 修改配置文件要重启nginx1/usr/local/sbin/nginx -s reload 用vim修改nginx.conf太费劲，一般直接本地修改完，SFTP工具拖到服务器nginx容器挂在目录，然后重启。 阿里云本站的域名和服务器都是在阿里云购买。阿里云的交互还是很简单的，比较方便，app做的也还行，现在手机也有内置的控制台了。 域名及解析我把博客部署到了github和自己的服务器上，在域名解析的时候，对于国内线路解析到自己的服务器，国外的线路解析到自己的GitHubPages上，来提高访问速度。 SSL证书申请，全站HTTPSSSL证书是在阿里云申请的，下载的时候 选择nginx版本，在创建nginx容器的时候要映射宿主机的443端口用于ssl。具体配置看👆。全站Https需要本站所有的外链必须为Https，包括加载的js，css等，所有的图片链接也必须为Https。因为Hexo其实就是静态页面，实现起来也简单。下面介绍下七牛云图床开启https。 七牛云七牛云提供 10 G/月的标准存储 CDN 回源流量免费额度， 超过按0.15 元/GB 价格进行收费。每个月免费10G对于这种没人看的小博客很够用了，哈哈～ 配置七牛云图床注册七牛云账号，申请对象存储空间（公开空间）。 进入所申请的空间，绑定域名（自动跳转域名管理）。 输入域名，先申请http，保存后进入域名管理，（保存成功后再改为https，这样可以免去手动配置ssl证书）。 状态变为成功后（一般10分钟左右），选择对应的域名，进入配置界面。 配置防盗链白名单，然后配置Https：选择免费证书（阿里云等其他网站申请，点击已有证书），七牛云会自动帮你申请一年有效的免费ssl证书并配置好，最后开启强制Https即可。 最后在域名管理找到域名对应的CNAME值，在阿里云上配置域名解析，类型为CNAME。 最后到此，整个流程结束，现在在MWeb的资源库写笔记，需要发到博客上的直接上传图床复制到外部引用模式对应md中，直接部署生效。也不需要担心备份等突发情况，MWeb支持3个地方的备份，我在Mac本机有备份，在iCloud网盘也有备份，永远不会担心资料丢失了～","link":"/2019/03/18/Hexo2/"},{"title":"搭建个人博客 之 Hexo基础","text":"一直有在本地写md笔记的习惯，又想同步到自己的各个设备随时查看，Win平台试过马克飞象同步到印象笔记，印象笔记端不能编辑，放弃……之后一直使用typora在本地保存，自从18年换到MacOS平台后，尝试过MWeb，Quiver，Bear，Ulysses，最后选择MWeb。后来有了自己的服务器，使用了WordPress一段时间，感觉比较麻烦，速度也不理想。折腾向的我又选择了Hexo，所以有了这篇文章，哈哈。现在是采用MWeb编辑md文件，通过MWeb发布服务直接推到服务器上，图片通过MWeb上传到七牛云，服务器使用Docker和Nginx来实现。这样一来，写完md文件后，直接发布，相当方便哈哈！ 安装HexoMac已经使用HomeBrew安装了node和git，所以直接安装Hexo。1npm install -g hexo 新建并进入Hexo目录，并执行Hexo初始化。 1hexo init //hexo初始化 123hexo g //重新生成博客静态文件hexo g --watch//重新生成博客代码(只对变动的文件生成静态文件)hexo s //启动hexo服务 可以在http://localhost:4000看到本地的hexo博客。 使用Hexo写作1hexo new [layout] &lt;title&gt; layout有三种布局： post 文章 page 页面 draft 草稿 三种布局的模版在Hexo目录/scaffolds/下，可以根据需要进行修改，正文部分可以使用md格式也可以使用html格式。 配置Hexo站点在Hexo目录下的_config.yml是Hexo的站点配置文件，注意每个冒号后要有空格，这是我做更改的配置，其余都为默认。1234567891011121314151617181920212223242526# Sitetitle: Corden Web //网站标题subtitle: Web developer, lifelong learner //网站副标题description: //网站描述keywords: //网站关键词author: MikeCorden //作者language: zh-CN //语言timezone: //时区，默认你电脑的时区## Themes: https://hexo.io/themes/theme: next //使用next主题# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: //同时部署到阿里云服务器和git上- type: sftp //部署方式 host: //服务器ip user: //用户名 pass: //密码 remotePath: //上传路径 port: //端口 agent: $SSH_AUTH_SOCK- type: git //部署方式 repo: //git上仓库地址 branch: //分支名称 message: //提交信息 如果只部署到服务器上(更多方式请参考 : hexo.io) ：123deploy: type: sftp ... 使用Hexo主题主题可以在hexo.themes上选择并下载，默认主题是landscape，我下载了Modernist和NexT。 安装NexT主题进入Hexo目录。1git clone git@github.com:theme-next/hexo-theme-next.git themes/next 修改Hexo路径下站点配置文件_config.yml。1theme: next //next需要与themes下对应的主题文件夹同名 配置NexT主题在Hexo目录下cd themes/next可以看到_config.yml，这个是NexT主题的配置文件，注意不要跟Hexo的站点配置文件搞混。 👇简单介绍一些我使用的配置： 菜单配置12345678910# Usage: `Key: /link/ || icon`menu: home: / || home archives: /archives/ || archive categories: /categories/ || th tags: /tags/ || tags about: /about/ || user #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 设置后需要在Hexo主目录下创建页面： 1hexo new page tags 如果引入评论系统要在页面加上comments: false（分类和关于页面也要加） 更改主题布局四种布局可选，打开所需布局即可。12345# Schemes#scheme: Muse#scheme: Mistscheme: Pisces#scheme: Gemini 联系方式12345social: GitHub: https://github.com/yourname || github E-Mail: mailto:&lt;yourmail&gt; || envelope Instagram: https://instagram.com/&lt;你的Ins用户名&gt; || instagram ... 头像123456# Sidebar Avataravatar: url: #头像地址 rounded: false #true--&gt;圆的 opacity: 1 #透明度 rotated: false #true--&gt;鼠标放上旋转 url可以是OSS外链，也可以在主题下的source/images/下放置头像文件即可。 边栏123sidebar: # Sidebar Position, available values: left | right (only for Pisces | Gemini). position: left 自带动画效果123motion: enable: true #开启 async: true #开启异步 开启动画会影响打开网站速度，可以关闭 自带动画背景效果1234567canvas_nest: enable: true #开启 onmobile: false #手机端是否显示 color: \"0,0,0\" #线条颜色 opacity: 0.5 #透明度 zIndex: -1 #z轴坐标 count: 99 #线的数量 NexT主题自带动画canvas_nest或three_waves，根据需求设置值为true或者false即可。 fancybox图片放大12git clone https://github.com/theme-next/theme-next-fancybox3 /themes/next/source/lib/fancybox 在NexT主题配置文件中设置fancybox: true即可。 自定义行内代码样式进入themes/next/source/css/_custom修改custom.styl文件即可。12345678code { color: #c7254e; background: #f9f2f4; border: 1px solid #d6d6d6; padding:1px 4px; word-break: break-all; border-radius:4px;} 百度统计分析 注册百度统计，并新建网站列表。 建立成功后，获取新版统计代码。 将上图中黑色遮挡的ID复制到NexT配置文件,即可开启。 1baidu_analytics: Your Baidu Analytics ID 百度统计的自动代码检测可能检测不到代码装载，可以进行手动检查。 不蒜子阅读量统计在NexT配置文件开启即可。12345678busuanzi_count: enable: true total_visitors: true total_visitors_icon: user total_views: true total_views_icon: eye post_views: true post_views_icon: eye 评论系统ValineNexT已经集成了Valine，在主题的配置文件中就可以找到。Valine是基于LeanCloud的，所以需要先申请LeanCloud。 在LeanCloud创建应用。 获取AppId和AppKey 在NexT主题配置文件找到valine并配置 12345678910111213valine: enable: true #开启 appid: #leancloud appid appkey: #leancloud appkey notify: false #邮件通知,参考:https://github.com/xCss/Valine/wiki verify: false #验证码 placeholder: ヾﾉ≧∀≦)o 来呀！快活呀！~ #placeholder文本 avatar: mm #评论头像，参考:https://valine.js.org/avatar.html guest_info: nick,mail #评论标题，link(网址) pageSize: 10 #每页数量 language: #语言:en, zh-cn visitor: false #阅读量 comment_count: true #true首页显示每篇文章评论数 使用Valine阅读量统计需要注意：leancloud-counter-security is not supported for now. When visitor is set to be true, appid and appkey are recommended to be the same as leancloud_visitors’ for counter compatibility. Article reading statistic 评论效果👇： 最后到此，Hexo和NexT主题配置结束，下一篇文章将介绍markdown编辑器MWeb快速部署Hexo文章，Docker创建Nginx容器，以及七牛云图床申请，ssl证书等设置。","link":"/2019/03/17/Hexo/"},{"title":"微服务概念类知识","text":"关于CAP理论CAP定理指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可同时获得。 一致性：C在分布式系统中的所有数据备份，在同一时刻是否同样的值。（所有节点在同一时间的数据完全一致，越多节点，数据同步越耗时） 可用性：A负载过大后，集群整体是否还能响应客户端的读写请求。（服务一直可用，而且是正常响应时间） 分区容错性：P分区容忍性，就是高可用性，一个节点崩了，并不影响其它的节点（100个节点，挂了几个，不影响服务，越多机器越好） CAP理论就是说在分布式存储系统中，最多只能实现上面的两点。而由于当前的网络硬件肯定会出现延迟丢包等问题，所以分区容忍性是我们必须需要实现的。所以我们只能在一致性和可用性之间进行权衡 其他问题 满足CA，不能满足P原因：数据同步(C)需要时间，也要正常的时间内响应(A)，那么机器数量就要少，所以P就不满足 满足CP，不能满足A原因：数据同步(C)需要时间, 机器数量也多(P)，但是同步数据需要时间，所以不能再正常时间内响应，所以A就不满足 满足AP，不能满足C原因：机器数量也多(P)，正常的时间内响应(A)，那么数据就不能及时同步到其他节点，所以C不满足 注册中心选择 Zookeeper：CP设计，保证了一致性，集群搭建的时候，某个节点失效，则会进行选举行的leader，或者半数以上节点不可用，则无法提供服务，因此可用性没法满足 Eureka：AP原则，无主从节点，一个节点挂了，自动切换其他节点可以使用，去中心化 结论：分布式系统中P,肯定要满足，所以只能在CA中二选一。没有最好的选择，最好的选择是根据业务场景来进行架构设计。 如果要求一致性，则选择zookeeper，如金融行业如果要去可用性，则Eureka，如电商系统 云计算模式:三种主流模式 名称 全称 翻译 PaaS Platform as a Service 平台即服务 IaaS Infrastructure sa a Service 基础设施即服务 SaaS Software as a Service 软件即服务 结合例子理解在《Spring Microservices in Action》有这样一个例子：当你想吃饭时，你有4种模式： 在家做饭。 去杂货店买一顿先做好的食物，然后你加热并享用。 叫外卖送到家里。 开车去餐厅吃饭。 这些选择之间主要的区别在于：谁负责烹饪，以及在哪烹饪。 上述第一条，想要在家里吃饭，就需要自己做所有的工作，家里的食材，器材。 上述第二条，去商店买，自己加热吃，是使用店内的厨师和器材先做好餐点，但你仍有责任要加热，食用，清洗餐具——&gt;IaaS。 上述第三条，外卖，自己提供盘子，家具，但餐厅提供烤箱、食材、厨师——&gt;PaaS 上述第四条，你去一个餐厅吃饭，什么都不需要做，你就是供应商所提供服务的被动消费者，无法对技术进行选择，同时没有责任维护应用程序的基础设施——&gt;SaaS IaaS也就是基础设施即服务（Infrastructure-as-a-Service），拥有了IaaS，就可以将引荐外包到别的地方去。IaaS公司会提供场外服务器，存储和网络硬件，也可以选择租用。节省了维护成本和办公场地，公司可以在任何时候利用这些硬件来运行其应用。目前比较知名的IaaS公司有亚马逊、Bluelock、CSC、GoGrid、IBM等。 PaaS即软件即服务（Platform-as-a-Service），某些时候也被叫作中间件。所有的开发都可以在这一层进行，节省时间与资源。PaaS公司可以提供各种开发和分发应用的解决方案，比如虚拟服务器和操作系统等，可以节省硬件上的费用。PaaS公司与IaaS公司有许多重叠，除了上面列出的那些之外，还有Google、Microsoft Azure、Force.com、,Heroku、Engine Yard等。 最后则是SaaS，软件即服务（Software-as-a-Service），也是我们目前普通用户接触最多的层面，在网络上任意一个远程服务器上的应用都是属于SaaS。比如现在阿里的钉钉、JIBUU以及苹果的iCloud都属于这一类。比较知名的SaaS公司有Salesforce、workday、Slack等。 新兴的云平台 FaaS 函数即服务 CaaS 容器即服务，例如Docker微服务概念的重点在于 构建 有限职责的 小型服务 ，并使用基于HTTP的接口进行通讯。FAAS、CaaS是部署微服务的替代基础设施机制","link":"/2019/02/01/MicroServices/"},{"title":"初遇Redis","text":"什么是Redis讲到redis不得不讲NoSql NoSQL是不同于传统的关系数据库的数据库管理系统的统称。其两者最重要的区别是NoSQL不使用SQL作为查询语言。 NoSQL数据存储可以不需要固定的表格模式。NoSQL是基于键值对的，可以想象成表中的主键和值的对应关系。 NoSQL：redis、memcached、mongodb、guava（loadingCache） Redis是什么Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多 种类型的数据结构，如 字符串（strings）、散列（hashes）、 列表（lists）、 集合（sets）、 有序集合（sorted sets）等。 对比Mysql关系型数据库的一个常见用法是存储长期的报告数据，并将这些报告数据用作固定时间范围内的聚合数据。收集聚合数据的常见做法是：先将各个行插入一个报告表里面， 之后再通过扫描这些行来收集聚合数据， 并更新聚合表中巳有的那些行。先来看看Mysql的执行流程图： 添加索引是在最后一步：执行引擎中发挥作用。 当执行查询时，命中缓存Cache时候，才是最快的。而Redis是一个内存缓存工具，可以通过内存返回数据结果，不用进行表查询，效率是最高的。因为磁盘计算是远远比不上内存计算的。磁盘是要进行一个全表扫描，数据是持久化的。 对比Memcached内存管理机制 Memcached默认使用Slab Allocation机制管理内存，其主要思想是按照预先规定的大小， 将分配的内存分割成特定长度的块 以存储相应长度的key-value数据记录，以完全解决内存碎 片问题。空闲列表进行判断存储状态,【类似于Java虚拟机对象的分配，空闲列表】 Redis使用现场申请内存的方式来存储数据，并且很少使用free-list等方式来优化内存分配，会在一定程度上存在内存碎片,【CPU内存是连续，类似于Java虚拟机对象的分配，直接内存分配（指针碰撞）】 Memcached个人感觉就是将内存碎片变成了内存的浪费。 redis作者可能为了更高的性能，所以在redis中实现了自己的内存分配器来管理内存，不会马上返还内存，不用每次都向OS申请了，从而实现高性能。但是redis的每个k-v对初始化的内存大小是最适合的，当这个value改变的并且原来内存大小不适用的时候，就需要重新分配内存了。（但是value存比原来小不知道会不会产生碎片）。重新分配之后，就会有一部分内存redis无法正常回收，一直占用着。解决方案： 重启redis服务，简单粗暴。 4.0以后清理：（自动）redis-cli -p 6379 config set activedefrag yes 4.0以后清理：（手动）redis-cli -p 6379 memory purge 数据持久化方案 memcached不支持内存数据的持久化操作，所有的数据都以in-memory的形式存储。 redis支持持久化操作。redis提供了两种不同的持久化方法来讲数据存储到硬盘里面， 第一种是rdb形式，一种是aof形式 rdb：属于全量数据备份，备份的是数据 aof：append only if,增量持久化备份，备份的是指令 缓存数据过期机制 概念：key，设计一个小时之后过期，超过一个小时查数据就会查不到 Memcached 在删除失效主键时也是采用的消极方法，即 Memcached 内部也不会监视主键是否失效，而是在通过 Get 访问主键时才会检查其是否已经失效 Redis 定时、定期等多种缓存失效机制，减少内存泄漏 支持的数据类型 Memcached支持单一数据类型,[k,v] redis支持五种数据类型 Redis数据类型操作Key/Value类型简介： String是最常用的一种数据类型，普通的key/value存储都可以归为此类。 set/get 设置key对应的值为String类型的value 获取key对应的值 mget 批量获取多个key的值，如果可以不存在则返回nil incr &amp;&amp; incrby incr对key对应的值进行加加操作，并返回新的值;incrby加指定值 incr &amp;&amp; incrby incr对key对应的值进行加加操作，并返回新的值;incrby加指定值 setnx 设置key对应的值为String类型的value，如果key已经存在则返回0 setex 设置key对应的值为String类型的value，并设定有效期 其他命令 getrange 获取key对应value的子字符串 mset 批量设置多个key的值，如果成功表示所有值都被设置，否则返回0表示没有任何值被设置 msetnx，同mset，不存在就设置，不会覆盖已有的key getset 设置key的值，并返回key旧的值 append：给指定key的value追加字符串，并返回新字符串的长度 Hash类型 Hash是一个String类型的field和value之间的映射表 redis的Hash数据类型的key（hash表名称）对应的value实际的内部存储结构为一个HashMap Hash特别适合存储对象 相对于把一个对象的每个属性存储为String类型，将整个对象存储在Hash类型中会占用更少内存。 所存储的成员较少时数据存储为zipmap，当成员数量增大时会自动转成真正的HashMap,此时encoding为ht。 运用场景： 如用一个对象来存储用户信息，商品信息，订单信息等等。 Hash命令讲解 hset——设置key对应的HashMap中的field的value hget——获取key对应的HashMap中的field的value hgetall——获取key对应的HashMap中的所有field的value hlen–返回key对应的HashMap中的field的数量 List类型 lpush——在key对应的list的头部添加一个元素 lrange——获取key对应的list的指定下标范围的元素，-1表示获取所有元素 lpop——从key对应的list的尾部删除一个元素，并返回该元素 rpush——在key对应的list的尾部添加一个元素 rpop——从key对应的list的尾部删除一个元素，并返回该元素 Set类型 sadd——在key对应的set中添加一个元素 smembers——获取key对应的set的所有元素 spop——随机返回并删除key对应的set中的一个元素 suion——求给定key对应的set并集 sinter——求给定key对应的set交集 SortSet类型简介：set的基础增加顺序score，再根据score进行排序 实战：通过sortset实现排行榜 zadd ——在key对应的zset中添加一个元素 zrange——获取key对应的zset中指定范围的元素，-1表示获取所有元素 zrem——删除key对应的zset中的一个元素 zrangebyscore——返回有序集key中，指定分数范围的元素列表,排行榜中运用 zrank——返回key对应的zset中指定member的排名。其中member按score值递增(从小到大）； 排名以0为底，也就是说，score值最小的成员排名为0,排行榜中运用 Set与SortSet set是通过hashmap存储，key对应set的元素，value是空对象 sortset是怎么存储并实现排序的呢，hashmap存储，还加了一层跳跃表 跳跃表：相当于双向链表，在其基础上添加前往比当前元素大的跳转链接","link":"/2019/06/15/RedisFirstEncounter/"},{"title":"Redis Sentinel模式","text":"在我们了解了Redis单机版本的Redis操作，使用后。在实际的生产环境中，不可能使用单机版Redis，通常最简单的就是主从模式，有点类似mysql的主从库，而当主Redis倒了，我们需要手动通过slaveof no one,slaveof new host进行切换,已经不是监控麻烦的事了，所以Redis官方提供了Sentinel出现了，解决了这一问题。 概述Redis-Sentinel是Redis官方推荐的高可用性(HA)解决方案，当用Redis做Master-slave的高可用方案时，假如master宕机了，Redis本身(包括它的很多客户端)都没有实现自动进行主备切换，而Redis-sentinel本身也是一个独立运行的进程，它能监控多个master-slave集群，发现master宕机后能进行自动切换。Sentinel由一个或多个Sentinel 实例 组成的Sentinel 系统可以监视任意多个主服务器，以及这些主服务器属下的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线主服务器属下的某个从服务器升级为新的主服务器。 简单介绍Sentinel的作用后，我们先进行Docker环境的搭建，再结合log来看Sentinel的原理。 Sentinel状态持久化Sentinel的状态会被持久化地写入sentinel的配置文件中。每次当收到一个新的配置时，或者新创建一个配置时，配置会被持久化到硬盘中，并带上配置的版本戳。这意味着，可以安全的停止和重启sentinel进程。 Sentinel作用 监控master节点状态 master节点异常，进行Master-slave切换，将一个slave升级为Master，原master上线，自动变为新master的slave节点 Master-slave切换后，master、slave的redis.conf文件都会发生改变，master的redis.conf会增加replicaof host port配置 Docker搭建（1主2从3哨兵）初次搭建最好关闭所有防火墙，或者开启对应端口，三台CentOS服务器IP为： IP地址 初始角色 10.211.55.15 主 10.211.55.17 从 10.211.55.19 从 搭建Redis(Master-Slave 一主两从)配置文件准备 Master-redis.conf配置文件 1234567requirepass 123456masterauth 123456port 6380protected-mode nodaemonize no #docker必须为noappendonly yesappendfsync everysec Slave-redis.conf配置文件 12345678replicaof 10.211.55.15 6380requirepass 123456masterauth 123456port 6380protected-mode nodaemonize no #docker必须为noappendonly yesappendfsync everysec Docker依次启动容器，进行验证12345678910docker run \\-d --network=host \\--name sr3-505 \\--restart=always \\-v /media/psf/Linux/df/redis/sentinel-config/redis3.conf:/etc/redis/redis.conf \\-v /var/df/sentinel/rdata:/data \\--privileged=true \\--sysctl net.core.somaxconn=1024 \\redis:5.0.5 \\redis-server /etc/redis/redis.conf 搭建Redis-Sentinel(三哨兵)sentinel.conf文件12345678protected-mode noport 26380sentinel myid s1759a8ddfb52e2c2656ac09da601072a6636b88sentinel monitor mymaster 10.211.55.15 6380 2sentinel down-after-milliseconds mymaster 10000sentinel failover-timeout mymaster 10000sentinel parallel-syncs mymaster 1sentinel auth-pass mymaster 123456 配置文件详解 sentinel monitor mymaster 10.211.55.15 6380 2 这个配置是sentinel需要监控的master/slaver信息，格式为sentinel monitor sentinel监听的master地址。第一个参数mymaster可以为任意名字，但是配置后，sentinel.conf中所有的名字都要跟着换，第四个参数：sentinel集群中至少有2个sentinel同意才行， 不达标，不会发生故障迁移操作。也就是说只要有2个sentinel认为master下线，就认为该master客观下线，启动failover并选举产生新的master。通常最后一个参数不能多于启动的sentinel实例数。 其中应该小于集群中slave的个数，当失效的节点数超过了,则认为整个体系结构失效。不过要注意， 无论你设置要多少个 Sentinel 同意才能判断一个服务器失效， 一个 Sentinel 都需要获得系统中多数（majority） Sentinel 的支持， 才能发起一次自动故障迁移，并预留一个给定的配置纪元 （configuration Epoch ，一个配置纪元就是一个新主服务器配置的版本号）。换句话说， 在只有少数（minority） Sentinel 进程正常运作的情况下，Sentinel 是不能执行自动故障迁移的。 sentinel down-after-milliseconds mymaster 10000 表示master被当前sentinel实例认定为失效的间隔时间。 master在多长时间内一直没有给Sentine返回有效信息，则认定该master主观下线。也就是说如果多久没联系上redis-servevr，认为这个redis-server进入到失效（SDOWN）状态。 如果服务器在给定的毫秒数之内， 没有返回 Sentinel 发送的 PING 命令的回复， 或者返回一个错误， 那么 Sentinel 将这个服务器标记为主观下线（subjectively down，简称 SDOWN）。不过只有一个 Sentinel 将服务器标记为主观下线并不一定会引起服务器的自动故障迁移： 只有在足够数量的 Sentinel 都将一个服务器标记为主观下线之后， 服务器才会被标记为客观下线（objectively down， 简称 ODOWN），这时自动故障迁移才会执行。将服务器标记为客观下线所需的 Sentinel 数量由对主服务器的配置决定。 sentinel auth-pass mymaster 123456 设置sentinel连接的master和slave的密码，这个需要和redis.conf文件中设置的密码一样。 sentinel failover-timeout mymaster 10000 failover过期时间，当failover开始后，在此时间内仍然没有触发任何failover操作，当前sentinel将会认为此次failoer失败。执行故障迁移超时时间，即在指定时间内没有大多数的sentinel 反馈master下线，该故障迁移计划则失效 sentinel parallel-syncs mymaster 1 当在执行故障转移时，设置几个slave同时进行切换master，该值越大，则可能就有越多的slave在切换master时不可用，可以将该值设置为1，即一个一个来，这样在某个slave进行切换master同步数据时，其余的slave还能正常工作，以此保证每次只有一个从服务器处于不能处理命令请求的状态。 Docker启动容器 12345678910docker run \\-d --network=host \\--name s3-505 \\--restart=always \\-v /media/psf/Linux/df/redis/sentinel-config/sentinel3.conf:/etc/redis/sentinel.conf \\-v /var/df/sentinel/sdata:/data \\--privileged=true \\--sysctl net.core.somaxconn=1024 \\redis:5.0.5 \\redis-sentinel /etc/redis/sentinel.conf 效果sentinel masters查看主节点状态sentinel slaves mymaster查看主节点下从节点状态，可以看到2个从节点查看Sentinel Log 至此我们已经在三台服务器上完整的搭建了Redis-Sentinel环境 常用命令登陆到对应的sentinel服务后，redis-cli -h 10.211.55.15 -p 26380 PING ：返回 PONG 。 SENTINEL masters ：列出所有被监视的主服务器，以及这些主服务器的当前状态； SENTINEL slaves &lt;master name&gt; ：列出给定主服务器的所有从服务器，以及这些从服务器的当前状态； SENTINEL get-master-addr-by-name &lt;master name&gt; ： 返回给定名字的主服务器的 IP 地址和端口号。 如果这个主服务器正在执行故障转移操作， 或者针对这个主服务器的故障转移操作已经完成， 那么这个命令返回新的主服务器的 IP 地址和端口号； SENTINEL reset &lt;pattern&gt; ： 重置所有名字和给定模式 pattern 相匹配的主服务器。 pattern 参数是一个 Glob 风格的模式。 重置操作清楚主服务器目前的所有状态， 包括正在执行中的故障转移， 并移除目前已经发现和关联的， 主服务器的所有从服务器和 Sentinel ； SENTINEL failover &lt;master name&gt; ： 当主服务器失效时， 在不询问其他 Sentinel 意见的情况下， 强制开始一次自动故障迁移。 （不过发起故障转移的 Sentinel 会向其他 Sentinel 发送一个新的配置，其他 Sentinel 会根据这个配置进行相应的更新） SENTINEL MONITOR &lt;name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt; 这个命令告诉sentinel去监听一个新的master SENTINEL REMOVE &lt;name&gt; 命令sentinel放弃对某个master的监听 SENTINEL SET &lt;name&gt; &lt;option&gt; &lt;value&gt; 这个命令很像Redis的CONFIG SET命令，用来改变指定master的配置。支持多个。例如以下实例：SENTINEL SET objects-cache-master down-after-milliseconds 1000只要是配置文件中存在的配置项，都可以用SENTINEL SET命令来设置。这个还可以用来设置master的属性，比如说quorum(票数)，而不需要先删除master，再重新添加master。例如：SENTINEL SET objects-cache-master quorum 5 手动容错现象通过上面sentinel log图片，我们可以看到15节点的sentinel显示，主节点是15，从节点是17和19，在17，19分别有两个sentinel监控我们的主节点。现在我们手动模拟线上主节点挂了的状态。关闭主节点，sentinel log如下： log解析123456789101112131415161718192021222324252627// 主观下线master节点:10.211.55.15 6380# +sdown master mymaster 10.211.55.15 6380,// 预留一个新的epoch(纪元),也就是配置版本,版本号为1# +new-epoch 1,// 选举出sentinel的leader为89641c594597aabde5b19d58c5724c0b7e7649f0# +vote-for-leader 89641c594597aabde5b19d58c5724c0b7e7649f0 1,// 客观下线10.211.55.15节点,投票结果是3,规定最小票数位2# +odown master mymaster 10.211.55.15 6380 #quorum 3/2,// 因为+vote-for-leader 89641c594597aabde5b19d58c5724c0b7e7649f0 1,当选失败，那么在设定的故障迁移超时时间（failover-timout=1500）的两倍之后，重新尝试当选。# Next failover delay: I will not start a failover before Wed Oct 9 11:53:56 2019,// 选举出的sentinel leader 进行更新配置文件# +config-update-from sentinel 89641c594597aabde5b19d58c5724c0b7e7649f0 10.211.55.17 26380 @ mymaster 10.211.55.15 6380,// 切换master节点为10.211.55.17 6380# +switch-master mymaster 10.211.55.15 6380 10.211.55.17 6380,// 设置10.211.55.19 6380/10.211.55.15 6380为master:10.211.55.17 6380的从节点* +slave slave 10.211.55.19:6380 10.211.55.19 6380 @ mymaster 10.211.55.17 6380,* +slave slave 10.211.55.15:6380 10.211.55.15 6380 @ mymaster 10.211.55.17 6380,// 主观下线从节点10.211.55.15:6380# +sdown slave 10.211.55.15:6380 10.211.55.15 6380 @ mymaster 10.211.55.17 6380, sentinel.conf的变化1234567sentinel config-epoch mymaster 1sentinel leader-epoch mymaster 1sentinel known-replica mymaster 10.211.55.15 6380sentinel known-replica mymaster 10.211.55.19 6380sentinel known-sentinel mymaster 10.211.55.19 26380 a757e33ab258e4e6b19880af7019418d5752dc11sentinel known-sentinel mymaster 10.211.55.17 26380 89641c594597aabde5b19d58c5724c0b7e7649f0sentinel current-epoch 1 下线节点重新上线11:X 09 Oct 2019 12:27:35.600 # -sdown slave 10.211.55.15:6380 10.211.55.15 6380 @ mymaster 10.211.55.17 6380 由log可见，sentinel会移除该节点的下线状态，并使其成为现master节点的slave节点。 SpringBoot整合配置文件1234567891011121314spring: redis: jedis: pool: max-active: 10 max-wait: 10000 max-idle: 10 min-idle: 0 sentinel: master: mymaster nodes: 10.211.55.15:26380 10.211.55.17:26380 10.211.55.19:26380 password: 123456 ssl: false timeout: 10000 Config1234@Value(\"${spring.redis.sentinel.master}\")private String master;@Value(\"${spring.redis.sentinel.nodes}\")private String nodes; 1234String[] cNodes = nodes.split(\" \");Set&lt;String&gt; nodes = new HashSet&lt;&gt;(Arrays.asList(cNodes));RedisSentinelConfiguration redisConfig = new RedisSentinelConfiguration(master,nodes);redisConfig.setPassword(RedisPassword.of(password));","link":"/2019/10/19/RedisSentinel/"},{"title":"Redis Sentinel原理分析","text":"主备切换过程上一篇文章我们了解了如何部署Sentinel模式Redis集群，本文在上一篇的基础上，结合log来分析Sentinel集群模式的一些原理。 SDOWN 主观下线SDOWN(subjectively down)，指的是单个Sentinel实例对服务器做出的下线判断。 即服务器在down-after-milliseconds指定毫秒数内，没有响应Sentinel实例的PING命令，或者响应结果为错误时，Sentinel实例将标记此服务器为SDOWN状态。 Sentinel会以每秒一次的频率向所有与其建立了命令连接的实例（master，从服务，其他sentinel）发PING命令。 如果多个sentinel监视一个服务，有可能存在多个sentinel的down-after-milliseconds配置不同，这个在实际生产中要注意。 ODOWN 客观下线ODOWN(objectively down)，指的是多个Sentinel实例在对同一个服务器做出SDOWN判断， 并且通过SENTINEL is-master-down-by-addr命令互相交流之后，得出的服务器下线判断。ODOWN后才会开启failover。 当一个Sentinel实例标记master为SDOWN后，会询问其他监控该master的Sentinel实例是否也认为master是主观下线。接受到足够数量（判断master是SDOWN，数量由sentinel monitor &lt;masterName&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt;中&lt;quorum&gt;确定）后，master被客观下线，准备进行failover。 只有master有ODOWN状态，slave没有ODOWN状态。 Sentinel之间如何交流master的SDOWN并确定是否ODOWNSentinel通过发送SENTINEL is-master-down-by-addr &lt;ip&gt; &lt;port&gt; &lt;current_epoch&gt; &lt;runid&gt; ip: 主观下线的服务id port: 主观下线的服务端口 current_epoch: sentinel的纪元 runid: * 表示检测服务下线状态 sentinel运行id，表示用来选举领头sentinel 一个sentinel接收另一个sentinel发来的is-master-down-by-addr后，提取参数，根据ip和端口，检测该服务时候在该sentinel主观下线，并且回复is-master-down-by-addr，回复包含三个参数： down_state（1表示已下线，0表示未下线） leader_runid（领头sentinal id） leader_epoch（领头sentinel纪元） Sentinel接收到回复后，根据配置设置的下线最小数量，达到这个值，既认为该服务客观下线。 SDOWN/ODOWN切换从SDOWN切换到ODOWN不需要任何一致性算法，只需要一个gossip协议：如果一个Sentinel收到了足够多的Sentinel发来消息告诉它某个master已经down掉了，SDOWN状态就会变成ODOWN状态。如果之后master可用了，这个状态就会相应地被清理掉。 正如之前已经解释过了，真正进行failover需要一个授权的过程，但是所有的failover都开始于一个ODOWN状态。ODOWN状态只适用于master，对于不是master的redis节点sentinel之间不需要任何协商，slaves和Sentinel不会有ODOWN状态。 配置版本号/纪元epoch在执行failover的时候，Sentinel会自动获取一份新的配置版本号用于本次的failover。当failover结束后，新的版本号会被用于最新的配置。 每个版本号都是独一无二的。 配置传播一个Sentinel成功地对一个master进行了failover，它将会把关于master的最新配置通过广播形式通知其它sentinel，其它的Sentinel则更新对应master的配置。 当将一个slave选举为master并发送SLAVEOF NO ONE后，即使其它的slave还没针对新master重新配置自己，failover也被认为是成功了的，然后所有sentinels将会发布新的配置信息。 每个sentinel使用##发布/订阅##的方式持续地传播master的配置版本信息，配置传播的##发布/订阅##管道是：sentinel:hello。因为每一个配置都有一个版本号，所以以版本号最大的那个为标准。 Sentinel的选举一个redis服务被判断为客观下线时，多个监视该服务的sentinel协商，选举一个领头sentinel，对该redis服务进行故障转移操作。选举领头sentinel遵循以下规则： 所有的sentinel都有公平被选举成领头的资格。 所有的sentinel都有且只有一次将某个sentinel选举成领头的机会（在一轮选举中），一旦选举某个sentinel为领头，不能更改。 sentinel设置领头sentinel是先到先得，一旦当前sentinel设置了领头sentinel，以后要求设置sentinel为领头请求都会被拒绝。 每个发现服务客观下线的sentinel，都会要求其他sentinel将自己设置成领头。 当一个sentinel（源sentinel）向另一个sentinel（目sentinel）发送is-master-down-by-addr ip port current_epoch runid命令的时候，runid参数不是*，而是sentinel运行id，就表示源sentinel要求目标sentinel选举其为领头。 源sentinel会检查目标sentinel对其要求设置成领头的回复，如果回复的leader_runid和leader_epoch为源sentinel，表示目标sentinel同意将源sentinel设置成领头。 如果某个sentinel被半数以上的sentinel设置成领头，那么该sentinel既为领头。 如果在限定时间内，没有选举出领头sentinel，暂定一段时间，再选举。 Slave的选举当Sentinel准备好开始failover，并得到了最终的选举授权后，要开始进行Slave的选举，评估方面有： 与master断开连接的次数 Slave的优先级 数据复制的下标(用来评估slave当前拥有多少master的数据) 进程ID 如果一个slave与master失去联系超过10次，并且每次都超过了配置的最大失联时间(down-after-milliseconds)，如果sentinel在进行failover时发现slave失联，那么这个slave就会被sentinel认为不适合用来做新master的。更严格的定义是，如果一个slave持续断开连接的时间超过(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state就会被认为失去选举资格。 符合上述条件的slave才会被列入master候选人列表，并根据以下顺序来进行排序： sentinel首先会根据slaves的优先级来进行排序，优先级越小排名越靠前。 如果优先级相同，则查看复制的下标，哪个从master接收的复制数据多，哪个就靠前。 如果优先级和下标都相同，就选择进程ID较小的那个。 一个redis无论是master还是slave，都必须在配置中指定一个slave优先级。要注意到master也是有可能通过failover变成slave的。如果一个redis的slave优先级配置为0，那么它将永远不会被选为master。但是它依然会从master哪里复制数据。 Sentinel模式主备切换总结Sentinel主要负责三个方面工作： 监控（Monitoring） Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。 提醒（Notification） 当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。 自动故障转移（Automatic failover） 当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作， 它会将失效主服务器的其中一个从服务器升级为新的主服务器， 并让失效主服务器的其他从服务器改为复制新的主服务器； 当客户端试图连接失效的主服务器时， 集群也会向客户端返回新主服务器的地址， 使得集群可以使用新主服务器代替失效服务器。 Sentinel集群杂乱知识总结为什么要集群单个Sentinel节点不可靠，可能因为宕机，网络波动问题导致无法进行主备切换，多个Sentinel，redis客户端可以连接任意一个Sentinel节点获取redis集群的信息。 Sentinel集群注意 Sentinel集群大多数Sentinel节点认定master主观下线时，master才会被客观下线，即使不管我们在sentinel monitor中设置的数是多少，就算是满足了该值，只要达不到大多数，就不会发生故障迁移。 官方建议至少3台Sentinel节点。 sentinel.conf中IP不要写127.0.0.1/localhost，jedis和客户端是通过这个获取master的IP，会导致连接不上master节点。 当sentinel 启动后会自动的修改sentinel.conf文件，如已发现的master的slave信息，和集群中其它sentinel 的信息等,这样即使重启sentinel也能保持原来的状态。注意，当集群服务器调整时，如更换sentinel的机器，或者新配置一个sentinel，请不要直接复制原来运行过得sentinel配置文件，因为其里面自动生成了以上说的那些信息，我们应该复制一个新的配置文件或者把自动生成的信息给删掉。 当发生故障迁移的时候，master的变更记录与slave更换master的修改会自动同步到redis的配置文件，这样即使重启redis也能保持变更后的状态。 Sentinel工作方式（每个Sentinel实例都执行的定时任务） 每个Sentinel以每秒钟一次的频率向它所知的Master，Slave以及其他 Sentinel 实例发送一个PING命令。 如果一个实例（instance）距离最后一次有效回复PING命令的时间超过 own-after-milliseconds 选项所指定的值，则这个实例会被Sentinel标记为主观下线。 如果一个Master被标记为主观下线，则正在监视这个Master的所有 Sentinel 要以每秒一次的频率确认Master的确进入了主观下线状态。 当有足够数量的Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认Master的确进入了主观下线状态，则Master会被标记为客观下线。 在一般情况下，每个Sentinel 会以每10秒一次的频率向它已知的所有Master，Slave发送 INFO 命令。 当Master被Sentinel标记为客观下线时，Sentinel 向下线的 Master 的所有Slave发送 INFO命令的频率会从10秒一次改为每秒一次。 若没有足够数量的Sentinel同意Master已经下线，Master的客观下线状态就会被移除。 若 Master重新向Sentinel 的PING命令返回有效回复，Master的主观下线状态就会被移除。 Sentinel集群节点/Slaves之间的发现机制Sentinel集群中每一个Sentinel节点都不需要配置其他节点的信息。因为Sentinel利用了master节点的发布/订阅机制去自动发现/监控同一master的sentinel节点。 同样，你也不需要在sentinel中配置某个master的所有slave的地址，sentinel会通过询问master来得到这些slave的地址的。 管道名：__sentinel__:hello 每个sentinel通过向每个master和slave的发布/订阅频道__sentinel__:hello每秒发送一次消息，来宣布它的存在。 每个sentinel也订阅了每个master和slave的频道__sentinel__:hello的内容，来发现未知的sentinel，当检测到了新的sentinel，则将其加入到自身维护的master监控列表中。 每个sentinel发送的消息中也包含了其当前维护的最新的master配置。如果某个sentinel发现自己的配置版本低于接收到的配置版本，则会用新的配置更新自己的master配置。 在为一个master添加一个新的sentinel前，sentinel总是检查是否已经有sentinel与新的sentinel的进程号或者是地址是一样的。如果是那样，这个sentinel将会被删除，而把新的sentinel添加上去。 Sentinel模式master的配置注意因为master在ODOWN后恢复，会变成新master的slave，所以在master的redis.conf 配置文件中同样要配置masterauth &lt;password&gt;，否则变为slave会连接不上新的master节点。 三个定时任务 每10秒每个sentinel会对master和slave执行info命令，这个任务达到两个目的： 发现slave节点 确认主从关系 每2秒每个sentinel通过master节点的channel交换信息（pub/sub）。master节点上有一个发布订阅的频道(__sentinel__:hello)。sentinel节点通过__sentinel__:hello频道进行信息交换(对节点的”看法”和自身的信息)，达成共识。 每1秒每个sentinel对其他sentinel和redis节点执行ping操作（相互监控），这个其实是一个心跳检测，是失败判定的依据。","link":"/2019/10/22/RedisSentinelAnalysis/"},{"title":"Redis(单机)安装部署，与SpringBoot整合(有redis配置详解)","text":"了解了Redis相关基础知识后，本文介绍了如何在Linux中用Docker快速搭建Redis服务（单机），并与SpringBoot进行整合。使用RedisTemplate进行redis的相关操作。 通过Docker安装RedisRedis版本5.0.5SpringBoot版本2.0.4 准备配置文件如果要自定义启动docker的Redis容器，需要去官网下载对应版本的配置文件redis.conf进行更改,以下是docker下更改的单机版配置文件内容。123456789101112daemonize no #docker设置为yes无法启动#安全情况的几个特殊配置：requirepass 123456protected-mode yesbind 0.0.0.0#免密情况：#bind 0.0.0.0#protected-mode noport 6379appendonly yesappendfsync everysec Docker部署拉取对应版本镜像1docker pull redis:5.0.5 创建容器123456789docker run -d -it --privileged=true -v /media/psf/Linux/df/redis/config/redis6.conf:/etc/redis/redis.conf --privileged=true -v /var/df/cluster-redis/data:/data --restart always --name redis5.0.5 --net=host --sysctl net.core.somaxconn=1024 redis-cluster:5.0.5 redis-server /etc/redis/redis.conf 查看镜像运行情况1docker ps 通过rdm连接命令测试 Spring Data Redis与JedisJedisJedis是redis的java客户端，通过它可以对redis进行操作。 与之功能相似的还包括：Lettuce等。 Spring Data Redis它依赖jedis或Lettuce，实际上是对jedis这些客户端的封装，提供一套与客户端无关的api供应用使用，从而你在从一个redis客户端切换为另一个客户端，不需要修改业务代码。spring-boot-data-redis 内部实现了对Lettuce和jedis两个客户端的封装，默认使用的是Lettuce。 连接包作为多个Redis驱动程序（Lettuce和Jedis）的低级抽象。 异常翻译到Spring的便携式数据访问异常层次结构Redis的驱动程序例外。 RedisTemplate，提供高级抽象，用于执行各种Redis操作，异常转换和序列化支持。 Pubsub支持（例如消息驱动的POJO的MessageListenerContainer）。 Redis Sentinel和Redis Cluster支持。 使用Lettuce驱动程序的Reactive API。 JDK，String，JSON和Spring Object / XML映射序列化程序。 在Redis之上的JDK Collection实现。 原子计数器支持课程。 排序和流水线功能。 专门支持SORT，SORT / GET模式和返回的批量值。 Redis 实现了Spring 3.1缓存抽象。 自动实现Repository接口，包括支持自定义查询方法@EnableRedisRepositories。 CDI对存储库的支持。 SpringBoot整合单机版redis使用redisTemplate进行交互 pom.xml依赖新版本：在新版本中spring-boot-starter-redis移除了jedis依赖，因为我们要使用到jedis提供的jedispool，所以要追加引入jedis包12345678910&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt; &lt;version&gt;2.1.8.RELEASE&lt;/version&gt;&lt;/dependency&gt; 旧版本：12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt; &lt;version&gt;2.1.8.RELEASE&lt;/version&gt;&lt;/dependency&gt; 添加配置文件1234567891011121314spring: redis: host: 10.211.55.15 port: 6379 password: 123456 database: 0 timeout: 10000 ssl: false jedis: pool: max-active: 10 max-wait: 10000 max-idle: 10 min-idle: 0 创建RedisConfig1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586@Configurationpublic class RedisConfig { @Value(\"${spring.redis.database}\") private int database; @Value(\"${spring.redis.host}\") private String host; @Value(\"${spring.redis.port}\") private int port; @Value(\"${spring.redis.password}\") private String password; @Value(\"${spring.redis.timeout}\") private int timeout; @Value(\"${spring.redis.jedis.pool.max-active}\") private int maxActive; @Value(\"${spring.redis.jedis.pool.max-idle}\") private int maxIdle; @Value(\"${spring.redis.jedis.pool.min-idle}\") private int minIdle; @Value(\"${spring.redis.jedis.pool.max-wait}\") private long maxWaitMillis; @Value(\"${spring.redis.ssl}\") private boolean ssl; @Bean public RedisConnectionFactory redisConnectionFactory(){ RedisStandaloneConfiguration redisConfig = new RedisStandaloneConfiguration(); redisConfig.setHostName(host); redisConfig.setPort(port); redisConfig.setPassword(RedisPassword.of(password)); redisConfig.setDatabase(database); //设置连接池 JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxIdle(maxIdle); jedisPoolConfig.setMinIdle(minIdle); jedisPoolConfig.setMaxWaitMillis(maxWaitMillis); // 连接耗尽时是否阻塞, false报异常,ture阻塞直到超时, 默认true jedisPoolConfig.setBlockWhenExhausted(true); // 是否启用pool的jmx管理功能, 默认true jedisPoolConfig.setJmxEnabled(true); JedisClientConfiguration jedisClientConfiguration; if(ssl){ jedisClientConfiguration = JedisClientConfiguration.builder() .usePooling().poolConfig(jedisPoolConfig) .and().readTimeout(Duration.ofMillis(timeout)) .useSsl().build(); }else{ jedisClientConfiguration = JedisClientConfiguration.builder() .usePooling().poolConfig(jedisPoolConfig).build(); } return new JedisConnectionFactory(redisConfig,jedisClientConfiguration); } @Bean public RedisTemplate&lt;String,String&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory){ RedisTemplate&lt;String,String&gt; redisTemplate = new RedisTemplate&lt;String,String&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory); RedisSerializer&lt;Object&gt; serializer = getRedisSerializer(); //设置序列化器 redisTemplate.setDefaultSerializer(serializer); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(serializer); redisTemplate.setHashKeySerializer(new StringRedisSerializer()); redisTemplate.setHashValueSerializer(serializer); //开启事务 redisTemplate.setEnableTransactionSupport(true); redisTemplate.afterPropertiesSet(); return redisTemplate; } /** * Redis序列化方式 * @return */ private RedisSerializer getRedisSerializer(){ Jackson2JsonRedisSerializer&lt;Object&gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer&lt;&gt;(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); //解决LocalDateTime的序列化错误 om.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS); om.registerModule(new JavaTimeModule()); jackson2JsonRedisSerializer.setObjectMapper(om); return jackson2JsonRedisSerializer; }} 创建RedisService在RedisService中封装一些常用的redis操作，如果没有可以参考RedisTemplate的api自行封装，下面简单举两个例子：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869@Servicepublic class RedisService { @Autowired private RedisTemplate redisTemplate; /** * 写入缓存 * * @param key * @param value * @return */ public boolean set(final String key, Object value) { boolean result = false; try { ValueOperations&lt;Serializable, Object&gt; operations = redisTemplate.opsForValue(); operations.set(key, value); result = true; } catch (Exception e) { e.printStackTrace(); } return result; } /** * 写入缓存设置时效时间 * * @param key * @param value * @return */ public boolean set(final String key, Object value, Long expireTime) { boolean result = false; try { ValueOperations&lt;Serializable, Object&gt; operations = redisTemplate.opsForValue(); operations.set(key, value); redisTemplate.expire(key, expireTime, TimeUnit.SECONDS); result = true; } catch (Exception e) { e.printStackTrace(); } return result; } /** * 读取缓存 * * @param key * @return */ public Object genValue(final String key) { Object result = null; ValueOperations&lt;String, String&gt; operations = redisTemplate.opsForValue(); result = operations.get(key); return result; } /** * 哈希 添加 * * @param key * @param hashKey * @param value */ public void hmSet(String key, Object hashKey, Object value) { HashOperations&lt;String, Object, Object&gt; hash = redisTemplate.opsForHash(); hash.put(key, hashKey, value); }} RedisTemplateRedisTemplate中定义了对5种数据结构来对redis进行操作:12345redisTemplate.opsForValue();//操作字符串redisTemplate.opsForHash();//操作hashredisTemplate.opsForList();//操作listredisTemplate.opsForSet();//操setredisTemplate.opsForZSet();//操作sortset 以ValueOperations为例,提供如下接口 Redis5.0配置详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281#是否在后台执行，yes：后台运行；no：不是后台运行daemonize yes #是否开启保护模式，默认开启。要是配置里没有指定bind和密码。开启该参数后，redis只会本地进行访问，拒绝外部访问。protected-mode yes #redis的进程文件pidfile /var/run/redis/redis-server.pid #redis监听的端口号。port 6379 #此参数确定了TCP连接中已完成队列(完成三次握手之后)的长度， 当然此值必须不大于Linux系统定义的/proc/sys/net/core/somaxconn值，默认是511，而Linux的默认参数值是128。当系统并发量大并且客户端速度缓慢的时候，可以将这二个参数一起参考设定。该内核参数默认值一般是128，对于负载很大的服务程序来说大大的不够。一般会将它修改为2048或者更大。在/etc/sysctl.conf中添加:net.core.somaxconn = 2048，然后在终端中执行sysctl -p。tcp-backlog 511 #指定 redis 只接收来自于该 IP 地址的请求，如果不进行设置，那么将处理所有请求bind 127.0.0.1 #配置unix socket来让redis支持监听本地连接。# unixsocket /var/run/redis/redis.sock #配置unix socket使用文件的权限# unixsocketperm 700 # 此参数为设置客户端空闲超过timeout，服务端会断开连接，为0则服务端不会主动断开连接，不能小于0。timeout 0 #tcp keepalive参数。如果设置不为0，就使用配置tcp的SO_KEEPALIVE值，使用keepalive有两个好处:检测挂掉的对端。降低中间设备出问题而导致网络看似连接却已经与对端端口的问题。在Linux内核中，设置了keepalive，redis会定时给对端发送ack。检测到对端关闭需要两倍的设置值。tcp-keepalive 0 #指定了服务端日志的级别。级别包括：debug（很多信息，方便开发、测试），verbose（许多有用的信息，但是没有debug级别信息多），notice（适当的日志级别，适合生产环境），warn（只有非常重要的信息）loglevel notice #指定了记录日志的文件。空字符串的话，日志会打印到标准输出设备。后台运行的redis标准输出是/dev/null。logfile /var/log/redis/redis-server.log #是否打开记录syslog功能# syslog-enabled no #syslog的标识符。# syslog-ident redis #日志的来源、设备# syslog-facility local0 #数据库的数量，默认使用的数据库是DB 0。可以通过SELECT命令选择一个dbdatabases 16 # redis是基于内存的数据库，可以通过设置该值定期写入磁盘。# 注释掉“save”这一行配置项就可以让保存数据库功能失效# 900秒（15分钟）内至少1个key值改变（则进行数据库保存--持久化）# 300秒（5分钟）内至少10个key值改变（则进行数据库保存--持久化）# 60秒（1分钟）内至少10000个key值改变（则进行数据库保存--持久化）save 900 1save 300 10save 60 10000 #当RDB持久化出现错误后，是否依然进行继续进行工作，yes：不能进行工作，no：可以继续进行工作，可以通过info中的rdb_last_bgsave_status了解RDB持久化是否有错误stop-writes-on-bgsave-error yes #使用压缩rdb文件，rdb文件压缩使用LZF压缩算法，yes：压缩，但是需要一些cpu的消耗。no：不压缩，需要更多的磁盘空间rdbcompression yes #是否校验rdb文件。从rdb格式的第五个版本开始，在rdb文件的末尾会带上CRC64的校验和。这跟有利于文件的容错性，但是在保存rdb文件的时候，会有大概10%的性能损耗，所以如果你追求高性能，可以关闭该配置。rdbchecksum yes #rdb文件的名称dbfilename dump.rdb #数据目录，数据库的写入会在这个目录。rdb、aof文件也会写在这个目录dir /var/lib/redis ############### 主从复制 ############### #复制选项，slave复制对应的master。# slaveof &lt;masterip&gt; &lt;masterport&gt; #如果master设置了requirepass，那么slave要连上master，需要有master的密码才行。masterauth就是用来配置master的密码，这样可以在连上master后进行认证。# masterauth &lt;master-password&gt; #当从库同主机失去连接或者复制正在进行，从机库有两种运行方式：1) 如果slave-serve-stale-data设置为yes(默认设置)，从库会继续响应客户端的请求。2) 如果slave-serve-stale-data设置为no，除去INFO和SLAVOF命令之外的任何请求都会返回一个错误”SYNC with master in progress”。slave-serve-stale-data yes #作为从服务器，默认情况下是只读的（yes），可以修改成NO，用于写（不建议）。slave-read-only yes #是否使用socket方式复制数据。目前redis复制提供两种方式，disk和socket。如果新的slave连上来或者重连的slave无法部分同步，就会执行全量同步，master会生成rdb文件。有2种方式：disk方式是master创建一个新的进程把rdb文件保存到磁盘，再把磁盘上的rdb文件传递给slave。socket是master创建一个新的进程，直接把rdb文件以socket的方式发给slave。disk方式的时候，当一个rdb保存的过程中，多个slave都能共享这个rdb文件。socket的方式就的一个个slave顺序复制。在磁盘速度缓慢，网速快的情况下推荐用socket方式。repl-diskless-sync no #diskless复制的延迟时间，防止设置为0。一旦复制开始，节点不会再接收新slave的复制请求直到下一个rdb传输。所以最好等待一段时间，等更多的slave连上来。repl-diskless-sync-delay 5 #slave根据指定的时间间隔向服务器发送ping请求。时间间隔可以通过 repl_ping_slave_period 来设置，默认10秒。# repl-ping-slave-period 10 #复制连接超时时间。master和slave都有超时时间的设置。master检测到slave上次发送的时间超过repl-timeout，即认为slave离线，清除该slave信息。slave检测到上次和master交互的时间超过repl-timeout，则认为master离线。需要注意的是repl-timeout需要设置一个比repl-ping-slave-period更大的值，不然会经常检测到超时。# repl-timeout 60 #是否禁止复制tcp链接的tcp nodelay参数，可传递yes或者no。默认是no，即使用tcp nodelay。如果master设置了yes来禁止tcp nodelay设置，在把数据复制给slave的时候，会减少包的数量和更小的网络带宽。但是这也可能带来数据的延迟。默认我们推荐更小的延迟，但是在数据量传输很大的场景下，建议选择yes。repl-disable-tcp-nodelay no #复制缓冲区大小，这是一个环形复制缓冲区，用来保存最新复制的命令。这样在slave离线的时候，不需要完全复制master的数据，如果可以执行部分同步，只需要把缓冲区的部分数据复制给slave，就能恢复正常复制状态。缓冲区的大小越大，slave离线的时间可以更长，复制缓冲区只有在有slave连接的时候才分配内存。没有slave的一段时间，内存会被释放出来，默认1m。# repl-backlog-size 5mb #master没有slave一段时间会释放复制缓冲区的内存，repl-backlog-ttl用来设置该时间长度。单位为秒。# repl-backlog-ttl 3600 #当master不可用，Sentinel会根据slave的优先级选举一个master。最低的优先级的slave，当选master。而配置成0，永远不会被选举。slave-priority 100 #redis提供了可以让master停止写入的方式，如果配置了min-slaves-to-write，健康的slave的个数小于N，mater就禁止写入。master最少得有多少个健康的slave存活才能执行写命令。这个配置虽然不能保证N个slave都一定能接收到master的写操作，但是能避免没有足够健康的slave的时候，master不能写入来避免数据丢失。设置为0是关闭该功能。# min-slaves-to-write 3 #延迟小于min-slaves-max-lag秒的slave才认为是健康的slave。# min-slaves-max-lag 10 # 设置1或另一个设置为0禁用这个特性。# Setting one or the other to 0 disables the feature.# By default min-slaves-to-write is set to 0 (feature disabled) and# min-slaves-max-lag is set to 10. ############### 安全相关 ############### #requirepass配置可以让用户使用AUTH命令来认证密码，才能使用其他命令。这让redis可以使用在不受信任的网络中。为了保持向后的兼容性，可以注释该命令，因为大部分用户也不需要认证。使用requirepass的时候需要注意，因为redis太快了，每秒可以认证15w次密码，简单的密码很容易被攻破，所以最好使用一个更复杂的密码。注意只有密码没有用户名。# requirepass foobared #把危险的命令给修改成其他名称。比如CONFIG命令可以重命名为一个很难被猜到的命令，这样用户不能使用，而内部工具还能接着使用。# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 #设置成一个空的值，可以禁止一个命令# rename-command CONFIG &quot;&quot; ############### 进程限制相关 ############### # 设置能连上redis的最大客户端连接数量。默认是10000个客户端连接。由于redis不区分连接是客户端连接还是内部打开文件或者和slave连接等，所以maxclients最小建议设置到32。如果超过了maxclients，redis会给新的连接发送’max number of clients reached’，并关闭连接。# maxclients 10000 #redis配置的最大内存容量。当内存满了，需要配合maxmemory-policy策略进行处理。注意slave的输出缓冲区是不计算在maxmemory内的。所以为了防止主机内存使用完，建议设置的maxmemory需要更小一些。# maxmemory &lt;bytes&gt; #内存容量超过maxmemory后的处理策略。#volatile-lru：利用LRU算法移除设置过过期时间的key。#volatile-random：随机移除设置过过期时间的key。#volatile-ttl：移除即将过期的key，根据最近过期时间来删除（辅以TTL）#allkeys-lru：利用LRU算法移除任何key。#allkeys-random：随机移除任何key。#noeviction：不移除任何key，只是返回一个写错误。#上面的这些驱逐策略，如果redis没有合适的key驱逐，对于写命令，还是会返回错误。redis将不再接收写请求，只接收get请求。写命令包括：set setnx setex append incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby getset mset msetnx exec sort。# maxmemory-policy noeviction #lru检测的样本数。使用lru或者ttl淘汰算法，从需要淘汰的列表中随机选择sample个key，选出闲置时间最长的key移除。# maxmemory-samples 5 ############### APPEND ONLY 持久化方式 ############### #默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。但是redis如果中途宕机，会导致可能有几分钟的数据丢失，根据save来策略进行持久化，Append Only File是另一种持久化方式，可以提供更好的持久化特性。Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。appendonly no #aof文件名appendfilename &quot;appendonly.aof&quot; #aof持久化策略的配置#no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快。#always表示每次写入都执行fsync，以保证数据同步到磁盘。#everysec表示每秒执行一次fsync，可能会导致丢失这1s数据。appendfsync everysec # 在aof重写或者写入rdb文件的时候，会执行大量IO，此时对于everysec和always的aof模式来说，执行fsync会造成阻塞过长时间，no-appendfsync-on-rewrite字段设置为默认设置为no。如果对延迟要求很高的应用，这个字段可以设置为yes，否则还是设置为no，这样对持久化特性来说这是更安全的选择。设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议yes。Linux的默认fsync策略是30秒。可能丢失30秒数据。no-appendfsync-on-rewrite no #aof自动重写配置。当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，即当aof文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写。当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程。auto-aof-rewrite-percentage 100#设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写auto-aof-rewrite-min-size 64mb #aof文件可能在尾部是不完整的，当redis启动的时候，aof文件的数据被载入内存。重启可能发生在redis所在的主机操作系统宕机后，尤其在ext4文件系统没有加上data=ordered选项（redis宕机或者异常终止不会造成尾部不完整现象。）出现这种现象，可以选择让redis退出，或者导入尽可能多的数据。如果选择的是yes，当截断的aof文件被导入的时候，会自动发布一个log给客户端然后load。如果是no，用户必须手动redis-check-aof修复AOF文件才可以。aof-load-truncated yes ############### LUA SCRIPTING ############### # 如果达到最大时间限制（毫秒），redis会记个log，然后返回error。当一个脚本超过了最大时限。只有SCRIPT KILL和SHUTDOWN NOSAVE可以用。第一个可以杀没有调write命令的东西。要是已经调用了write，只能用第二个命令杀。lua-time-limit 5000 ############### 集群相关 ############### #集群开关，默认是不开启集群模式。# cluster-enabled yes #集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。这个文件并不需要手动配置，这个配置文件有Redis生成并更新，每个Redis集群节点需要一个单独的配置文件，请确保与实例运行的系统中配置文件名称不冲突# cluster-config-file nodes-6379.conf #节点互连超时的阀值。集群节点超时毫秒数# cluster-node-timeout 15000 #在进行故障转移的时候，全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了，导致数据过于陈旧，这样的slave不应该被提升为master。该参数就是用来判断slave节点与master断线的时间是否过长。判断方法是：#比较slave断开连接的时间和(node-timeout * slave-validity-factor) + repl-ping-slave-period#如果节点超时时间为三十秒, 并且slave-validity-factor为10,假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移# cluster-slave-validity-factor 10 #master的slave数量大于该值，slave才能迁移到其他孤立master上，如这个参数若被设为2，那么只有当一个主节点拥有2 个可工作的从节点时，它的一个从节点会尝试迁移。# cluster-migration-barrier 1 #默认情况下，集群全部的slot有节点负责，集群状态才为ok，才能提供服务。设置为no，可以在slot没有全部分配的时候提供服务。不建议打开该配置，这样会造成分区的时候，小分区的master一直在接受写请求，而造成很长时间数据不一致。# cluster-require-full-coverage yes ############### SLOW LOG 慢查询日志 ############### ###slog log是用来记录redis运行中执行比较慢的命令耗时。当命令的执行超过了指定时间，就记录在slow log中，slog log保存在内存中，所以没有IO操作。#执行时间比slowlog-log-slower-than大的请求记录到slowlog里面，单位是微秒，所以1000000就是1秒。注意，负数时间会禁用慢查询日志，而0则会强制记录所有命令。slowlog-log-slower-than 10000 #慢查询日志长度。当一个新的命令被写进日志的时候，最老的那个记录会被删掉。这个长度没有限制。只要有足够的内存就行。你可以通过 SLOWLOG RESET 来释放内存。slowlog-max-len 128 ############### 延迟监控 ################延迟监控功能是用来监控redis中执行比较缓慢的一些操作，用LATENCY打印redis实例在跑命令时的耗时图表。只记录大于等于下边设置的值的操作。0的话，就是关闭监视。默认延迟监控功能是关闭的，如果你需要打开，也可以通过CONFIG SET命令动态设置。latency-monitor-threshold 0 ############### EVENT NOTIFICATION 订阅通知 ################键空间通知使得客户端可以通过订阅频道或模式，来接收那些以某种方式改动了 Redis 数据集的事件。因为开启键空间通知功能需要消耗一些 CPU ，所以在默认配置下，该功能处于关闭状态。#notify-keyspace-events 的参数可以是以下字符的任意组合，它指定了服务器该发送哪些类型的通知：##K 键空间通知，所有通知以 __keyspace@__ 为前缀##E 键事件通知，所有通知以 __keyevent@__ 为前缀##g DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知##$ 字符串命令的通知##l 列表命令的通知##s 集合命令的通知##h 哈希命令的通知##z 有序集合命令的通知##x 过期事件：每当有过期键被删除时发送##e 驱逐(evict)事件：每当有键因为 maxmemory 政策而被删除时发送##A 参数 g$lshzxe 的别名#输入的参数中至少要有一个 K 或者 E，否则的话，不管其余的参数是什么，都不会有任何 通知被分发。详细使用可以参考http://redis.io/topics/notifications notify-keyspace-events &quot;&quot; ############### ADVANCED CONFIG 高级配置 ################数据量小于等于hash-max-ziplist-entries的用ziplist，大于hash-max-ziplist-entries用hashhash-max-ziplist-entries 512#value大小小于等于hash-max-ziplist-value的用ziplist，大于hash-max-ziplist-value用hash。hash-max-ziplist-value 64 #数据量小于等于list-max-ziplist-entries用ziplist，大于list-max-ziplist-entries用list。list-max-ziplist-entries 512#value大小小于等于list-max-ziplist-value的用ziplist，大于list-max-ziplist-value用list。list-max-ziplist-value 64 #数据量小于等于set-max-intset-entries用iniset，大于set-max-intset-entries用set。set-max-intset-entries 512 #数据量小于等于zset-max-ziplist-entries用ziplist，大于zset-max-ziplist-entries用zset。zset-max-ziplist-entries 128#value大小小于等于zset-max-ziplist-value用ziplist，大于zset-max-ziplist-value用zset。zset-max-ziplist-value 64 #value大小小于等于hll-sparse-max-bytes使用稀疏数据结构（sparse），大于hll-sparse-max-bytes使用稠密的数据结构（dense）。一个比16000大的value是几乎没用的，建议的value大概为3000。如果对CPU要求不高，对空间要求较高的，建议设置到10000左右。hll-sparse-max-bytes 3000 #Redis将在每100毫秒时使用1毫秒的CPU时间来对redis的hash表进行重新hash，可以降低内存的使用。当你的使用场景中，有非常严格的实时性需要，不能够接受Redis时不时的对请求有2毫秒的延迟的话，把这项配置为no。如果没有这么严格的实时性要求，可以设置为yes，以便能够尽可能快的释放内存。activerehashing yes ##对客户端输出缓冲进行限制可以强迫那些不从服务器读取数据的客户端断开连接，用来强制关闭传输缓慢的客户端。#对于normal client，第一个0表示取消hard limit，第二个0和第三个0表示取消soft limit，normal client默认取消限制，因为如果没有寻问，他们是不会接收数据的。client-output-buffer-limit normal 0 0 0#对于slave client和MONITER client，如果client-output-buffer一旦超过256mb，又或者超过64mb持续60秒，那么服务器就会立即断开客户端连接。client-output-buffer-limit slave 256mb 64mb 60#对于pubsub client，如果client-output-buffer一旦超过32mb，又或者超过8mb持续60秒，那么服务器就会立即断开客户端连接。client-output-buffer-limit pubsub 32mb 8mb 60 #redis执行任务的频率为1s除以hz。hz 10 #在aof重写的时候，如果打开了aof-rewrite-incremental-fsync开关，系统会每32MB执行一次fsync。这对于把文件写入磁盘是有帮助的，可以避免过大的延迟峰值。aof-rewrite-incremental-fsync yes","link":"/2019/06/16/RedisSpringJunior/"},{"title":"Spring Cloud Eureka","text":"主要介绍Spring Cloud Eureka 服务发现组件概述 各个服务启动时候，将自己注册到注册中心，服务发现组件（Eureka Server）会记录这些信息。 服务消费之可以到服务发现组件（Eureka Server）的注册表查询服务提供者的信息（地址等……），并使用该信息调用提供者的接口 各个微服务使用心跳机制与服务发现组件（Eureka Server）进行通信，服务发现组件长时间没有接收到心跳，会注销该服务实例。 微服务更改信息（IP地址等）会重新进行注册，服务消费者可直接获取最新信息。 Spring Cloud服务发现组件有：Eureka，Zookeeper，Consul…… Eureka概述 Netflix开发的服务发现组件，基于REST的服务。包含：Server、Client。 Spring Cloud将其集成于Spring Cloud Netflix中。 Eureka 2.0以上已经闭源。 Eureka原理概述 Eureka Server提供服务发现能力。 Eureka Client是一个Java客户端，会周期性（默认30s）向Eureka Server 发送心跳。 Eureka Server一定时间（默认90s）内没有接收到心跳会注销掉该实例。 默认情况下Eureka Server也是一个Eureka Client（用于高可用），多个Eureka Server互相注册，会通过复制的方式来同步注册表。 Eureka Client也会缓存注册表信息（避免Eureka Server挂掉，无法调用服务提供者） 创建Eureka Serverpom.xml12345&lt;!-- EurekaServer --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 启动类增加@EnableEurekaServer注解 配置文件application.yml123456789101112131415server: port: 8002spring: application: name: Eureka-Servereureka: client: registerWithEureka: true #是否将自己注册到注册中心 fetchRegistry: true #高可用设置，作用：从其他EurekaServer上复制注册表 service-url: defaultZone: http://admin:admin1@peer1:8001/eureka/ #可以配置多个地址，用逗号分隔 instance: hostname: peer2 高可用Eureka Server因为Eureka Server本身也是一个Eureka Client，互相注册，配置文件设置eureka.client.regsiterWithEureka=true,eureka.client.fetchRegistry=true即可。 添加用户认证引入依赖12345&lt;!-- 登陆验证 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件 Spring Cloud 2.x以后 12345spring: security: user: name: admin password: 123456 Srong CLoud 1.x 123456security: base: enable: true user: name: admin password: 123456 关闭crsf验证设置安全验证后，由于Spring Cloud 2.x是默认开启crsf验证的，所以一点要关闭crsf，否则client是无法注册到eureka server的。1234567891011121314151617@Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { //覆盖父类的 configure(HttpSecurity http) 方法，关闭掉 csrf //如果不关闭，服务将无法注册到此注册中心 //http.csrf().disable();默认是formLogin()，登陆时候不弹窗 http.csrf() .disable() .authorizeRequests() .anyRequest().authenticated() .and() .httpBasic();//httpBasic登陆模式（弹出框） super.configure(http); }} 用户认证下Eureka Client的配置更改defaultZone：erueka.client.service-url.defaultZone: http://{name}:{password}@{host}:{port}/eureka 其他 eureka.instance.prefer-ip-address=true表示将自己的IP注册到Eureka Server，false会将微服务所在的操作系统HOSTNAME注册到Eureka Server eureka.instance.metadate-map.my-metadata=***（key，value随便写）,可以自定义Eureka Server元数据，例如“my-metadata=***”。 自我保护模式，当Eureka Serve节点短时间丢失过多客户端时候，这个节点就会进入自我保护模式，，此时，Eureka Server会保护注册表中的信息，不再删除，故障恢复后节点会自动退出自我保护模式。 多网卡环境下IP选择： 12345678910111213spring: client: inetutils: #忽略docker0网卡和所有veth开头的网卡 ignored-interfaces: - docker0 - veth.* #允许的网络地址 preferredNetworks: - 192.168 - 10.0 #只允许使用站点本地的地址 useOnlySiteLocalInterfaces: true 健康检查状态有：UP，DOWN，OUT_OF_SERVICE，UNKNOWN显示错误，看看健康检查是否开启eureka.client.healthcheck.enabled=true 创建Eureka Clientpom.xml12345&lt;!-- Eureka client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 启动类增加@EnableDiscoveryClient注解 配置文件1234567891011server: port: 9001spring: application: name: Producer eureka: client: serviceUrl: defaultZone: http://admin:123456@peer1:8001/eureka/ 启动Eureka Client可以看到已经注册成功。","link":"/2019/02/05/SpringCloudEureka/"},{"title":"Spring Cloud Bus","text":"主要介绍Spring Cloud Bus github上配置文件 Spring Cloud Bus 概述Spring Cloud Bus 使用轻量级的消息代理（RabbitMQ,Kafka……）连接分布式系统的节点（clients），这样可以广播传播状态的更改（更新配置文件操作）或其他管理指令。达到下图效果。例如上图，所有client都与消息总线想连，当configserver的/bus/refresh接收到请求，会像消息总线发送一个配置更新的事件，通过消息总线广播，所有的client会去configServer拉最新的配置。 Client如何更新配置–&gt;refresh客户端如何去主动获取新的配置信息呢，springcloud已经给我们提供了解决方案，每个客户端通过POST方法触发各自的/refresh Client添加依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; spring-boot-starter-actuator是一套监控的功能，可以监控程序在运行时状态，其中就包括/refresh的功能。 开启更新机制需要给加载变量的类上面加载@RefreshScope，在客户端执行/refresh的时候就会更新此类下面的变量值。 所有的客户端和服务端都需要的依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt; ConfigServer配置文件在configServer配置文件增加：1234567891011121314151617181920212223spring: application: name: Config-Server cloud: config: server: git: uri: https://github.com/****/first-config-repo search-paths: /first username: *** password: *** prefix: /config # 访问yml时候http://hostname:port/config/test/dev即可 rabbitmq: host: 0.0.0.0 # RabbitMQ服务地址 port: 5672 username: *** password: *** management: endpoints: web: exposure: include: bus-refresh # 暴露/bus/refresh端点 可以把所有端点都暴露，用*就可以，但yml中的*需要用双引号括起–&gt;&quot;*&quot;,SpringBoot 2.0.x暴露端点方式：1234# 启用端点 envmanagement.endpoint.env.enabled=true# 暴露端点 env 配置多个,隔开management.endpoints.web.exposure.include=env 已经弃用：management.security.enabled=false client配置文件在bootstrap.yml中增加：1234567891011121314151617spring: cloud: config: name: test # application profile: dev # profile label: master # git分支 discovery: service-id: EUR-SERVER2 # 指定server端的name,也就是server端spring.application.name的值 enabled: true # 开启Config服务发现支持 bus: trace: enabled: true # 开启消息跟踪 rabbitmq: host: 0.0.0.0 port: 5672 username: *** password: *** 其中spring.cloud.config.discovery.*下的配置是为了实现配置中心高可用，也可以指定configServer的地址(此方式不是高可用)：spring.cloud.config.uri: http://peer2:8882 WebHook可以在github上设置，码云也可以，push后可以发送一个Post请求。本地验证可以用HTTP工具自己发http://peer1:8881/actuator/bus-refresh（其中actuator别忘了，经常忘写） 验证当更新github上的文件后，手动发送一个post请求http://peer1:8881/actuator/bus-refresh，这时候再验证client中对应的属性值就会发现已经更改了。","link":"/2019/03/01/SpringCloudBus/"},{"title":"Spring整合Redis进阶","text":"了解过Spring整合Redis后，我们已经可以使用Redis进行缓存操作了。但在某些业务环境下，我们需要向Redis加载一些既有数据，例如：学员答题竞赛的分数排行，首页的一些缓存。这些数据我们需要在项目初始化阶段加载完毕。在项目运行阶段，我们也可以利用SpringCache进行接口的数据缓存，这样可以改善因为并发导致的缓慢（数据库IO），可以成倍的提升QPS。在分布式环境下的项目，我们也可以利用Redis进行集群环境的session共享。 本文依次介绍了，项目初始化阶段加载Redis数据的方式，SpringCache与Redis的整合，以及SpringSession与Redis的整合。 SpringBoot项目初始化加载Redis数据(推荐)第一种方式：实现InitializingBean接口复写afterPropertiesSet方法：123456789@Overridepublic void afterPropertiesSet() throws Exception { List&lt;Student&gt; list = this.findStudents(); if(StringUtils.isNotNull(list)){ list.stream() .filter(s -&gt; StringUtils.isNotNull(s.getTestDatetime())) .forEach(s -&gt; redisService.hmSet(\"stus\",\"stu[\"+s.getStudentId()+\"]\", s)); }} 第二种方式：实现ApplicationRunner接口复写run方法：123456789@Overridepublic void run(ApplicationArguments args) throws Exception { List&lt;Student&gt; list = this.findStudents(); if(StringUtils.isNotNull(list)){ list.stream() .filter(s -&gt; StringUtils.isNotNull(s.getTestDatetime())) .forEach(s -&gt; redisService.hmSet(\"stus\",\"stu[\"+s.getStudentId()+\"]\", s)); }} 两种方法区别 实现InitializingBean接口方式，InitializingBean接口为bean提供了初始化方法的方式，它只包括afterPropertiesSet()方法。在spring初始化bean的时候，如果bean实现了InitializingBean接口， ​ 在对象的所有属性被初始化后之后才会调用afterPropertiesSet()方法。而且这时候用户是进不来的，只有初始化结束后才会放入请求。推荐这种方式。 实现ApplicationRunner接口方式，复写run方法仅在SpringApplication.run(…)完成之后调用。这时候服务已经对外开放，用户可以访问，当redis预热时间很长的时候会造成用户获取数据出错的情况，所以不推荐。 SpringCache与RedisSpringCache集成redis的运行原理Spring缓存抽象模块通过CacheManager来创建、管理实际缓存组件，当SpringBoot应用程序引入spring-boot-starter-data-redis依赖后吗，容器中将注册的是CacheManager实例RedisCacheManager对象，RedisCacheManager来负责创建RedisCache作为缓存管理组件，由RedisCache操作redis服务器实现缓存数据操作。实际测试发现默认注入的RedisCacheManager操作缓存用的是RedisTemplate&lt;Object, Object&gt;，因此我们需要自定义cacheManager，替换掉默认的序列化器。 pom.xml1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;&lt;/dependency&gt; RedisConfig自定义cacheManager，配置序列化方式123456789101112131415161718192021222324252627@Beanpublic CacheManager cacheManager(RedisConnectionFactory redisConnectionFactory, RedisTemplate redisTemplate) { return new RedisCacheManager( RedisCacheWriter.nonLockingRedisCacheWriter(redisConnectionFactory), // 默认策略，未配置的 key 会使用这个 this.getRedisCacheConfigurationWithTtl(600), // 指定 key 策略 this.getRedisCacheConfigurationMap() );}private Map&lt;String, RedisCacheConfiguration&gt; getRedisCacheConfigurationMap() { Map&lt;String, RedisCacheConfiguration&gt; redisCacheConfigurationMap = new HashMap&lt;&gt;(); //单独设置某些缓存key的ttl时间 redisCacheConfigurationMap.put(\"UserInfoList\", this.getRedisCacheConfigurationWithTtl(122200)); return redisCacheConfigurationMap;}private RedisCacheConfiguration getRedisCacheConfigurationWithTtl(Integer seconds) { RedisSerializer&lt;Object&gt; serializer = getRedisSerializer(); RedisCacheConfiguration redisCacheConfiguration = RedisCacheConfiguration.defaultCacheConfig(); redisCacheConfiguration = redisCacheConfiguration .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer())) .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(serializer)) .entryTtl(Duration.ofSeconds(seconds)); return redisCacheConfiguration;} 自定义key生成规则1234567891011121314151617181920/** * Cache缓存key生成规则 * @return */@Beanpublic KeyGenerator simpleKeyGenerator() { return (o, method, objects) -&gt; { StringBuilder stringBuilder = new StringBuilder(); stringBuilder.append(o.getClass().getSimpleName()); stringBuilder.append(\".\"); stringBuilder.append(method.getName()); stringBuilder.append(\"[\"); for (Object obj : objects) { stringBuilder.append(obj.toString()); } stringBuilder.append(\"]\"); return stringBuilder.toString(); };} 开启缓存 在config类添加@EnableCaching注解。 在需要缓存的serviceImpl实现方法添加注解。 12345@Override@Cacheable(value = \"studentObject\",keyGenerator = \"simpleKeyGenerator\")public Student findStudentById(String id) { return getById(id);} 效果第一次从mysql中取数据，第二次以后在key生效内都会从redis中取数据，大大减少了数据库的IO负担。 关于缓存项目中关于数据库的缓存方案有很多，例如MybatisPlus的缓存，EhCache，和SpringCache。SpringCache+Redis可以直接缓存一个Service的数据副本，某些业务场景更有效率写。当然也可以将Redis做为Mysql的二级缓存使用。 Redis实现分布式集群环境session共享pom.xml1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 添加注解在configBean中添加@EnableRedisHttpSession(maxInactiveIntervalInSeconds = 50)注解，该注解还可以配置其他参数： maxInactiveIntervalInSeconds:过期时间 redisNamespace:命名空间，默认为spring:session redisFlushMode:缓存方式，默认为ON_SAVE cleanupCron:session缓存定期清除任务，默认static final String DEFAULT_CLEANUP_CRON = &quot;0 * * * * *&quot;; 自定义SpringSession序列化方式123456789101112131415161718192021222324 /** * Redis Session 序列化方式 * @return */@Bean(\"springSessionDefaultRedisSerializer\")public RedisSerializer&lt;Object&gt; defaultRedisSerializer() { return getRedisSerializer();}/** * Redis序列化方式 * @return */private RedisSerializer&lt;Object&gt; getRedisSerializer(){ Jackson2JsonRedisSerializer&lt;Object&gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer&lt;&gt;(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); //解决LocalDateTime的序列化错误 om.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS); om.registerModule(new JavaTimeModule()); jackson2JsonRedisSerializer.setObjectMapper(om); return jackson2JsonRedisSerializer;} 测试接口1234567891011121314151617181920@RestController()@RequestMapping(\"/session\")public class SessionController { @RequestMapping(value = \"/setSession\", method = RequestMethod.GET) public Map&lt;String, Object&gt; setSession (HttpServletRequest request){ Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); request.getSession().setAttribute(\"request Url\", request.getRequestURL()); map.put(\"request Url\", request.getRequestURL()); return map; } @RequestMapping(value = \"/getSession\", method = RequestMethod.GET) public Object getSession (HttpServletRequest request){ Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"sessionIdUrl\",request.getSession().getAttribute(\"request Url\")); map.put(\"sessionId\", request.getSession().getId()); return map; }} 结果 SetSession Redis GetSession","link":"/2019/06/17/RedisSpringMiddle/"},{"title":"软件架构设计原则","text":"做开发有一段时间了，没有系统的看过Java的软件设计原则。在实际的工作中，已经对通过合理的软件设架构计来提升编码工作的幸福感深有体会。希望通过本文学习，对Java的软件设计原则有个大体的认识。后续也会结合Spring的源码来证明，软件设计原则的重要性。 开闭原则OCP(Open-Closed Principle)原则，指一个实体（类，模块，函数）应该对扩展开放，对修改关闭。即用抽象构建框架（接口），用实现扩展细节（实现类）。 依赖倒置原则DIP(Dependence Inversion Principle)原则，指在设计代码结构，高层模块不应该依赖底层模块，二者都应该依赖其抽象。抽象不依赖细节，细节依赖抽象。作用在于，减少类之间的耦合，利于维护。 “依赖注入”就是这种方式，通过引用接口（抽象），这时调用方对实现类是无依赖的，调用方依赖的是抽象接口，实现类也依赖于接口（毕竟是实现类么）。这样，通过依赖注入调用方与实现类就解耦了（依赖注入不同的实现类，调用方调用同一接口可以有不同的实现）。 单一职责原则SRP(Simple Responsibility Principle)原则：简单来说就是一个类、接口、方法只负责一项职责。因为需求变更改，导致修改其中一个职责逻辑代码，有可能导致另一个职责的功能发生故障。 接口隔离原则ISP(Interface Segregation Principle)原则，指多个专门的接口，而不适用单一的总接口，客户端（实现类）不应该依赖其不需要的接口（或者说实现类有不需要实现的方法）。 一个类对应一个类的依赖应该建立在最小的接口之上。 建议单一接口，不要建立庞大臃肿的接口（在之前不相干接口追加方法）。 尽量细化接口，接口中的方法尽量少（不是越少越好，适量即可）。接口隔离原则符合高内聚，低耦合的设计思想，使类有更好的可读性，可扩展性，维护也很方便。对抽象和业务模型的深入理解才能更好地遵循此原则。 迪米特原则（最少知道原则）LoD(Law of Demeter)又叫最少知道原则（LKP,Least Knowledge Principle）：一个对象对于其他对象保持最少的了解。尽量降低类之间的耦合度。强调： 只与朋友（成员变量，方法的入参、出参中的类）交流，不同陌生人（例如方法体内部的类）说话 举个例子，不要将service层代码逻辑写到controller层，controller只需要调用对应接口即可，所有的内部实现，在controller是无感知的。 里氏原则LSP(Liskov Substitution Principle),指每个T1类型的对象O1，都有T2类型的对象O2，使得T1定义的所有程序P中所有对象O1都替换成O2，程序P的行为没有发生变化，那么类型T2是类型T1的子类。 简单来说：一个程序，适用于父类对象，一定适用于其子类。所有引用父类的地方必须能透明地使用其子类的对象，子类对象能在程序逻辑不变的前提下替换父类对象。或者说：子类可以扩展父类的功能，但不能改变父类原有的功能。 子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。 子类可以增加自己特有的方法。 当子类的方法重载父类的方法时，方法的前置条件（方法的入参）要比父类方法的入参更宽松。 当子类方法实现父类方法时（重写，重载，实现），方法的后置条件（方法的输出、返回值）要比父类更严格或一样。 优势： 约束继承泛滥，是开闭原则的一种体现。 加强程序的健壮性，同时变更时也可以做到非常好的兼容性，提高程序的可维护性，扩展性，降低需求变更时引入的风险。 LSP是继承复用的基石，只有当子类可以替换掉父类，功能不受到影响时，父类才能真正的被复用，子类也能在父类的基础上增加新行为。LSP是对“开闭原则”的补充，实现“开闭原则”的关键步骤就是抽象化。而父类与子类的继承关系就是抽象化的具体实现，所以LSP是对实现抽象化的具体步骤的规范。 合成复用原则CRP(Composite Reuse Principle)原则，指尽量先使用组合或者聚合等关联关系来实现，其次才考虑使用继承关系来实现。 组合/聚合：黑箱复用，无法获取到类以外的对象的实现细节的。 继承：白箱复用，把所有的实现细节暴露给子类。 缺点： 破坏类的封装性。父类实现细节暴露给子类，即父类对子类的透明的，所以叫白箱复用。 父类子类耦合度高。父类任何改变都直接影响子类。 限制了复用的灵活性。继承是静态的，编译时就会定义完毕，运行不能发生变化。 对象之间的继承 —转变—&gt; 引用为成员变量 即：将已有对象纳入新对象中，使之成为新对象的一部分，新对象可以调用已有对象的功能。 参考例子 总结实际开发中，并不要求所有代码都要遵循设计原则，我们要考虑人力，时间，成本，质量，不能刻意追求完美，但是要在适当的场景遵循设计原则。这是一种平衡取舍，可以帮助我们设计出更加优雅的代码结构。","link":"/2020/04/07/SoftwarePrincipe/"}],"tags":[{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/tags/Spring-Boot/"},{"name":"Mac","slug":"Mac","link":"/tags/Mac/"},{"name":"IDEA","slug":"IDEA","link":"/tags/IDEA/"},{"name":"备忘","slug":"备忘","link":"/tags/备忘/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Spring Cloud","slug":"Spring-Cloud","link":"/tags/Spring-Cloud/"}],"categories":[{"name":"Docker","slug":"Docker","link":"/categories/Docker/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/categories/Spring-Boot/"},{"name":"MacOS相关","slug":"MacOS相关","link":"/categories/MacOS相关/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Redis","slug":"Redis","link":"/categories/Redis/"},{"name":"Hexo","slug":"Hexo","link":"/categories/Hexo/"},{"name":"Spring Cloud","slug":"Spring-Cloud","link":"/categories/Spring-Cloud/"},{"name":"Spring 读书笔记","slug":"Java/Spring-读书笔记","link":"/categories/Java/Spring-读书笔记/"}]}